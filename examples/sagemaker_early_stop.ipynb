{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notebook created by nov05 on 2025-02-07\n",
    "* It was run locally with conda env `sagemaker_py310`.  \n",
    "* Compare training results with [this model](https://github.com/silverbottlep/abid_challenge/blob/master/counting/train.py#L191)  \n",
    "* [Issues during training](https://gist.github.com/nov05/1bdc15eda0e781640b46ab28d38f45bd)   \n",
    "* Check [the wandb logs](https://wandb.ai/nov05/udacity-awsmle-resnet34-amazon-bin?nw=nwusernov05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ‘‰ **AWS Credentials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\github\\\\udacity-nd009t-capstone-starter\\\\examples'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## windows cmd to launch notepad to edit aws credential file\n",
    "# !notepad C:\\Users\\guido\\.aws\\config\n",
    "!notepad C:\\Users\\guido\\.aws\\credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/25 21:05:09] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\botocore\\credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\botocore\\credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/25 21:05:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=340545;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\botocore\\credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=988950;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\botocore\\credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/25 21:05:13] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> Couldn't call <span style=\"color: #008700; text-decoration-color: #008700\">'get_role'</span> to get Role ARN from role name voclabs to get <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py#5971\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5971</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Role path.                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/25 21:05:13]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m Couldn't call \u001b[38;2;0;135;0m'get_role'\u001b[0m to get Role ARN from role name voclabs to get \u001b]8;id=634844;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=526924;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py#5971\u001b\\\u001b[2m5971\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         Role path.                                                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current AWS Account ID: 570668189909\n",
      "AWS Region: us-east-1\n",
      "Default Bucket: sagemaker-us-east-1-570668189909\n",
      "Role voclabs ARN: arn:aws:iam::570668189909:role/voclabs\n",
      "SageMaker Role ARN: arn:aws:iam::570668189909:role/service-role/AmazonSageMaker-ExecutionRole-20250126T194519\n"
     ]
    }
   ],
   "source": [
    "## reset the session after updating credentials\n",
    "import boto3 # type: ignore\n",
    "boto3.DEFAULT_SESSION = None\n",
    "import sagemaker # type: ignore\n",
    "from sagemaker import get_execution_role # type: ignore\n",
    "\n",
    "# Extract and print the account ID\n",
    "sts_client = boto3.client('sts')\n",
    "response = sts_client.get_caller_identity() \n",
    "account_id = response['Account']\n",
    "\n",
    "role_arn = get_execution_role()  ## get role ARN\n",
    "if 'AmazonSageMaker-ExecutionRole' not in role_arn:\n",
    "    ## Go to \"IAM - Roles\", search for \"SageMaker\", find the execution role.\n",
    "    voclabs_role_arn = role_arn\n",
    "    sagemaker_role_arn = \"arn:aws:iam::570668189909:role/service-role/AmazonSageMaker-ExecutionRole-20250126T194519\"\n",
    "session = sagemaker.Session()  ## \"default\"\n",
    "region = session.boto_region_name\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "print(f\"Current AWS Account ID: {account_id}\")\n",
    "print(\"AWS Region: {}\".format(region))\n",
    "print(\"Default Bucket: {}\".format(bucket))\n",
    "print(f\"Role voclabs ARN: {voclabs_role_arn}\") ## If local, Role ARN: arn:aws:iam::807711953667:role/voclabs\n",
    "print(\"SageMaker Role ARN: {}\".format(sagemaker_role_arn)) \n",
    "\n",
    "## generate secrets.env. remember to add it to .gitignore  \n",
    "import wandb\n",
    "wandb.sagemaker_auth(path=\"../secrets\") \n",
    "\n",
    "## get my own AWS account info\n",
    "def get_secrets(name):\n",
    "    path = '../secrets/' + name\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            return line.strip()\n",
    "aws_account_number = get_secrets('aws_account_number')\n",
    "aws_account_profile = get_secrets('aws_account_profile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ðŸ‘‰ Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar\n",
      "train_size: 7308, val_size: 1566, test_size: 1567\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/25 23:39:14] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/25 23:39:14]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=126469;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=438121;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/25 23:39:16] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> image_uri is not presented, retrieving image_uri based on            <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py#679\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">679</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         instance_type, framework etc.                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/25 23:39:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m image_uri is not presented, retrieving image_uri based on            \u001b]8;id=75880;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=309985;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py#679\u001b\\\u001b[2m679\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         instance_type, framework etc.                                        \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name: p5-amazon-bin-job-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20250207</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">233914</span>     <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name: p5-amazon-bin-job-\u001b[1;36m20250207\u001b[0m-\u001b[1;36m233914\u001b[0m     \u001b]8;id=756533;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=398529;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-08 05:39:12 Starting - Starting the training job...\n",
      "2025-02-08 05:39:26 Starting - Preparing the instances for training...\n",
      "2025-02-08 05:40:20 Downloading - Downloading the training image...............\n",
      "2025-02-08 05:43:12 Training - Training image download completed. Training in progress...bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "/opt/conda/lib/python3.9/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "/opt/conda/lib/python3.9/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n",
      "2025-02-08 05:43:22,942 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2025-02-08 05:43:22,963 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-08 05:43:22,977 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2025-02-08 05:43:22,981 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\n",
      "2025-02-08 05:43:22,981 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2025-02-08 05:43:24,171 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\n",
      "bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "/opt/conda/lib/python3.9/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "/opt/conda/lib/python3.9/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n",
      "2025-02-08 05:43:21,893 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2025-02-08 05:43:21,915 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-08 05:43:21,929 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2025-02-08 05:43:21,933 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\n",
      "2025-02-08 05:43:21,933 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2025-02-08 05:43:23,186 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\n",
      "Collecting wandb (from -r requirements.txt (line 1))\n",
      "Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting webdataset==0.2.100 (from -r requirements.txt (line 2))\n",
      "Downloading webdataset-0.2.100-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting braceexpand (from webdataset==0.2.100->-r requirements.txt (line 2))\n",
      "Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from webdataset==0.2.100->-r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from webdataset==0.2.100->-r requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting eval-type-backport (from wandb->-r requirements.txt (line 1))\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.15.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (5.9.8)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb->-r requirements.txt (line 1))\n",
      "Downloading setproctitle-1.3.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (71.0.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 1)) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 1))\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.9/site-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 1)) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2024.7.4)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 1))\n",
      "Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading webdataset-0.2.100-py3-none-any.whl (74 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 74.8/74.8 kB 11.8 MB/s eta 0:00:00\n",
      "Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.9 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20.9/20.9 MB 112.8 MB/s eta 0:00:00\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 207.6/207.6 kB 43.9 MB/s eta 0:00:00\n",
      "Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl (322 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 322.6/322.6 kB 60.8 MB/s eta 0:00:00\n",
      "Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading setproctitle-1.3.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 62.8/62.8 kB 18.1 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Collecting wandb (from -r requirements.txt (line 1))\n",
      "Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting webdataset==0.2.100 (from -r requirements.txt (line 2))\n",
      "Downloading webdataset-0.2.100-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting braceexpand (from webdataset==0.2.100->-r requirements.txt (line 2))\n",
      "Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from webdataset==0.2.100->-r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from webdataset==0.2.100->-r requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting eval-type-backport (from wandb->-r requirements.txt (line 1))\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.15.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (5.9.8)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb->-r requirements.txt (line 1))\n",
      "Downloading setproctitle-1.3.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (71.0.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 1)) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 1))\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.9/site-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 1)) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2024.7.4)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 1))\n",
      "Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading webdataset-0.2.100-py3-none-any.whl (74 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 74.8/74.8 kB 11.8 MB/s eta 0:00:00\n",
      "Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.9 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20.9/20.9 MB 106.7 MB/s eta 0:00:00\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 207.6/207.6 kB 44.7 MB/s eta 0:00:00\n",
      "Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl (322 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 322.6/322.6 kB 59.5 MB/s eta 0:00:00\n",
      "Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading setproctitle-1.3.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 62.8/62.8 kB 17.4 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: braceexpand, webdataset, smmap, setproctitle, sentry-sdk, eval-type-backport, docker-pycreds, gitdb, gitpython, wandb\n",
      "Installing collected packages: braceexpand, webdataset, smmap, setproctitle, sentry-sdk, eval-type-backport, docker-pycreds, gitdb, gitpython, wandb\n",
      "Successfully installed braceexpand-0.1.7 docker-pycreds-0.4.0 eval-type-backport-0.2.2 gitdb-4.0.12 gitpython-3.1.44 sentry-sdk-2.20.0 setproctitle-1.3.4 smmap-5.0.2 wandb-0.19.6 webdataset-0.2.100\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "[notice] A new release of pip is available: 24.1.2 -> 25.0\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2025-02-08 05:43:27,287 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2025-02-08 05:43:27,287 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2025-02-08 05:43:27,334 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-08 05:43:27,381 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-08 05:43:27,400 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\n",
      "2025-02-08 05:43:27,400 sagemaker-training-toolkit INFO     Creating SSH daemon.\n",
      "2025-02-08 05:43:27,404 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\n",
      "2025-02-08 05:43:27,405 sagemaker-training-toolkit INFO     Cannot connect to host algo-1 at port 22. Retrying...\n",
      "2025-02-08 05:43:27,405 sagemaker-training-toolkit INFO     Connection closed\n",
      "Successfully installed braceexpand-0.1.7 docker-pycreds-0.4.0 eval-type-backport-0.2.2 gitdb-4.0.12 gitpython-3.1.44 sentry-sdk-2.20.0 setproctitle-1.3.4 smmap-5.0.2 wandb-0.19.6 webdataset-0.2.100\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "[notice] A new release of pip is available: 24.1.2 -> 25.0\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2025-02-08 05:43:28,336 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2025-02-08 05:43:28,337 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2025-02-08 05:43:28,368 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-08 05:43:28,417 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-08 05:43:28,435 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\n",
      "2025-02-08 05:43:28,436 sagemaker-training-toolkit INFO     Waiting for MPI Master to create SSH daemon.\n",
      "2025-02-08 05:43:28,446 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\n",
      "2025-02-08 05:43:28,406 sagemaker-training-toolkit INFO     Cannot connect to host algo-1 at port 22. Retrying...\n",
      "2025-02-08 05:43:28,407 sagemaker-training-toolkit INFO     Connection closed\n",
      "2025-02-08 05:43:28,607 paramiko.transport INFO     Authentication (publickey) successful!\n",
      "2025-02-08 05:43:28,607 sagemaker-training-toolkit INFO     Can connect to host algo-2\n",
      "2025-02-08 05:43:28,607 sagemaker-training-toolkit INFO     MPI Master online, creating SSH daemon.\n",
      "2025-02-08 05:43:28,608 sagemaker-training-toolkit INFO     Writing environment variables to /etc/environment for the MPI process.\n",
      "2025-02-08 05:43:28,615 sagemaker-training-toolkit INFO     Waiting for MPI process to finish.\n",
      "2025-02-08 05:43:29,418 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\n",
      "2025-02-08 05:43:29,578 paramiko.transport INFO     Authentication (publickey) successful!\n",
      "2025-02-08 05:43:29,578 sagemaker-training-toolkit INFO     Can connect to host algo-1 at port 22\n",
      "2025-02-08 05:43:29,578 sagemaker-training-toolkit INFO     Connection closed\n",
      "2025-02-08 05:43:29,578 sagemaker-training-toolkit INFO     Worker algo-1 available for communication\n",
      "2025-02-08 05:43:29,579 sagemaker-training-toolkit INFO     Network interface name: eth0\n",
      "2025-02-08 05:43:29,579 sagemaker-training-toolkit INFO     Host: ['algo-2', 'algo-1']\n",
      "2025-02-08 05:43:29,627 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-08 05:43:29,646 sagemaker-training-toolkit INFO     instance type: ml.g4dn.xlarge\n",
      "2025-02-08 05:43:29,646 sagemaker-training-toolkit INFO     Env Hosts: ['algo-2', 'algo-1'] Hosts: ['algo-2:1', 'algo-1:1'] process_per_hosts: 1 num_processes: 2\n",
      "2025-02-08 05:43:29,674 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-08 05:43:29,695 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_distributed_dataparallel_custom_mpi_options\": \"\",\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": true,\n",
      "        \"sagemaker_instance_type\": \"ml.g4dn.xlarge\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-2\",\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-2\",\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 128,\n",
      "        \"class-weights-dict\": {\n",
      "            \"1\": 1.7004885993485341,\n",
      "            \"2\": 0.9083079599826012,\n",
      "            \"3\": 0.7832708177044261,\n",
      "            \"4\": 0.8799831436999579,\n",
      "            \"5\": 1.1137066666666666\n",
      "        },\n",
      "        \"debug\": false,\n",
      "        \"early-stopping-patience\": 1,\n",
      "        \"epochs\": 40,\n",
      "        \"lr-sched-step-size\": 10,\n",
      "        \"model-arch\": \"resnet34\",\n",
      "        \"opt-learning-rate\": 0.1,\n",
      "        \"opt-momentum\": 0.9,\n",
      "        \"opt-type\": \"sgd\",\n",
      "        \"test-data-path\": \"s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000001}.tar\",\n",
      "        \"test-data-size\": 1567,\n",
      "        \"train-data-path\": \"s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar\",\n",
      "        \"train-data-size\": 7308,\n",
      "        \"val-data-path\": \"s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000001}.tar\",\n",
      "        \"val-data-size\": 1566,\n",
      "        \"wandb\": false\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-2\",\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"p5-amazon-bin-job-20250207-233914\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-2\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://p5-amazon-bin-images-train/p5-amazon-bin-job-20250207-233914/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_early_stop\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-2\",\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_early_stop.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"batch-size\":128,\"class-weights-dict\":{\"1\":1.7004885993485341,\"2\":0.9083079599826012,\"3\":0.7832708177044261,\"4\":0.8799831436999579,\"5\":1.1137066666666666},\"debug\":false,\"early-stopping-patience\":1,\"epochs\":40,\"lr-sched-step-size\":10,\"model-arch\":\"resnet34\",\"opt-learning-rate\":0.1,\"opt-momentum\":0.9,\"opt-type\":\"sgd\",\"test-data-path\":\"s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000001}.tar\",\"test-data-size\":1567,\"train-data-path\":\"s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar\",\"train-data-size\":7308,\"val-data-path\":\"s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000001}.tar\",\"val-data-size\":1566,\"wandb\":false}\n",
      "SM_USER_ENTRY_POINT=train_early_stop.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.g4dn.xlarge\"}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[]\n",
      "SM_CURRENT_HOST=algo-2\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g4dn.xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-2\",\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=train_early_stop\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=4\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://p5-amazon-bin-images-train/p5-amazon-bin-job-20250207-233914/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.g4dn.xlarge\"},\"channel_input_dirs\":{},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-2\",\"algo-1\"],\"current_instance_type\":\"ml.g4dn.xlarge\",\"distribution_hosts\":[\"algo-2\",\"algo-1\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch-size\":128,\"class-weights-dict\":{\"1\":1.7004885993485341,\"2\":0.9083079599826012,\"3\":0.7832708177044261,\"4\":0.8799831436999579,\"5\":1.1137066666666666},\"debug\":false,\"early-stopping-patience\":1,\"epochs\":40,\"lr-sched-step-size\":10,\"model-arch\":\"resnet34\",\"opt-learning-rate\":0.1,\"opt-momentum\":0.9,\"opt-type\":\"sgd\",\"test-data-path\":\"s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000001}.tar\",\"test-data-size\":1567,\"train-data-path\":\"s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar\",\"train-data-size\":7308,\"val-data-path\":\"s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000001}.tar\",\"val-data-size\":1566,\"wandb\":false},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"is_smddprun_installed\":true,\"job_name\":\"p5-amazon-bin-job-20250207-233914\",\"log_level\":20,\"master_hostname\":\"algo-2\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://p5-amazon-bin-images-train/p5-amazon-bin-job-20250207-233914/source/sourcedir.tar.gz\",\"module_name\":\"train_early_stop\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_early_stop.py\"}\n",
      "SM_USER_ARGS=[\"--batch-size\",\"128\",\"--class-weights-dict\",\"1=1.7004885993485341,2=0.9083079599826012,3=0.7832708177044261,4=0.8799831436999579,5=1.1137066666666666\",\"--debug\",\"False\",\"--early-stopping-patience\",\"1\",\"--epochs\",\"40\",\"--lr-sched-step-size\",\"10\",\"--model-arch\",\"resnet34\",\"--opt-learning-rate\",\"0.1\",\"--opt-momentum\",\"0.9\",\"--opt-type\",\"sgd\",\"--test-data-path\",\"s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000001}.tar\",\"--test-data-size\",\"1567\",\"--train-data-path\",\"s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar\",\"--train-data-size\",\"7308\",\"--val-data-path\",\"s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000001}.tar\",\"--val-data-size\",\"1566\",\"--wandb\",\"False\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_HP_BATCH-SIZE=128\n",
      "SM_HP_CLASS-WEIGHTS-DICT={\"1\":1.7004885993485341,\"2\":0.9083079599826012,\"3\":0.7832708177044261,\"4\":0.8799831436999579,\"5\":1.1137066666666666}\n",
      "SM_HP_DEBUG=false\n",
      "SM_HP_EARLY-STOPPING-PATIENCE=1\n",
      "SM_HP_EPOCHS=40\n",
      "SM_HP_LR-SCHED-STEP-SIZE=10\n",
      "SM_HP_MODEL-ARCH=resnet34\n",
      "SM_HP_OPT-LEARNING-RATE=0.1\n",
      "SM_HP_OPT-MOMENTUM=0.9\n",
      "SM_HP_OPT-TYPE=sgd\n",
      "SM_HP_TEST-DATA-PATH=s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000001}.tar\n",
      "SM_HP_TEST-DATA-SIZE=1567\n",
      "SM_HP_TRAIN-DATA-PATH=s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar\n",
      "SM_HP_TRAIN-DATA-SIZE=7308\n",
      "SM_HP_VAL-DATA-PATH=s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000001}.tar\n",
      "SM_HP_VAL-DATA-SIZE=1566\n",
      "SM_HP_WANDB=false\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\n",
      "Invoking script with the following command:\n",
      "mpirun --host algo-2:1,algo-1:1 -np 2 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 2 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_HOMOGENEOUS=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.9/site-packages/gethostname.cpython-39-x86_64-linux-gnu.so -x SMDATAPARALLEL_SERVER_ADDR=algo-2 -x SMDATAPARALLEL_SERVER_PORT=7592 -x SAGEMAKER_INSTANCE_TYPE=ml.g4dn.xlarge smddprun /opt/conda/bin/python3.9 -m mpi4py train_early_stop.py --batch-size 128 --class-weights-dict 1=1.7004885993485341,2=0.9083079599826012,3=0.7832708177044261,4=0.8799831436999579,5=1.1137066666666666 --debug False --early-stopping-patience 1 --epochs 40 --lr-sched-step-size 10 --model-arch resnet34 --opt-learning-rate 0.1 --opt-momentum 0.9 --opt-type sgd --test-data-path s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000001}.tar --test-data-size 1567 --train-data-path s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar --train-data-size 7308 --val-data-path s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000001}.tar --val-data-size 1566 --wandb False\n",
      "Warning: Permanently added 'algo-1,10.0.128.134' (ECDSA) to the list of known hosts.\n",
      "[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:1,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:1,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:1,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "2025-02-08 05:43:30,620 sagemaker-training-toolkit INFO     Process[es]: [psutil.Process(pid=86, name='orted', status='sleeping', started='05:43:29')]\n",
      "2025-02-08 05:43:30,620 sagemaker-training-toolkit INFO     Orted process found [psutil.Process(pid=86, name='orted', status='sleeping', started='05:43:29')]\n",
      "2025-02-08 05:43:30,620 sagemaker-training-toolkit INFO     Waiting for orted process [psutil.Process(pid=86, name='orted', status='sleeping', started='05:43:29')]\n",
      "[1,mpirank:0,algo-1]<stdout>:DDP Mode\n",
      "[1,mpirank:0,algo-1]<stderr>:train_early_stop.py:23: DeprecationWarning: smdistributed.dataparallel.torch.dist is deprecated in the SageMaker distributed data parallel library v1.4.0+.Please use torch.distributed and specify 'smddp' as a backend when initializing process group as follows:torch.distributed.init_process_group(backend='smddp')For more information, see the library's API documentation at https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-modify-sdp-pt.html\n",
      "[1,mpirank:0,algo-1]<stderr>:  import smdistributed.dataparallel.torch.distributed as dist\n",
      "[1,mpirank:1,algo-2]<stdout>:DDP Mode\n",
      "[1,mpirank:1,algo-2]<stderr>:train_early_stop.py:23: DeprecationWarning: smdistributed.dataparallel.torch.dist is deprecated in the SageMaker distributed data parallel library v1.4.0+.Please use torch.distributed and specify 'smddp' as a backend when initializing process group as follows:torch.distributed.init_process_group(backend='smddp')For more information, see the library's API documentation at https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-modify-sdp-pt.html\n",
      "[1,mpirank:1,algo-2]<stderr>:  import smdistributed.dataparallel.torch.distributed as dist\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Bootstrap : Using eth0:10.0.155.90<0>\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO cudaDriverVersion 12040\n",
      "[1,mpirank:0,algo-1]<stdout>:NCCL version 2.14.3+cuda11.7\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO cudaDriverVersion 12040\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.155.90<0>\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Using network Socket\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Bootstrap : Using eth0:10.0.128.134<0>\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.128.134<0>\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Using network Socket\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 00/02 :    0   1\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 01/02 :    0   1\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:125 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 00/0 : 0[1e0] -> 1[1e0] [receive] via NET/Socket/0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:128 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 00/0 : 1[1e0] -> 0[1e0] [receive] via NET/Socket/0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:125 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 01/0 : 0[1e0] -> 1[1e0] [receive] via NET/Socket/0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:128 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 01/0 : 1[1e0] -> 0[1e0] [receive] via NET/Socket/0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 00/0 : 1[1e0] -> 0[1e0] [send] via NET/Socket/0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 00/0 : 0[1e0] -> 1[1e0] [send] via NET/Socket/0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 01/0 : 1[1e0] -> 0[1e0] [send] via NET/Socket/0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 01/0 : 0[1e0] -> 1[1e0] [send] via NET/Socket/0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Connected all rings\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Connected all trees\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Connected all rings\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Connected all trees\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO comm 0x562d2ba4a3a0 rank 1 nranks 2 cudaDev 0 busId 1e0 - Init COMPLETE\n",
      "[1,mpirank:1,algo-2]<stdout>:NCCL version 2.14.3+cuda11.7\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Using network Socket\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 00/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 01/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 02/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 03/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 04/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 05/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 06/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 07/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 08/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 09/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 10/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 11/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 12/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 13/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 14/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 15/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 16/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 17/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 18/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 19/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 20/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 21/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 22/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 23/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 24/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 25/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 26/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 27/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 28/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 29/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 30/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Channel 31/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Connected all rings\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO Connected all trees\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO comm 0x55a164726860 rank 0 nranks 2 cudaDev 0 busId 1e0 - Init COMPLETE\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Using network Socket\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 00/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 01/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 02/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 03/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 04/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 05/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 06/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 07/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 08/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 09/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 10/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 11/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 12/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 13/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 14/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 15/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 16/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 17/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 18/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 19/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 20/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 21/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 22/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 23/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 24/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 25/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 26/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 27/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 28/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 29/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 30/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Channel 31/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Connected all rings\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO Connected all trees\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-1:105:105 [0] NCCL INFO comm 0x562d2baf70b0 rank 0 nranks 1 cudaDev 0 busId 1e0 - Init COMPLETE\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-2:106:106 [0] NCCL INFO comm 0x55a1647bbe70 rank 0 nranks 1 cudaDev 0 busId 1e0 - Init COMPLETE\n",
      "[1,mpirank:0,algo-1]<stdout>:Running smdistributed.dataparallel v1.7.0\n",
      "[1,mpirank:0,algo-1]<stdout>:SMDDP: Multi node ENA mode\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸŸ¢ SageMkaer DDP is initialized.\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ‘‰ Total GPU count: 2\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ‘‰ Rank: 0, Local Rank: 0\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸŸ¢ SageMkaer DDP is initialized.\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ‘‰ Total GPU count: 2\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ‘‰ Rank: 1, Local Rank: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ‘‰ Device: cuda, Rank: 0, Local rank: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ‘‰ task.config:\n",
      "[1,mpirank:0,algo-1]<stdout>:{'batch_size': 128[1,mpirank:0,algo-1]<stdout>:,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'class_weights_dict':\n",
      "[1,mpirank:0,algo-1]<stdout>:{[1,mpirank:0,algo-1]<stdout>:1: 1.7004885993485341[1,mpirank:0,algo-1]<stdout>:,\n",
      "[1,mpirank:0,algo-1]<stdout>:                        [1,mpirank:0,algo-1]<stdout>:2:\n",
      "[1,mpirank:0,algo-1]<stdout>:0.9083079599826012,\n",
      "[1,mpirank:0,algo-1]<stdout>:                        [1,mpirank:0,algo-1]<stdout>:3: [1,mpirank:0,algo-1]<stdout>:0.7832708177044261,\n",
      "[1,mpirank:0,algo-1]<stdout>:                        4: [1,mpirank:0,algo-1]<stdout>:0.8799831436999579,\n",
      "[1,mpirank:0,algo-1]<stdout>:                        [1,mpirank:0,algo-1]<stdout>:5: 1.1137066666666666[1,mpirank:0,algo-1]<stdout>:},\n",
      "[1,mpirank:0,algo-1]<stdout>: 'debug': [1,mpirank:0,algo-1]<stdout>:False,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'device': device(type='cuda'),\n",
      "[1,mpirank:0,algo-1]<stdout>: 'early_stopping_patience': 1,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'epochs': 40,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'lr_sched_gamma': 0.5,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'lr_sched_step_size': 10,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'model_arch': 'resnet34',\n",
      "[1,mpirank:0,algo-1]<stdout>: 'model_dir': '/opt/ml/model',\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:'num_cpu': 4,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'opt_learning_rate': 0.1[1,mpirank:1,algo-2]<stdout>:ðŸ‘‰ Device: cuda, Rank: 1, Local rank: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'opt_momentum': 0.9,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'opt_type': 'sgd',\n",
      "[1,mpirank:0,algo-1]<stdout>: 'opt_weight_decay': 0.0001,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'output_data_dir': '/opt/ml/output/data',\n",
      "[1,mpirank:0,algo-1]<stdout>: 'test_data_path': [1,mpirank:0,algo-1]<stdout>:'s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000001}.tar',\n",
      "[1,mpirank:0,algo-1]<stdout>: 'test_data_size': 1567,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'test_shards': 2,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'train_data_path': 's3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar',\n",
      "[1,mpirank:0,algo-1]<stdout>: 'train_data_size': 7308,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'train_shards': 8,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'use_cuda': True,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'val_data_path': 's3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000001}.tar',\n",
      "[1,mpirank:0,algo-1]<stdout>: 'val_data_size': 1566,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'val_shards': 2,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'wandb': [1,mpirank:0,algo-1]<stdout>:False}\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ‘‰ Rank 0: Model resnet34 has been created successfully.\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ‘‰ Train Epoch: 0, Learning Rate: 0.2\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ‘‰ Rank 1: Model resnet34 has been created successfully.\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-08 05:43:37.134 algo-2:106 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-08 05:43:37.154 algo-1:105 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-08 05:43:37.486 algo-2:106 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-08 05:43:37.486 algo-2:106 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-08 05:43:37.487 algo-2:106 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-08 05:43:37.487 algo-2:106 INFO hook.py:259] Saving to /opt/ml/output/tensors\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-08 05:43:37.487 algo-2:106 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-08 05:43:37.509 algo-1:105 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-08 05:43:37.510 algo-1:105 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-08 05:43:37.510 algo-1:105 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-08 05:43:37.511 algo-1:105 INFO hook.py:259] Saving to /opt/ml/output/tensors\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-08 05:43:37.511 algo-1:105 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [128/3654 (4%)], Loss: 2.893206\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [128/3654 (4%)], Loss: 2.882558\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\n",
      "[1,mpirank:1,algo-2]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [256/3654 (7%)], Loss: 14.948893\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [256/3654 (7%)], Loss: 17.756199\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [384/3654 (11%)], Loss: 14.726310\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [384/3654 (11%)], Loss: 14.353333\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [512/3654 (14%)], Loss: 17.937725\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [512/3654 (14%)], Loss: 17.236588\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [640/3654 (18%)], Loss: 12.504326\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [640/3654 (18%)], Loss: 13.554504\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [768/3654 (21%)], Loss: 8.597149\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [768/3654 (21%)], Loss: 5.803978\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [896/3654 (25%)], Loss: 10.228502\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [896/3654 (25%)], Loss: 5.159139\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [1024/3654 (28%)], Loss: 6.494933\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [1024/3654 (28%)], Loss: 3.445840\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [1152/3654 (32%)], Loss: 3.502093\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [1152/3654 (32%)], Loss: 2.774545\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [1280/3654 (35%)], Loss: 2.654688\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [1280/3654 (35%)], Loss: 1.919989\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [1408/3654 (39%)], Loss: 3.521161\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [1408/3654 (39%)], Loss: 2.668336\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [1536/3654 (42%)], Loss: 2.639274\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [1536/3654 (42%)], Loss: 2.617745\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [1664/3654 (46%)], Loss: 2.092687\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [1664/3654 (46%)], Loss: 5.735764\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [1792/3654 (49%)], Loss: 5.089617\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [1792/3654 (49%)], Loss: 2.175226\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [1920/3654 (53%)], Loss: 1.977196\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [1920/3654 (53%)], Loss: 2.672393\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [2048/3654 (56%)], Loss: 2.842837\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [2048/3654 (56%)], Loss: 1.676436\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [2176/3654 (60%)], Loss: 1.693540\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [2176/3654 (60%)], Loss: 4.200427\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [2304/3654 (63%)], Loss: 1.845725\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [2304/3654 (63%)], Loss: 3.463280\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [2432/3654 (67%)], Loss: 1.657708\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [2432/3654 (67%)], Loss: 3.373415\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [2560/3654 (70%)], Loss: 2.970133\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [2560/3654 (70%)], Loss: 2.498808\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [2688/3654 (74%)], Loss: 1.977275\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [2688/3654 (74%)], Loss: 2.697310\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [2816/3654 (77%)], Loss: 3.123639\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [2816/3654 (77%)], Loss: 1.673330\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [2944/3654 (81%)], Loss: 2.113240\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [2944/3654 (81%)], Loss: 1.620418\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [3072/3654 (84%)], Loss: 1.662710\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [3072/3654 (84%)], Loss: 1.746984\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [3200/3654 (88%)], Loss: 2.036765\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [3200/3654 (88%)], Loss: 1.933203\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [3308/3654 (91%)], Loss: 1.876460\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [3308/3654 (91%)], Loss: 2.178197\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [3436/3654 (94%)], Loss: 2.103977\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [3436/3654 (94%)], Loss: 1.792298\n",
      "[1,mpirank:1,algo-2]<stdout>:ðŸ”¹ Train Epoch 0, Rank 1: [3564/3654 (98%)], Loss: 1.690451\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ”¹ Train Epoch 0, Rank 0: [3564/3654 (98%)], Loss: 1.798253\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fb9bfb7aaf0>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError\n",
      "[1,mpirank:0,algo-1]<stderr>:: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fa7009c0af0>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stdout>:âš ï¸ Early stopping broadcasting 28 from Rank 1...\n",
      "[1,mpirank:1,algo-2]<stdout>:âš ï¸ Early stopping at epoch 0 on Rank 1\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/test/test-shard-000001.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fb9bfb7aaf0>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.close()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError\n",
      "[1,mpirank:0,algo-1]<stderr>:: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/test/test-shard-000001.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ‘‰ VAL: Average loss: 134.4924, Accuracy: 318/1536 (20.70%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:âš ï¸ Early stopping broadcasting 2 from Rank 0...\n",
      "[1,mpirank:0,algo-1]<stdout>:âš ï¸ Early stopping at epoch 0 on Rank 0\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸŸ¢ Start testing...\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/test/test-shard-000001.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fb9bfb7aaf0>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.close()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/test/test-shard-000001.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ‘‰ TEST: Average loss: 134.4924, Accuracy: 318/1536 (20.70%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸŸ¢ Start saving the trained model...\n",
      "[1,mpirank:0,algo-1]<stdout>:ðŸ‘‰ Model saved at '/opt/ml/model/model.pth'\n",
      "2025-02-08 05:45:35,779 sagemaker-training-toolkit INFO     Invoked on_terminate from psutil.wait_for_procs\n",
      "2025-02-08 05:45:35,779 sagemaker-training-toolkit INFO     process psutil.Process(pid=86, name='orted', status='terminated', started='05:43:29') terminated with exit code None\n",
      "2025-02-08 05:45:35,780 sagemaker-training-toolkit INFO     Reporting status for ORTEd process. gone: [psutil.Process(pid=86, name='orted', status='terminated', started='05:43:29')] alive: []\n",
      "2025-02-08 05:45:35,780 sagemaker-training-toolkit INFO     Orted process exited\n",
      "2025-02-08 05:45:35,745 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2025-02-08 05:45:35,745 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2025-02-08 05:45:35,746 sagemaker-training-toolkit INFO     Begin writing status file from leader node to worker nodes\n",
      "2025-02-08 05:45:35,746 sagemaker-training-toolkit INFO     Start writing mpirun finished status to algo-1\n",
      "2025-02-08 05:45:35,925 sagemaker-training-toolkit INFO     output from subprocess run CompletedProcess(args=['ssh', 'algo-1', 'touch', '/tmp/done.algo-2'], returncode=0, stdout='', stderr='')\n",
      "2025-02-08 05:45:35,925 sagemaker-training-toolkit INFO     Finished writing status file\n",
      "2025-02-08 05:46:05,809 sagemaker-training-toolkit INFO     Begin looking for status file on algo-1\n",
      "2025-02-08 05:46:05,809 sagemaker-training-toolkit INFO     MPI training job status file found. Exit gracefully\n",
      "2025-02-08 05:46:05,809 sagemaker-training-toolkit INFO     End looking for status file\n",
      "2025-02-08 05:46:05,809 sagemaker-training-toolkit INFO     MPI process finished.\n",
      "2025-02-08 05:46:05,809 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "2025-02-08 05:46:05,952 sagemaker-training-toolkit INFO     Finished writing status file from leader node to worker nodes\n",
      "2025-02-08 05:46:05,952 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2025-02-08 05:46:08 Uploading - Uploading generated training model\n",
      "2025-02-08 05:46:26 Completed - Training job completed\n",
      "Training seconds: 772\n",
      "Billable seconds: 772\n",
      "CPU times: total: 14.1 s\n",
      "Wall time: 8min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from sagemaker.pytorch import PyTorch\n",
    "from datetime import datetime\n",
    "data_base_path = \"s3://p5-amazon-bin-images/webdataset/\"\n",
    "train_data_path = data_base_path + \"train/train-shard-{000000..000007}.tar\"\n",
    "val_data_path = data_base_path + \"val/val-shard-{000000..000001}.tar\"\n",
    "test_data_path = data_base_path + \"test/test-shard-{000000..000001}.tar\"\n",
    "print(train_data_path)\n",
    "output_path = \"s3://p5-amazon-bin-images-train/\"  \n",
    "## Manually set dataset sizes hyperparameters\n",
    "l = 10441  ## 10K dataset\n",
    "split_ratio=[0.7, 0.15, 0.15]\n",
    "train_data_size = int(l*split_ratio[0])\n",
    "val_data_size = int(l*split_ratio[1])\n",
    "test_data_size = l - train_data_size - val_data_size\n",
    "print(f\"train_size: {train_data_size}, val_size: {val_data_size}, test_size: {test_data_size}\")\n",
    "## s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar\n",
    "## train_size: 7308, val_size: 1566, test_size: 1567\n",
    "hyperparameters = {\n",
    "    'epochs': 40,   \n",
    "    'batch-size': 128,   \n",
    "    'opt-type': 'sgd',         ## ðŸ‘‰ SGD optimizer\n",
    "    'opt-momentum': 0.9,       ## ðŸ‘‰ SGD optimizer\n",
    "    'opt-learning-rate': 0.1,  ## ðŸ‘‰ SGD optimizer\n",
    "    # 'opt-weight-decay': 1e-4,  \n",
    "    'lr-sched-step-size': 10,  ## ðŸ‘‰ optimizer learning rate scheduler\n",
    "    # 'lr-sched-gamma': 0.5,\n",
    "    'early-stopping-patience': 1,  ## set larger than epochs if no early stopping\n",
    "    'model-arch': 'resnet34', \n",
    "    'wandb': False,  \n",
    "    'debug': False, \n",
    "## input data \n",
    "    \"train-data-path\": train_data_path,\n",
    "    \"val-data-path\": val_data_path,\n",
    "    \"test-data-path\": test_data_path,\n",
    "    \"train-data-size\": train_data_size, \n",
    "    \"val-data-size\": val_data_size,\n",
    "    \"test-data-size\": test_data_size,\n",
    "    \"class-weights-dict\": {\n",
    "        1: 1.7004885993485341, \n",
    "        2: 0.9083079599826012, \n",
    "        3: 0.7832708177044261, \n",
    "        4: 0.8799831436999579, \n",
    "        5: 1.1137066666666666\n",
    "    },\n",
    "}\n",
    "estimator = PyTorch(\n",
    "    entry_point='train_early_stop.py',  # Your training script that defines the ResNet50 model and training loop\n",
    "    source_dir='../scripts_train',  # Directory where your script and dependencies are stored\n",
    "    role=sagemaker_role_arn,\n",
    "    framework_version='1.13.1',  # Use the PyTorch version you need\n",
    "    py_version='py39',\n",
    "    instance_count=2,  ## multi-instance training, Udacity account level limit 2\n",
    "    instance_type='ml.g4dn.xlarge',  ## 16GB, 1 GPU per instance\n",
    "    output_path=output_path,  ## if not specify, output to the sagemaker default bucket\n",
    "    hyperparameters=hyperparameters,\n",
    "    distribution={\"smdistributed\": {\"dataparallel\": { \"enabled\": True}}},  # mpirun, activates SMDDP AllReduce OR AllGather\n",
    ") \n",
    "job_name = f\"p5-amazon-bin-job-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "estimator.fit(\n",
    "    wait=True,  \n",
    "    job_name=job_name, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "response = sagemaker_client.describe_training_job(TrainingJobName=job_name) # type: ignore\n",
    "status = response['TrainingJobStatus']\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tensor_early_stop = torch.tensor(0, dtype=torch.int32)\n",
    "tensor_early_stop = 1  ## âš ï¸\n",
    "print(tensor_early_stop, type(tensor_early_stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âš ï¸ Issue: \n",
    "\n",
    "```\n",
    " terminate called after throwing an instance of ':SMDDPTimeoutError:'\n",
    " what()\n",
    " #011Timeout: A call to 'allGather' has taken over 120.000000 seconds. Terminating the distributed job.It might be one of the workers failed during forward and backward propagation and failed to call \"allGather\".\n",
    " #011Extend timeout using dist.init_process_group(timeout=timedelta(minutes=60)\n",
    " #011Extend timeout using dist.init(timeout=timedelta(minutes=60)\n",
    "```\n",
    "\n",
    "âš ï¸ Issue: \n",
    "```\n",
    " #011Timeout: A call to 'broadcast' has taken over 120.000000 seconds. Terminating the distributed job.It might be one of the workers failed during forward and backward propagation and failed to call \"broadcast\".\n",
    " #011Extend timeout using dist.init_process_group(timeout=timedelta(minutes=60)\n",
    " ...\n",
    " #011Timeout: A call to 'allReduce' has taken over 120.000000 seconds. Terminating the distributed job.It might be one of the workers failed during forward and backward propagation and failed to call \"allReduce\".\n",
    "```\n",
    "\n",
    "âš ï¸ Issue:\n",
    "```\n",
    "[1,mpirank:1,algo-2]<stdout>:  File \"train_early_stop.py\", line 449, in main\n",
    "[1,mpirank:1,algo-2]<stdout>:    dist.broadcast(braodcast_early_stop, src=0)  ## one to all, src is the process rank\n",
    "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/smdistributed/dataparallel/torch/distributed.py\", line 156, in wrapper\n",
    "[1,mpirank:1,algo-2]<stdout>:    return func(*args, **kwargs)\n",
    "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/smdistributed/dataparallel/__init__.py\", line 58, in wrapper\n",
    "[1,mpirank:1,algo-2]<stdout>:    return func(*args, **kwargs)\n",
    "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/smdistributed/dataparallel/torch/distributed.py\", line 200, in broadcast\n",
    "[1,mpirank:1,algo-2]<stdout>:    return torchdst.broadcast(tensor, src=src, group=None, async_op=async_op)\n",
    "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py\", line 1408, in broadcast\n",
    "[1,mpirank:1,algo-2]<stdout>:    work.wait()\n",
    "[1,mpirank:1,algo-2]<stdout>:RuntimeError: Timeout: A call to a collective SMDDP operation has taken over 120 seconds. Terminating the distributed job.\n",
    "[1,mpirank:1,algo-2]<stderr>:terminate called after throwing an instance of '--------------------------------------------------------------------------\n",
    "MPI_ABORT was invoked on rank 1 in communicator MPI COMMUNICATOR 4 DUP FROM 0\n",
    "```\n",
    "\n",
    "âš ï¸ Issue:\n",
    "\n",
    "```\n",
    "[1,mpirank:1,algo-2]<stdout>:  File \"train_early_stop.py\", line 450, in main\n",
    "[1,mpirank:1,algo-2]<stdout>:    dist.all_reduce(broadcast_early_stop, op=torch.distributed.ReduceOp.SUM)\n",
    "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/smdistributed/dataparallel/torch/distributed.py\", line 156, in wrapper\n",
    "[1,mpirank:1,algo-2]<stdout>:    return func(*args, **kwargs)\n",
    "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/smdistributed/dataparallel/__init__.py\", line 58, in wrapper\n",
    "[1,mpirank:1,algo-2]<stdout>:    return func(*args, **kwargs)\n",
    "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/smdistributed/dataparallel/torch/distributed.py\", line 192, in all_reduce\n",
    "[1,mpirank:1,algo-2]<stdout>:    op=ReduceOpMap[op],\n",
    "[1,mpirank:1,algo-2]<stdout>:TypeError: __eq__(): incompatible function arguments. The following argument types are supported:\n",
    "[1,mpirank:1,algo-2]<stdout>:    1. (self: torch._C._distributed_c10d.ReduceOp, arg0: c10d::ReduceOp::RedOpType) -> bool\n",
    "[1,mpirank:1,algo-2]<stdout>:    2. (self: torch._C._distributed_c10d.ReduceOp, arg0: torch._C._distributed_c10d.ReduceOp) -> bool\n",
    "[1,mpirank:1,algo-2]<stdout>:\n",
    "[1,mpirank:1,algo-2]<stdout>:Invoked with: <torch.distributed.distributed_c10d.ReduceOp object at 0x7f52fa00e8b0>, 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "awsmle_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
