{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notebook created by nov05 on 2024-12-29\n",
    "* It was run locally with conda env `sagemaker_py310`.  \n",
    "\n",
    "---   \n",
    "* View the S3 bucket in your account   \n",
    "    https://s3.console.aws.amazon.com/s3/buckets/aft-vbi-pds\n",
    "* [Docs > Models and pre-trained weights > ResNet > resnet34](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet34.html)  \n",
    "* GitHub gist [code snippets](https://gist.github.com/nov05/95cb7edcbe2e8bb68c9d29bdc00b9ca8)   \n",
    "\n",
    "* Check [SageMaker AI Pricing](https://aws.amazon.com/sagemaker-ai/pricing/) > On-Demand Pricing > Training  \n",
    "    | Instance Type      | vCPU | Memory  | Price per Hour |\n",
    "    |--------------------|------|---------|----------------|\n",
    "    | ml.g4dn.xlarge      | 4    | 16 GiB  | $0.736         |\n",
    "    |ml.p3.2xlarge\t| 8\t| 61 GiB\t| $3.825 | \n",
    "\n",
    "* Documentation > Amazon SageMaker > Developer Guide   \n",
    "  [**Use the PyTorch framework estimators in the SageMaker Python SDK**](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-framework-estimator.html)    \n",
    "\n",
    "* sagemaker 2.239.0  \n",
    "  [**PyTorch Guide to SageMaker’s distributed data parallel library**](https://sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1.0.0/smd_data_parallel_pytorch.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\github\\\\udacity-nd009t-capstone-starter\\\\starter'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## windows cmd to launch notepad to edit aws credential file\n",
    "# !notepad C:\\Users\\guido\\.aws\\config\n",
    "!notepad C:\\Users\\guido\\.aws\\credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\pydantic\\_internal\\_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/08/25 03:35:51] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\botocore\\credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\botocore\\credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/08/25 03:35:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=831461;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\botocore\\credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=552856;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\botocore\\credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\guido\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/08/25 03:35:52] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\botocore\\credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\botocore\\credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/08/25 03:35:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=582718;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\botocore\\credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=405955;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\botocore\\credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/08/25 03:35:56] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> Couldn't call <span style=\"color: #008700; text-decoration-color: #008700\">'get_role'</span> to get Role ARN from role name voclabs to get <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py#5971\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5971</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Role path.                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/08/25 03:35:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m Couldn't call \u001b[38;2;0;135;0m'get_role'\u001b[0m to get Role ARN from role name voclabs to get \u001b]8;id=202352;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=565470;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py#5971\u001b\\\u001b[2m5971\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         Role path.                                                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current AWS Account ID: 570668189909\n",
      "AWS Region: us-east-1\n",
      "Default Bucket: sagemaker-us-east-1-570668189909\n",
      "Role voclabs ARN: arn:aws:iam::570668189909:role/voclabs\n",
      "SageMaker Role ARN: arn:aws:iam::570668189909:role/service-role/AmazonSageMaker-ExecutionRole-20250126T194519\n"
     ]
    }
   ],
   "source": [
    "## reset the session after updating credentials\n",
    "import boto3 # type: ignore\n",
    "boto3.DEFAULT_SESSION = None\n",
    "import sagemaker # type: ignore\n",
    "from sagemaker import get_execution_role # type: ignore\n",
    "\n",
    "# Extract and print the account ID\n",
    "sts_client = boto3.client('sts')\n",
    "response = sts_client.get_caller_identity() \n",
    "account_id = response['Account']\n",
    "\n",
    "role_arn = get_execution_role()  ## get role ARN\n",
    "if 'AmazonSageMaker-ExecutionRole' not in role_arn:\n",
    "    ## Go to \"IAM - Roles\", search for \"SageMaker\", find the execution role.\n",
    "    voclabs_role_arn = role_arn\n",
    "    sagemaker_role_arn = \"arn:aws:iam::570668189909:role/service-role/AmazonSageMaker-ExecutionRole-20250126T194519\"\n",
    "session = sagemaker.Session()  ## \"default\"\n",
    "region = session.boto_region_name\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "print(f\"Current AWS Account ID: {account_id}\")\n",
    "print(\"AWS Region: {}\".format(region))\n",
    "print(\"Default Bucket: {}\".format(bucket))\n",
    "print(f\"Role voclabs ARN: {voclabs_role_arn}\") ## If local, Role ARN: arn:aws:iam::807711953667:role/voclabs\n",
    "print(\"SageMaker Role ARN: {}\".format(sagemaker_role_arn)) \n",
    "\n",
    "## generate secrets.env. remember to add it to .gitignore  \n",
    "import wandb\n",
    "wandb.sagemaker_auth(path=\"../secrets\") \n",
    "\n",
    "## get my own AWS account info\n",
    "def get_secrets(name):\n",
    "    path = '../secrets/' + name\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            return line.strip()\n",
    "aws_account_number = get_secrets('aws_account_number')\n",
    "aws_account_profile = get_secrets('aws_account_profile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👉 **Data Preparation** (Run only once)\n",
    "**TODO:** Run the cell below to download the data.\n",
    "\n",
    "The cell below creates a folder called `data`, downloads training data and arranges it in subfolders. Each of these subfolders contain images where the number of objects is equal to the name of the folder. For instance, all images in folder `1` has images with 1 object in them. Images are not divided into training, testing or validation sets. If you feel like the number of samples are not enough, you can always download more data (instructions for that can be found [here](https://registry.opendata.aws/amazon-bin-imagery/)). However, we are not assessing you on the accuracy of your final trained model, but how you create your machine learning engineering pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* View the S3 bucket in your account   \n",
    "    https://s3.console.aws.amazon.com/s3/buckets/aft-vbi-pds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "\n",
    "def download_and_arrange_data(\n",
    "        prefix='bin-images', \n",
    "        file_extension='.jpg',\n",
    "        download_dir='../data/bin-images',\n",
    "        partition=True):\n",
    "    \n",
    "    s3_client = boto3.client('s3', config=Config(signature_version=UNSIGNED))  ## public access\n",
    "\n",
    "    ## There are 140536 image file names in the list. \n",
    "    with open('file_list.json', 'r') as f:\n",
    "        d = json.load(f)\n",
    "\n",
    "    for k, v in d.items():  ## There are 5 items (for 5 classes) in the JSON file.\n",
    "        print(f\"Downloading images/metadata of images with {k} object...\")\n",
    "        if partition:\n",
    "            download_dir = os.path.join(download_dir, k)\n",
    "        if not os.path.exists(download_dir):\n",
    "            os.makedirs(download_dir)\n",
    "        for file_path in tqdm(v):\n",
    "            file_name = os.path.basename(file_path).split('.')[0] + file_extension\n",
    "            s3_client.download_file(\n",
    "                'aft-vbi-pds', \n",
    "                prefix+'/'+file_name,  ## e.g. metadata/100313.json\n",
    "                download_dir+'/'+file_name)\n",
    "            \n",
    "## download the 10K-dataset metadata, 17.9 MB, 56m 57.4s\n",
    "download_and_arrange_data(\n",
    "    prefix='metadata', \n",
    "    file_extension='.json',\n",
    "    download_dir='../data/metadata',\n",
    "    partition=False)\n",
    "print(\"total metadata file number:\", 1228 + 2299 + 2666 + 2373 + 1875)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Downloading images/metadata of images with 1 object...\n",
    "100%|██████████| 1228/1228 [06:36<00:00,  3.09it/s]\n",
    "Downloading images/metadata of images with 2 object...\n",
    "100%|██████████| 2299/2299 [12:38<00:00,  3.03it/s]\n",
    "Downloading images/metadata of images with 3 object...\n",
    "100%|██████████| 2666/2666 [14:35<00:00,  3.04it/s]\n",
    "Downloading images/metadata of images with 4 object...\n",
    "100%|██████████| 2373/2373 [12:54<00:00,  3.06it/s]\n",
    "Downloading images/metadata of images with 5 object...\n",
    "100%|██████████| 1875/1875 [10:11<00:00,  3.07it/s]\n",
    "\n",
    "total metadata file number: 10441\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👉 **Convert 10K-dataset on S3 to WebDataset tar files with SageMaker ScriptProcessor on a custome image** (Run only once) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/25 17:55:50] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating processing-job with name                                      <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\sagemaker_py310\\lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\sagemaker_py310\\lib\\site-packages\\sagemaker\\session.py#1575\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1575</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         p5-amazon-bin-images-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-01-31-23-55-46-542                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/25 17:55:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating processing-job with name                                      \u001b]8;id=28680;file://d:\\Users\\guido\\miniconda3\\envs\\sagemaker_py310\\lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=800486;file://d:\\Users\\guido\\miniconda3\\envs\\sagemaker_py310\\lib\\site-packages\\sagemaker\\session.py#1575\u001b\\\u001b[2m1575\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         p5-amazon-bin-images-\u001b[1;36m2025\u001b[0m-01-31-23-55-46-542                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................Starting data processing...\n",
      "🟢 File list successfully loaded from s3://p5-amazon-bin-images/file_list.json\n",
      "    Total number of image files: 10441\n",
      "# writing train-shard-000000.tar 0 0.0 GB 0\n",
      "# writing train-shard-000001.tar 1000 0.1 GB 1000\n",
      "# writing train-shard-000002.tar 1000 0.1 GB 2000\n",
      "# writing train-shard-000003.tar 1000 0.1 GB 3000\n",
      "# writing train-shard-000004.tar 1000 0.1 GB 4000\n",
      "# writing train-shard-000005.tar 1000 0.1 GB 5000\n",
      "# writing train-shard-000006.tar 1000 0.1 GB 6000\n",
      "# writing train-shard-000007.tar 1000 0.1 GB 7000\n",
      "🟢 Successfully uploaded shard files to s3://p5-amazon-bin-images/webdataset/train/:\n",
      "    ['train-shard-000000.tar', 'train-shard-000001.tar', 'train-shard-000002.tar', 'train-shard-000003.tar', 'train-shard-000004.tar', 'train-shard-000005.tar', 'train-shard-000006.tar', 'train-shard-000007.tar']\n",
      "# writing val-shard-000000.tar 0 0.0 GB 0\n",
      "# writing val-shard-000001.tar 1000 0.1 GB 1000\n",
      "🟢 Successfully uploaded shard files to s3://p5-amazon-bin-images/webdataset/val/:\n",
      "    ['val-shard-000000.tar', 'val-shard-000001.tar']\n",
      "# writing test-shard-000000.tar 0 0.0 GB 0\n",
      "# writing test-shard-000001.tar 1000 0.1 GB 1000\n",
      "🟢 Successfully uploaded shard files to s3://p5-amazon-bin-images/webdataset/test/:\n",
      "    ['test-shard-000000.tar', 'test-shard-000001.tar']\n",
      "\n",
      "CPU times: total: 27.6 s\n",
      "Wall time: 15min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nIt took about 13 minutes to process 10.4K files (1.2 GB). If we keep 1K files per shard, \\nprocessing 500K files could take around 11 hours. I’ll probably increase it to 10K \\nfiles per shard, which would make each tar file around 1 GB and speed up the process.\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## TODO: Perform any data cleaning or data preprocessing\n",
    "## This cell shuffle then split the 10K dataset to train, val, and test.  \n",
    "## And convert the datasets to WebDataset tar files for SageMaker FastFile input mode.\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "processor = ScriptProcessor(\n",
    "    command=['python3'],\n",
    "    ## You can use a custom image or use the default SageMaker image\n",
    "    ## You can pull from AWS ECR or DockerHub\n",
    "    image_uri=f'{aws_account_number}.dkr.ecr.us-east-1.amazonaws.com/udacity/p5-amazon-bin-images:latest', \n",
    "    role=sagemaker_role_arn,  # Execution role\n",
    "    instance_count=1,\n",
    "    instance_type='ml.t3.large',  # Use the appropriate instance type\n",
    "    volume_size_in_gb=10,  # Minimal disk space since we're streaming\n",
    "    base_job_name='p5-amazon-bin-images' \n",
    ")\n",
    "processor.run(\n",
    "    code='../scripts_process/convert_to_webdataset_10k.py',  # process the 10K files in the list\n",
    "    arguments=[\n",
    "        '--SM_INPUT_BUCKET', 'aft-vbi-pds',\n",
    "        '--SM_INPUT_PREFIX_IMAGES', 'bin-images/',\n",
    "        '--SM_INPUT_PREFIX_METADATA', 'metadata/',\n",
    "        '--SM_OUTPUT_BUCKET', 'p5-amazon-bin-images',\n",
    "        '--SM_OUTPUT_PREFIX', 'webdataset/',\n",
    "    ]\n",
    ")\n",
    "## It took about 13 minutes to process 10.4K files (1.2 GB). If we keep 1K files per shard, \n",
    "## processing 500K files could take around 11 hours. I’ll probably increase it to 10K \n",
    "## files per shard, which would make each tar file around 1 GB and speed up the process.\n",
    "## CPU times: total: 21.9 s\n",
    "## Wall time: 12min 58s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👉 **Dataset**  \n",
    "\n",
    "**TODO:** Explain what dataset you are using for this project. Give a small overview of the classes, class distributions etc that can help anyone not familiar with the dataset get a better understanding of it. You can find more information about the data [here](https://registry.opendata.aws/amazon-bin-imagery/).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar\n",
      "train_size: 7308, val_size: 1566, test_size: 1567\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "# from sagemaker.inputs import TrainingInput\n",
    "data_base_path = \"s3://p5-amazon-bin-images/webdataset/\"\n",
    "# train_data = TrainingInput(data_base_path + \"train/\", \n",
    "#                            content_type=\"application/x-tar\")\n",
    "# val_data = TrainingInput(data_base_path + \"val/\", \n",
    "#                          content_type=\"application/x-tar\")\n",
    "# test_data = TrainingInput(data_base_path + \"test/\", \n",
    "#                           content_type=\"application/x-tar\")\n",
    "train_data_path = data_base_path + \"train/train-shard-{000000..000007}.tar\"\n",
    "val_data_path = data_base_path + \"val/val-shard-{000000..000001}.tar\"\n",
    "test_data_path = data_base_path + \"test/test-shard-{000000..000001}.tar\"\n",
    "print(train_data_path)\n",
    "## ⚠️ don't use prefix in output_path, cause source folder will be created \n",
    "## at bucket level, while other folders, e.g. debug-output, at prefix levle.\n",
    "output_path = \"s3://p5-amazon-bin-images-train/\"  \n",
    "\n",
    "## Manually set dataset sizes hyperparameters\n",
    "l = 10441\n",
    "split_ratio=[0.7, 0.15, 0.15]\n",
    "train_data_size = int(l*split_ratio[0])\n",
    "val_data_size = int(l*split_ratio[1])\n",
    "test_data_size = l - train_data_size - val_data_size\n",
    "print(f\"train_size: {train_data_size}, val_size: {val_data_size}, test_size: {test_data_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👉 **Model Training (Distributed Data Parallel)**  \n",
    "\n",
    "**TODO:** This is the part where you can train a model. The type or architecture of the model you use is not important.   \n",
    "**Note:** You will need to use the `train.py` script to train your model.\n",
    "\n",
    "* Official document: [SageMaker distributed data parallel (SDP) with PyTorch](https://sagemaker-examples.readthedocs.io/en/latest/training/distributed_training/index.html#pytorch-distributed)   \n",
    "\n",
    "* ⚠️ [Traning issues](https://gist.github.com/nov05/1bdc15eda0e781640b46ab28d38f45bd)   \n",
    "* Training times\n",
    "    * Train 2 epochs, val, test data sizes: 2K, 1K, 1K\n",
    "        ```\n",
    "        2025-02-06 22:26:36 Completed - Training job completed\n",
    "        Training seconds: 874\n",
    "        Billable seconds: 874\n",
    "        CPU times: total: 14 s\n",
    "        Wall time: 8min 45s\n",
    "        ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/08/25 04:11:51] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> Framework profiling will be deprecated from tensorflow <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.12</span> and     <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\deprecations.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">deprecations.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\deprecations.py#34\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         pytorch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span> in sagemaker&gt;=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>.                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         See: <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/v2.html</span> for         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         details.                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/08/25 04:11:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m Framework profiling will be deprecated from tensorflow \u001b[1;36m2.12\u001b[0m and     \u001b]8;id=363763;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\deprecations.py\u001b\\\u001b[2mdeprecations.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=673373;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\deprecations.py#34\u001b\\\u001b[2m34\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         pytorch \u001b[1;36m2.0\u001b[0m in sagemaker>=\u001b[1;36m2\u001b[0m.                                        \u001b[2m                  \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         See: \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/v2.html\u001b[0m for         \u001b[2m                  \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         details.                                                            \u001b[2m                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO: Declare your model training hyperparameter.\n",
    "#NOTE: You do not need to do hyperparameter tuning. You can use fixed hyperparameter values\n",
    "from sagemaker.debugger import (\n",
    "    Rule,\n",
    "## debugger\n",
    "    DebuggerHookConfig,\n",
    "    rule_configs,\n",
    "## profiler \n",
    "    ProfilerRule,\n",
    "    ProfilerConfig,\n",
    "    FrameworkProfile\n",
    ")\n",
    "## SageMaker will automatically append these as command-line arguments  \n",
    "hyperparameters = {\n",
    "    'epochs': 40,   \n",
    "    'batch-size': 128,  ## ⚠️ 256 causes ml.g4dn.xlarge memory issue\n",
    "    'opt-type': 'adamw',\n",
    "    'opt-learning-rate': 1e-4,  \n",
    "    'opt-weight-decay': 1e-5,  \n",
    "    'lr-sched-step-size': 5,  \n",
    "    'lr-sched-gamma': 0.5,\n",
    "    'early-stopping-patience': 5,\n",
    "    'model-arch': 'resnet34', \n",
    "    'wandb': True,  \n",
    "    'debug': False, \n",
    "## input data \n",
    "    \"train-data-path\": train_data_path,\n",
    "    \"val-data-path\": val_data_path,\n",
    "    \"test-data-path\": test_data_path,\n",
    "    \"train-data-size\": train_data_size, \n",
    "    \"val-data-size\": val_data_size,\n",
    "    \"test-data-size\": test_data_size,\n",
    "    \"num-classes\": 5,\n",
    "    # \"class-weights-dict\": {\n",
    "    #     1: 1.7004885993485341, \n",
    "    #     2: 0.9083079599826012, \n",
    "    #     3: 0.7832708177044261, \n",
    "    #     4: 0.8799831436999579, \n",
    "    #     5: 1.1137066666666666\n",
    "    # },\n",
    "}\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "    Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "]\n",
    "hook_config = DebuggerHookConfig(\n",
    "    hook_parameters={\n",
    "        \"train.save_interval\": \"100\", \n",
    "        \"eval.save_interval\": \"10\"\n",
    "    }\n",
    ")\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, \n",
    "    framework_profile_params=FrameworkProfile(num_steps=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/08/25 04:12:48] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/08/25 04:12:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=225654;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=600298;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/08/25 04:12:49] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> image_uri is not presented, retrieving image_uri based on            <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py#679\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">679</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         instance_type, framework etc.                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/08/25 04:12:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m image_uri is not presented, retrieving image_uri based on            \u001b]8;id=517720;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=883194;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py#679\u001b\\\u001b[2m679\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         instance_type, framework etc.                                        \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name: p5-amazon-bin-job-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20250208</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">041248</span>     <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name: p5-amazon-bin-job-\u001b[1;36m20250208\u001b[0m-\u001b[1;36m041248\u001b[0m     \u001b]8;id=549938;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=348890;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-08 10:12:44 Starting - Starting the training job...\n",
      "2025-02-08 10:12:59 Starting - Preparing the instances for training...\n",
      "2025-02-08 10:13:39 Downloading - Downloading input data...\n",
      "2025-02-08 10:14:04 Downloading - Downloading the training image...............\n",
      "2025-02-08 10:17:06 Training - Training image download completed. Training in progress.bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "/opt/conda/lib/python3.9/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "/opt/conda/lib/python3.9/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n",
      "2025-02-08 10:17:12,866 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2025-02-08 10:17:12,887 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-08 10:17:12,900 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2025-02-08 10:17:12,903 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\n",
      "2025-02-08 10:17:12,903 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2025-02-08 10:17:14,123 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\n",
      "Collecting wandb (from -r requirements.txt (line 1))\n",
      "Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting webdataset==0.2.100 (from -r requirements.txt (line 2))\n",
      "Downloading webdataset-0.2.100-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting braceexpand (from webdataset==0.2.100->-r requirements.txt (line 2))\n",
      "Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from webdataset==0.2.100->-r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from webdataset==0.2.100->-r requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting eval-type-backport (from wandb->-r requirements.txt (line 1))\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.15.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (5.9.8)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb->-r requirements.txt (line 1))\n",
      "Downloading setproctitle-1.3.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (71.0.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 1)) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 1))\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.9/site-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 1)) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2024.7.4)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 1))\n",
      "Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading webdataset-0.2.100-py3-none-any.whl (74 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 74.8/74.8 kB 11.5 MB/s eta 0:00:00\n",
      "Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.9 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.9/20.9 MB 99.4 MB/s eta 0:00:00\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.6/207.6 kB 40.6 MB/s eta 0:00:00\n",
      "Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl (322 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 322.6/322.6 kB 61.5 MB/s eta 0:00:00\n",
      "Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading setproctitle-1.3.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.8/62.8 kB 14.7 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: braceexpand, webdataset, smmap, setproctitle, sentry-sdk, eval-type-backport, docker-pycreds, gitdb, gitpython, wandb\n",
      "Successfully installed braceexpand-0.1.7 docker-pycreds-0.4.0 eval-type-backport-0.2.2 gitdb-4.0.12 gitpython-3.1.44 sentry-sdk-2.20.0 setproctitle-1.3.4 smmap-5.0.2 wandb-0.19.6 webdataset-0.2.100\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "[notice] A new release of pip is available: 24.1.2 -> 25.0\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2025-02-08 10:17:18,157 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2025-02-08 10:17:18,157 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2025-02-08 10:17:18,204 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-08 10:17:18,249 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-08 10:17:18,267 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\n",
      "2025-02-08 10:17:18,268 sagemaker-training-toolkit INFO     Creating SSH daemon.\n",
      "2025-02-08 10:17:18,271 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\n",
      "2025-02-08 10:17:18,272 sagemaker-training-toolkit INFO     Cannot connect to host algo-2 at port 22. Retrying...\n",
      "2025-02-08 10:17:18,272 sagemaker-training-toolkit INFO     Connection closed\n",
      "2025-02-08 10:17:19,274 sagemaker-training-toolkit INFO     Cannot connect to host algo-2 at port 22. Retrying...\n",
      "2025-02-08 10:17:19,274 sagemaker-training-toolkit INFO     Connection closed\n",
      "2025-02-08 10:17:20,276 sagemaker-training-toolkit INFO     Cannot connect to host algo-2 at port 22. Retrying...\n",
      "2025-02-08 10:17:20,276 sagemaker-training-toolkit INFO     Connection closed\n",
      "bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "/opt/conda/lib/python3.9/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "/opt/conda/lib/python3.9/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n",
      "2025-02-08 10:17:16,236 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2025-02-08 10:17:16,257 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-08 10:17:16,270 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2025-02-08 10:17:16,274 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\n",
      "2025-02-08 10:17:16,274 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2025-02-08 10:17:17,444 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\n",
      "Collecting wandb (from -r requirements.txt (line 1))\n",
      "Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting webdataset==0.2.100 (from -r requirements.txt (line 2))\n",
      "Downloading webdataset-0.2.100-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting braceexpand (from webdataset==0.2.100->-r requirements.txt (line 2))\n",
      "Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from webdataset==0.2.100->-r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from webdataset==0.2.100->-r requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting eval-type-backport (from wandb->-r requirements.txt (line 1))\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.15.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (5.9.8)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb->-r requirements.txt (line 1))\n",
      "Downloading setproctitle-1.3.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (71.0.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 1)) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 1))\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.9/site-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 1)) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2024.7.4)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 1))\n",
      "Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading webdataset-0.2.100-py3-none-any.whl (74 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 74.8/74.8 kB 14.2 MB/s eta 0:00:00\n",
      "Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.9 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.9/20.9 MB 90.0 MB/s eta 0:00:00\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.6/207.6 kB 37.7 MB/s eta 0:00:00\n",
      "Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl (322 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 322.6/322.6 kB 47.9 MB/s eta 0:00:00\n",
      "Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading setproctitle-1.3.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.8/62.8 kB 12.9 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: braceexpand, webdataset, smmap, setproctitle, sentry-sdk, eval-type-backport, docker-pycreds, gitdb, gitpython, wandb\n",
      "2025-02-08 10:17:21,277 sagemaker-training-toolkit INFO     Cannot connect to host algo-2 at port 22. Retrying...\n",
      "2025-02-08 10:17:21,278 sagemaker-training-toolkit INFO     Connection closed\n",
      "Successfully installed braceexpand-0.1.7 docker-pycreds-0.4.0 eval-type-backport-0.2.2 gitdb-4.0.12 gitpython-3.1.44 sentry-sdk-2.20.0 setproctitle-1.3.4 smmap-5.0.2 wandb-0.19.6 webdataset-0.2.100\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "[notice] A new release of pip is available: 24.1.2 -> 25.0\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2025-02-08 10:17:21,579 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2025-02-08 10:17:21,579 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2025-02-08 10:17:21,634 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-08 10:17:21,682 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-08 10:17:21,701 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\n",
      "2025-02-08 10:17:21,701 sagemaker-training-toolkit INFO     Waiting for MPI Master to create SSH daemon.\n",
      "2025-02-08 10:17:21,711 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\n",
      "2025-02-08 10:17:21,867 paramiko.transport INFO     Authentication (publickey) successful!\n",
      "2025-02-08 10:17:21,867 sagemaker-training-toolkit INFO     Can connect to host algo-1\n",
      "2025-02-08 10:17:21,867 sagemaker-training-toolkit INFO     MPI Master online, creating SSH daemon.\n",
      "2025-02-08 10:17:21,867 sagemaker-training-toolkit INFO     Writing environment variables to /etc/environment for the MPI process.\n",
      "2025-02-08 10:17:21,874 sagemaker-training-toolkit INFO     Waiting for MPI process to finish.\n",
      "2025-02-08 10:17:22,288 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\n",
      "2025-02-08 10:17:22,449 paramiko.transport INFO     Authentication (publickey) successful!\n",
      "2025-02-08 10:17:22,449 sagemaker-training-toolkit INFO     Can connect to host algo-2 at port 22\n",
      "2025-02-08 10:17:22,450 sagemaker-training-toolkit INFO     Connection closed\n",
      "2025-02-08 10:17:22,450 sagemaker-training-toolkit INFO     Worker algo-2 available for communication\n",
      "2025-02-08 10:17:22,450 sagemaker-training-toolkit INFO     Network interface name: eth0\n",
      "2025-02-08 10:17:22,450 sagemaker-training-toolkit INFO     Host: ['algo-1', 'algo-2']\n",
      "2025-02-08 10:17:22,877 sagemaker-training-toolkit INFO     Process[es]: [psutil.Process(pid=86, name='orted', status='running', started='10:17:22')]\n",
      "2025-02-08 10:17:22,877 sagemaker-training-toolkit INFO     Orted process found [psutil.Process(pid=86, name='orted', status='running', started='10:17:22')]\n",
      "2025-02-08 10:17:22,877 sagemaker-training-toolkit INFO     Waiting for orted process [psutil.Process(pid=86, name='orted', status='running', started='10:17:22')]\n",
      "2025-02-08 10:17:22,497 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-08 10:17:22,516 sagemaker-training-toolkit INFO     instance type: ml.g4dn.xlarge\n",
      "2025-02-08 10:17:22,516 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1', 'algo-2'] Hosts: ['algo-1:1', 'algo-2:1'] process_per_hosts: 1 num_processes: 2\n",
      "2025-02-08 10:17:22,542 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-08 10:17:22,567 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_distributed_dataparallel_custom_mpi_options\": \"\",\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": true,\n",
      "        \"sagemaker_instance_type\": \"ml.g4dn.xlarge\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 128,\n",
      "        \"debug\": false,\n",
      "        \"early-stopping-patience\": 5,\n",
      "        \"epochs\": 40,\n",
      "        \"lr-sched-gamma\": 0.5,\n",
      "        \"lr-sched-step-size\": 5,\n",
      "        \"model-arch\": \"resnet34\",\n",
      "        \"num-classes\": 5,\n",
      "        \"opt-learning-rate\": 0.0001,\n",
      "        \"opt-type\": \"adamw\",\n",
      "        \"opt-weight-decay\": 1e-05,\n",
      "        \"test-data-path\": \"s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000001}.tar\",\n",
      "        \"test-data-size\": 1567,\n",
      "        \"train-data-path\": \"s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar\",\n",
      "        \"train-data-size\": 7308,\n",
      "        \"val-data-path\": \"s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000001}.tar\",\n",
      "        \"val-data-size\": 1566,\n",
      "        \"wandb\": true\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"p5-amazon-bin-job-20250208-041248\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://p5-amazon-bin-images-train/p5-amazon-bin-job-20250208-041248/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_v1\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_v1.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"batch-size\":128,\"debug\":false,\"early-stopping-patience\":5,\"epochs\":40,\"lr-sched-gamma\":0.5,\"lr-sched-step-size\":5,\"model-arch\":\"resnet34\",\"num-classes\":5,\"opt-learning-rate\":0.0001,\"opt-type\":\"adamw\",\"opt-weight-decay\":1e-05,\"test-data-path\":\"s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000001}.tar\",\"test-data-size\":1567,\"train-data-path\":\"s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar\",\"train-data-size\":7308,\"val-data-path\":\"s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000001}.tar\",\"val-data-size\":1566,\"wandb\":true}\n",
      "SM_USER_ENTRY_POINT=train_v1.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.g4dn.xlarge\"}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g4dn.xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-2\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=train_v1\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=4\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://p5-amazon-bin-images-train/p5-amazon-bin-job-20250208-041248/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.g4dn.xlarge\"},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.g4dn.xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch-size\":128,\"debug\":false,\"early-stopping-patience\":5,\"epochs\":40,\"lr-sched-gamma\":0.5,\"lr-sched-step-size\":5,\"model-arch\":\"resnet34\",\"num-classes\":5,\"opt-learning-rate\":0.0001,\"opt-type\":\"adamw\",\"opt-weight-decay\":1e-05,\"test-data-path\":\"s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000001}.tar\",\"test-data-size\":1567,\"train-data-path\":\"s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar\",\"train-data-size\":7308,\"val-data-path\":\"s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000001}.tar\",\"val-data-size\":1566,\"wandb\":true},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"is_smddprun_installed\":true,\"job_name\":\"p5-amazon-bin-job-20250208-041248\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://p5-amazon-bin-images-train/p5-amazon-bin-job-20250208-041248/source/sourcedir.tar.gz\",\"module_name\":\"train_v1\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_v1.py\"}\n",
      "SM_USER_ARGS=[\"--batch-size\",\"128\",\"--debug\",\"False\",\"--early-stopping-patience\",\"5\",\"--epochs\",\"40\",\"--lr-sched-gamma\",\"0.5\",\"--lr-sched-step-size\",\"5\",\"--model-arch\",\"resnet34\",\"--num-classes\",\"5\",\"--opt-learning-rate\",\"0.0001\",\"--opt-type\",\"adamw\",\"--opt-weight-decay\",\"1e-05\",\"--test-data-path\",\"s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000001}.tar\",\"--test-data-size\",\"1567\",\"--train-data-path\",\"s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar\",\"--train-data-size\",\"7308\",\"--val-data-path\",\"s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000001}.tar\",\"--val-data-size\",\"1566\",\"--wandb\",\"True\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_HP_BATCH-SIZE=128\n",
      "SM_HP_DEBUG=false\n",
      "SM_HP_EARLY-STOPPING-PATIENCE=5\n",
      "SM_HP_EPOCHS=40\n",
      "SM_HP_LR-SCHED-GAMMA=0.5\n",
      "SM_HP_LR-SCHED-STEP-SIZE=5\n",
      "SM_HP_MODEL-ARCH=resnet34\n",
      "SM_HP_NUM-CLASSES=5\n",
      "SM_HP_OPT-LEARNING-RATE=0.0001\n",
      "SM_HP_OPT-TYPE=adamw\n",
      "SM_HP_OPT-WEIGHT-DECAY=1e-05\n",
      "SM_HP_TEST-DATA-PATH=s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000001}.tar\n",
      "SM_HP_TEST-DATA-SIZE=1567\n",
      "SM_HP_TRAIN-DATA-PATH=s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar\n",
      "SM_HP_TRAIN-DATA-SIZE=7308\n",
      "SM_HP_VAL-DATA-PATH=s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000001}.tar\n",
      "SM_HP_VAL-DATA-SIZE=1566\n",
      "SM_HP_WANDB=true\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\n",
      "Invoking script with the following command:\n",
      "mpirun --host algo-1:1,algo-2:1 -np 2 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 2 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_HOMOGENEOUS=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.9/site-packages/gethostname.cpython-39-x86_64-linux-gnu.so -x SMDATAPARALLEL_SERVER_ADDR=algo-1 -x SMDATAPARALLEL_SERVER_PORT=7592 -x SAGEMAKER_INSTANCE_TYPE=ml.g4dn.xlarge smddprun /opt/conda/bin/python3.9 -m mpi4py train_v1.py --batch-size 128 --debug False --early-stopping-patience 5 --epochs 40 --lr-sched-gamma 0.5 --lr-sched-step-size 5 --model-arch resnet34 --num-classes 5 --opt-learning-rate 0.0001 --opt-type adamw --opt-weight-decay 1e-05 --test-data-path s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000001}.tar --test-data-size 1567 --train-data-path s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar --train-data-size 7308 --val-data-path s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000001}.tar --val-data-size 1566 --wandb True\n",
      "Warning: Permanently added 'algo-2,10.0.250.26' (ECDSA) to the list of known hosts.\n",
      "[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:1,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:1,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:1,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:1,algo-2]<stdout>:DDP Mode\n",
      "[1,mpirank:1,algo-2]<stderr>:train_v1.py:22: DeprecationWarning: smdistributed.dataparallel.torch.dist is deprecated in the SageMaker distributed data parallel library v1.4.0+.Please use torch.distributed and specify 'smddp' as a backend when initializing process group as follows:torch.distributed.init_process_group(backend='smddp')For more information, see the library's API documentation at https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-modify-sdp-pt.html\n",
      "[1,mpirank:1,algo-2]<stderr>:  import smdistributed.dataparallel.torch.distributed as dist\n",
      "[1,mpirank:0,algo-1]<stdout>:DDP Mode\n",
      "[1,mpirank:0,algo-1]<stderr>:train_v1.py:22: DeprecationWarning: smdistributed.dataparallel.torch.dist is deprecated in the SageMaker distributed data parallel library v1.4.0+.Please use torch.distributed and specify 'smddp' as a backend when initializing process group as follows:torch.distributed.init_process_group(backend='smddp')For more information, see the library's API documentation at https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-modify-sdp-pt.html\n",
      "[1,mpirank:0,algo-1]<stderr>:  import smdistributed.dataparallel.torch.distributed as dist\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Bootstrap : Using eth0:10.0.234.47<0>\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO cudaDriverVersion 12040\n",
      "[1,mpirank:0,algo-1]<stdout>:NCCL version 2.14.3+cuda11.7\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO cudaDriverVersion 12040\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.234.47<0>\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Using network Socket\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Bootstrap : Using eth0:10.0.250.26<0>\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.250.26<0>\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Using network Socket\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 00/02 :    0   1\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 01/02 :    0   1\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:125 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 00/0 : 0[1e0] -> 1[1e0] [receive] via NET/Socket/0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:128 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 00/0 : 1[1e0] -> 0[1e0] [receive] via NET/Socket/0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:125 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 01/0 : 0[1e0] -> 1[1e0] [receive] via NET/Socket/0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:128 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 01/0 : 1[1e0] -> 0[1e0] [receive] via NET/Socket/0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 00/0 : 1[1e0] -> 0[1e0] [send] via NET/Socket/0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 00/0 : 0[1e0] -> 1[1e0] [send] via NET/Socket/0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 01/0 : 1[1e0] -> 0[1e0] [send] via NET/Socket/0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 01/0 : 0[1e0] -> 1[1e0] [send] via NET/Socket/0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Connected all rings\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Connected all trees\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Connected all rings\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Connected all trees\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO comm 0x55f78a7d3050 rank 1 nranks 2 cudaDev 0 busId 1e0 - Init COMPLETE\n",
      "[1,mpirank:1,algo-2]<stdout>:NCCL version 2.14.3+cuda11.7\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Using network Socket\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO comm 0x560047d8a710 rank 0 nranks 2 cudaDev 0 busId 1e0 - Init COMPLETE\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Using network Socket\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 00/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 01/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 02/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 03/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 04/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 05/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 06/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 07/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 08/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 09/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 10/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 11/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 12/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 13/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 14/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 15/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 16/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 17/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 18/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 19/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 20/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 21/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 22/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 23/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 24/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 25/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 26/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 27/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 28/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 29/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 30/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 31/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Connected all rings\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Connected all trees\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 00/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 01/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 02/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 03/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 04/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 05/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 06/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 07/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 08/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 09/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 10/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 11/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 12/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 13/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 14/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 15/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 16/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 17/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 18/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 19/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 20/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 21/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 22/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 23/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 24/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 25/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 26/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 27/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 28/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 29/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 30/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 31/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Connected all rings\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Connected all trees\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO comm 0x55f78b452ec0 rank 0 nranks 1 cudaDev 0 busId 1e0 - Init COMPLETE\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO comm 0x560047e0f870 rank 0 nranks 1 cudaDev 0 busId 1e0 - Init COMPLETE\n",
      "[1,mpirank:0,algo-1]<stdout>:Running smdistributed.dataparallel v1.7.0\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:SMDDP: Multi node ENA mode[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🟢 SageMkaer DDP is initialized.\n",
      "[1,mpirank:1,algo-2]<stdout>:👉 Total GPU count: 2\n",
      "[1,mpirank:1,algo-2]<stdout>:👉 Rank: 1, Local Rank: 0\n",
      "[1,mpirank:1,algo-2]<stdout>:👉 Device: cuda, Rank: 1, Local rank: 0\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🟢 SageMkaer DDP is initialized.\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Total GPU count: 2\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Rank: 0, Local Rank: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Device: cuda, Rank: 0, Local rank: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 task.config:\n",
      "[1,mpirank:0,algo-1]<stdout>:{\n",
      "[1,mpirank:0,algo-1]<stdout>:'batch_size': 128,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'class_weights_dict': {},\n",
      "[1,mpirank:0,algo-1]<stdout>: 'debug': [1,mpirank:0,algo-1]<stdout>:False,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'device': device(type='cuda'),\n",
      "[1,mpirank:0,algo-1]<stdout>: 'early_stopping_patience': 5,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'epochs': 40,\n",
      "[1,mpirank:0,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:'lr_sched_gamma':\n",
      "[1,mpirank:0,algo-1]<stdout>:0.5,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'lr_sched_step_size': 5,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'model_arch': 'resnet34',\n",
      "[1,mpirank:0,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:'model_dir': '/opt/ml/model',\n",
      "[1,mpirank:0,algo-1]<stdout>: 'num_classes': 5,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'num_cpu': 4,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'opt_learning_rate': 0.0001,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'opt_momentum': 0.9,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'opt_type': [1,mpirank:0,algo-1]<stdout>:'adamw',\n",
      "[1,mpirank:0,algo-1]<stdout>: 'opt_weight_decay': [1,mpirank:0,algo-1]<stdout>:1e-05,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'output_data_dir': '/opt/ml/output/data',\n",
      "[1,mpirank:0,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:'test_data_path': [1,mpirank:0,algo-1]<stdout>:'s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000001}.tar'[1,mpirank:0,algo-1]<stdout>:,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'test_data_size': 1567[1,mpirank:0,algo-1]<stdout>:,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'test_shards'[1,mpirank:0,algo-1]<stdout>:: 2,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'train_data_path': [1,mpirank:0,algo-1]<stdout>:'s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar',\n",
      "[1,mpirank:0,algo-1]<stdout>: 'train_data_size': 7308,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'train_shards': [1,mpirank:0,algo-1]<stdout>:8,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'use_cuda': [1,mpirank:0,algo-1]<stdout>:True,\n",
      "[1,mpirank:0,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:'val_data_path': [1,mpirank:0,algo-1]<stdout>:'s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000001}.tar',\n",
      "[1,mpirank:0,algo-1]<stdout>: 'val_data_size'[1,mpirank:0,algo-1]<stdout>:: [1,mpirank:0,algo-1]<stdout>:1566[1,mpirank:0,algo-1]<stdout>:,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'val_shards': 2,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'wandb': [1,mpirank:0,algo-1]<stdout>:True[1,mpirank:0,algo-1]<stdout>:}[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Currently logged in as: nov05 to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Tracking run with wandb version 0.19.6\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Run data is saved locally in /opt/ml/code/wandb/run-20250208_101730-p5-amazon-bin-job-20250208-041248-0q3ao9-algo-1\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Run `wandb offline` to turn off syncing.\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Syncing run p5-amazon-bin-job-20250208-041248-0q3ao9-algo-1\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: ⭐️ View project at https://wandb.ai/nov05/udacity-awsmle-resnet34-amazon-bin\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: 🚀 View run at https://wandb.ai/nov05/udacity-awsmle-resnet34-amazon-bin/runs/p5-amazon-bin-job-20250208-041248-0q3ao9-algo-1\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Rank 0: Model resnet34 has been created successfully.\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 0, Learning Rate: 0.0002\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:👉 Rank 1: Model resnet34 has been created successfully.\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-08 10:17:31.973 algo-1:106 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-08 10:17:32.020 algo-2:105 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-08 10:17:32.334 algo-1:106 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-08 10:17:32.335 algo-1:106 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-08 10:17:32.336 algo-1:106 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-08 10:17:32.336 algo-1:106 INFO hook.py:259] Saving to /opt/ml/output/tensors\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-08 10:17:32.337 algo-1:106 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-08 10:17:32.392 algo-2:105 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-08 10:17:32.392 algo-2:105 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-08 10:17:32.393 algo-2:105 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-08 10:17:32.393 algo-2:105 INFO hook.py:259] Saving to /opt/ml/output/tensors\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-08 10:17:32.393 algo-2:105 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [128/3654 (4%)], Loss: 3.881778[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [128/3654 (4%)], Loss: 4.118821\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\n",
      "[1,mpirank:1,algo-2]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [256/3654 (7%)], Loss: 5.139647\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [256/3654 (7%)], Loss: 4.758651\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [384/3654 (11%)], Loss: 2.798761\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [384/3654 (11%)], Loss: 2.354123\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [512/3654 (14%)], Loss: 3.062535[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [512/3654 (14%)], Loss: 2.685015\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [640/3654 (18%)], Loss: 2.226707\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [640/3654 (18%)], Loss: 2.034117\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [768/3654 (21%)], Loss: 1.974017\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [768/3654 (21%)], Loss: 1.858533\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [896/3654 (25%)], Loss: 1.774962\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [896/3654 (25%)], Loss: 1.687266\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [1024/3654 (28%)], Loss: 1.702186\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [1024/3654 (28%)], Loss: 1.637734[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [1152/3654 (32%)], Loss: 1.603123\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [1152/3654 (32%)], Loss: 1.699420\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [1280/3654 (35%)], Loss: 1.597446\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [1280/3654 (35%)], Loss: 1.642343\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [1408/3654 (39%)], Loss: 1.644807[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [1408/3654 (39%)], Loss: 1.722838\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [1536/3654 (42%)], Loss: 1.615036\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [1536/3654 (42%)], Loss: 1.684289\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [1664/3654 (46%)], Loss: 1.592617\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [1664/3654 (46%)], Loss: 1.601081\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [1792/3654 (49%)], Loss: 1.570000[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [1792/3654 (49%)], Loss: 1.738255\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [1920/3654 (53%)], Loss: 1.650493[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [1920/3654 (53%)], Loss: 1.578725\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [2048/3654 (56%)], Loss: 1.564998\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [2048/3654 (56%)], Loss: 1.539243\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [2176/3654 (60%)], Loss: 1.645669\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [2176/3654 (60%)], Loss: 1.571114\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [2304/3654 (63%)], Loss: 1.577156\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [2304/3654 (63%)], Loss: 1.594495\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [2432/3654 (67%)], Loss: 1.502179\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [2432/3654 (67%)], Loss: 1.636034\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [2560/3654 (70%)], Loss: 1.546839[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [2560/3654 (70%)], Loss: 1.549181\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [2688/3654 (74%)], Loss: 1.493037\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [2688/3654 (74%)], Loss: 1.542361\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [2816/3654 (77%)], Loss: 1.563442\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [2816/3654 (77%)], Loss: 1.550840\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [2944/3654 (81%)], Loss: 1.512142\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [2944/3654 (81%)], Loss: 1.555809\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [3072/3654 (84%)], Loss: 1.593338\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [3072/3654 (84%)], Loss: 1.490490\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [3200/3654 (88%)], Loss: 1.543104\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [3200/3654 (88%)], Loss: 1.542024\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [3328/3654 (91%)], Loss: 1.566052\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [3328/3654 (91%)], Loss: 1.559785\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [3456/3654 (95%)], Loss: 1.584740\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [3456/3654 (95%)], Loss: 1.481594\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 0, Rank 0: [3584/3654 (98%)], Loss: 1.501144\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 0, Rank 1: [3584/3654 (98%)], Loss: 1.554594\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.6505, Accuracy: 360/1536 (23.44%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 1, Learning Rate: 0.0002\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [128/3654 (4%)], Loss: 1.531949\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [128/3654 (4%)], Loss: 1.509084\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [256/3654 (7%)], Loss: 1.525474\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [256/3654 (7%)], Loss: 1.595452\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [384/3654 (11%)], Loss: 1.542086[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [384/3654 (11%)], Loss: 1.520411\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [512/3654 (14%)], Loss: 1.580260\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [512/3654 (14%)], Loss: 1.522250\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [640/3654 (18%)], Loss: 1.549488\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [640/3654 (18%)], Loss: 1.517664\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [768/3654 (21%)], Loss: 1.513899\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [768/3654 (21%)], Loss: 1.501388\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [896/3654 (25%)], Loss: 1.530654[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [896/3654 (25%)], Loss: 1.568785\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [1024/3654 (28%)], Loss: 1.522013\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [1024/3654 (28%)], Loss: 1.641315\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [1152/3654 (32%)], Loss: 1.630702\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [1152/3654 (32%)], Loss: 1.474949\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [1280/3654 (35%)], Loss: 1.557582[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [1280/3654 (35%)], Loss: 1.539618\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [1408/3654 (39%)], Loss: 1.527305\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [1408/3654 (39%)], Loss: 1.504169\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [1536/3654 (42%)], Loss: 1.453905\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [1536/3654 (42%)], Loss: 1.505079\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [1664/3654 (46%)], Loss: 1.553491\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [1664/3654 (46%)], Loss: 1.518381\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [1792/3654 (49%)], Loss: 1.480615\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [1792/3654 (49%)], Loss: 1.530907\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [1920/3654 (53%)], Loss: 1.533903\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [1920/3654 (53%)], Loss: 1.564466\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [2048/3654 (56%)], Loss: 1.545195\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [2048/3654 (56%)], Loss: 1.533425\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [2176/3654 (60%)], Loss: 1.580275\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [2176/3654 (60%)], Loss: 1.504526\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [2304/3654 (63%)], Loss: 1.460139\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [2304/3654 (63%)], Loss: 1.610777\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [2432/3654 (67%)], Loss: 1.494154\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [2432/3654 (67%)], Loss: 1.590226\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [2560/3654 (70%)], Loss: 1.595028\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [2560/3654 (70%)], Loss: 1.643175\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [2688/3654 (74%)], Loss: 1.571012\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [2688/3654 (74%)], Loss: 1.486454\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [2816/3654 (77%)], Loss: 1.585324\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [2816/3654 (77%)], Loss: 1.541326\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [2944/3654 (81%)], Loss: 1.585033\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [2944/3654 (81%)], Loss: 1.568831\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [3072/3654 (84%)], Loss: 1.508295\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [3072/3654 (84%)], Loss: 1.586351\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [3200/3654 (88%)], Loss: 1.508564\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [3200/3654 (88%)], Loss: 1.565048[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [3328/3654 (91%)], Loss: 1.575423\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [3328/3654 (91%)], Loss: 1.501825\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [3456/3654 (95%)], Loss: 1.520234[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [3456/3654 (95%)], Loss: 1.536175\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 1, Rank 0: [3584/3654 (98%)], Loss: 1.583269\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 1, Rank 1: [3584/3654 (98%)], Loss: 1.504701\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:self.close()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError\n",
      "[1,mpirank:0,algo-1]<stderr>:: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4697, Accuracy: 476/1536 (30.99%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 2, Learning Rate: 0.0002\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [128/3654 (4%)], Loss: 1.509662\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [128/3654 (4%)], Loss: 1.518967\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [256/3654 (7%)], Loss: 1.494072\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [256/3654 (7%)], Loss: 1.535244\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [384/3654 (11%)], Loss: 1.498427[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [384/3654 (11%)], Loss: 1.648956\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [512/3654 (14%)], Loss: 1.605086\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [512/3654 (14%)], Loss: 1.486587[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [640/3654 (18%)], Loss: 1.649211\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [640/3654 (18%)], Loss: 1.477199\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [768/3654 (21%)], Loss: 1.589361\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [768/3654 (21%)], Loss: 1.421424\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [896/3654 (25%)], Loss: 1.540855\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [896/3654 (25%)], Loss: 1.558111\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [1024/3654 (28%)], Loss: 1.642173\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [1024/3654 (28%)], Loss: 1.544478\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [1152/3654 (32%)], Loss: 1.603902\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [1152/3654 (32%)], Loss: 1.559108\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [1280/3654 (35%)], Loss: 1.564502\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [1280/3654 (35%)], Loss: 1.576619\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [1408/3654 (39%)], Loss: 1.528070\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [1408/3654 (39%)], Loss: 1.540679\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [1536/3654 (42%)], Loss: 1.495011\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [1536/3654 (42%)], Loss: 1.491977[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [1664/3654 (46%)], Loss: 1.540045\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [1664/3654 (46%)], Loss: 1.535844\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [1792/3654 (49%)], Loss: 1.563877\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [1792/3654 (49%)], Loss: 1.541176\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [1920/3654 (53%)], Loss: 1.615150\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [1920/3654 (53%)], Loss: 1.504481\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [2048/3654 (56%)], Loss: 1.543387\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [2048/3654 (56%)], Loss: 1.485671\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [2176/3654 (60%)], Loss: 1.516053\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [2176/3654 (60%)], Loss: 1.536918\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [2304/3654 (63%)], Loss: 1.487445\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [2304/3654 (63%)], Loss: 1.492968\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [2432/3654 (67%)], Loss: 1.512737\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [2432/3654 (67%)], Loss: 1.551359\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [2560/3654 (70%)], Loss: 1.622848\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [2560/3654 (70%)], Loss: 1.537119\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [2688/3654 (74%)], Loss: 1.548121\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [2688/3654 (74%)], Loss: 1.471363\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [2816/3654 (77%)], Loss: 1.508842\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [2816/3654 (77%)], Loss: 1.525862\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [2944/3654 (81%)], Loss: 1.518186\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [2944/3654 (81%)], Loss: 1.425981\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [3072/3654 (84%)], Loss: 1.549980\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [3072/3654 (84%)], Loss: 1.519222[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [3200/3654 (88%)], Loss: 1.554214\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [3200/3654 (88%)], Loss: 1.507348\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [3328/3654 (91%)], Loss: 1.536885\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [3328/3654 (91%)], Loss: 1.505697\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [3456/3654 (95%)], Loss: 1.441070\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [3456/3654 (95%)], Loss: 1.559267\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 2, Rank 0: [3584/3654 (98%)], Loss: 1.564049\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 2, Rank 1: [3584/3654 (98%)], Loss: 1.497586\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.5031, Accuracy: 420/1536 (27.34%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 3, Learning Rate: 0.0002[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [128/3654 (4%)], Loss: 1.483439\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [128/3654 (4%)], Loss: 1.582427\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [256/3654 (7%)], Loss: 1.524578\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [256/3654 (7%)], Loss: 1.517290\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [384/3654 (11%)], Loss: 1.516329\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [384/3654 (11%)], Loss: 1.578780[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [512/3654 (14%)], Loss: 1.514663\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [512/3654 (14%)], Loss: 1.453339[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [640/3654 (18%)], Loss: 1.424702\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [640/3654 (18%)], Loss: 1.519316\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [768/3654 (21%)], Loss: 1.488208\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [768/3654 (21%)], Loss: 1.471652[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [896/3654 (25%)], Loss: 1.507233\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [896/3654 (25%)], Loss: 1.443410\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [1024/3654 (28%)], Loss: 1.512417[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [1024/3654 (28%)], Loss: 1.579542\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [1152/3654 (32%)], Loss: 1.426599\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [1152/3654 (32%)], Loss: 1.489708\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [1280/3654 (35%)], Loss: 1.524579[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [1280/3654 (35%)], Loss: 1.516608\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [1408/3654 (39%)], Loss: 1.502082\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [1408/3654 (39%)], Loss: 1.467955\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [1536/3654 (42%)], Loss: 1.521025[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [1536/3654 (42%)], Loss: 1.540937\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [1664/3654 (46%)], Loss: 1.486073\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [1664/3654 (46%)], Loss: 1.491844\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [1792/3654 (49%)], Loss: 1.501853\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [1792/3654 (49%)], Loss: 1.547726\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [1920/3654 (53%)], Loss: 1.491700\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [1920/3654 (53%)], Loss: 1.568119\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [2048/3654 (56%)], Loss: 1.493079\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [2048/3654 (56%)], Loss: 1.479113\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [2176/3654 (60%)], Loss: 1.503454\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [2176/3654 (60%)], Loss: 1.543765\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [2304/3654 (63%)], Loss: 1.505000\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [2304/3654 (63%)], Loss: 1.506669\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [2432/3654 (67%)], Loss: 1.575812\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [2432/3654 (67%)], Loss: 1.557183\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [2560/3654 (70%)], Loss: 1.473154\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [2560/3654 (70%)], Loss: 1.501176\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [2688/3654 (74%)], Loss: 1.520293\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [2688/3654 (74%)], Loss: 1.492192\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [2816/3654 (77%)], Loss: 1.541164\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [2816/3654 (77%)], Loss: 1.480198\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [2944/3654 (81%)], Loss: 1.510078\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [2944/3654 (81%)], Loss: 1.426651\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [3072/3654 (84%)], Loss: 1.507812\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [3072/3654 (84%)], Loss: 1.445767\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [3200/3654 (88%)], Loss: 1.437676\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [3200/3654 (88%)], Loss: 1.582061\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [3328/3654 (91%)], Loss: 1.519693\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [3328/3654 (91%)], Loss: 1.464459\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [3456/3654 (95%)], Loss: 1.534376\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [3456/3654 (95%)], Loss: 1.500886\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 3, Rank 1: [3584/3654 (98%)], Loss: 1.571930\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 3, Rank 0: [3584/3654 (98%)], Loss: 1.478024\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError[1,mpirank:0,algo-1]<stderr>:: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>[1,mpirank:1,algo-2]<stderr>:\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:\n",
      "[1,mpirank:1,algo-2]<stderr>:self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:1,algo-2]<stderr>:\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4652, Accuracy: 440/1536 (28.65%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 4, Learning Rate: 0.0002\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [128/3654 (4%)], Loss: 1.479388\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [128/3654 (4%)], Loss: 1.491390\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [256/3654 (7%)], Loss: 1.483050\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [256/3654 (7%)], Loss: 1.512330\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [384/3654 (11%)], Loss: 1.466020\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [384/3654 (11%)], Loss: 1.467633\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [512/3654 (14%)], Loss: 1.521974\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [512/3654 (14%)], Loss: 1.549739\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [640/3654 (18%)], Loss: 1.571236[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [640/3654 (18%)], Loss: 1.459047\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [768/3654 (21%)], Loss: 1.441160[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [768/3654 (21%)], Loss: 1.563702\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [896/3654 (25%)], Loss: 1.525868\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [896/3654 (25%)], Loss: 1.514367\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [1024/3654 (28%)], Loss: 1.531149\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [1024/3654 (28%)], Loss: 1.480971\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [1152/3654 (32%)], Loss: 1.471654\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [1152/3654 (32%)], Loss: 1.507266[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [1280/3654 (35%)], Loss: 1.502353\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [1280/3654 (35%)], Loss: 1.494621\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [1408/3654 (39%)], Loss: 1.513655[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [1408/3654 (39%)], Loss: 1.506075\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [1536/3654 (42%)], Loss: 1.457657\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [1536/3654 (42%)], Loss: 1.493998\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [1664/3654 (46%)], Loss: 1.485384\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [1664/3654 (46%)], Loss: 1.540980\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [1792/3654 (49%)], Loss: 1.481277[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [1792/3654 (49%)], Loss: 1.501219\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [1920/3654 (53%)], Loss: 1.551262[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [1920/3654 (53%)], Loss: 1.526883\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [2048/3654 (56%)], Loss: 1.528665\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [2048/3654 (56%)], Loss: 1.499807\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [2176/3654 (60%)], Loss: 1.602367\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [2176/3654 (60%)], Loss: 1.531482[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [2304/3654 (63%)], Loss: 1.573974\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [2304/3654 (63%)], Loss: 1.485397[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [2432/3654 (67%)], Loss: 1.469598\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [2432/3654 (67%)], Loss: 1.515750\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [2560/3654 (70%)], Loss: 1.496537\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [2560/3654 (70%)], Loss: 1.573874\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [2688/3654 (74%)], Loss: 1.594989\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [2688/3654 (74%)], Loss: 1.472943\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [2816/3654 (77%)], Loss: 1.521468\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [2816/3654 (77%)], Loss: 1.468104\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [2944/3654 (81%)], Loss: 1.491744\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [2944/3654 (81%)], Loss: 1.457431[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [3072/3654 (84%)], Loss: 1.557099\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [3072/3654 (84%)], Loss: 1.525489[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [3200/3654 (88%)], Loss: 1.513252\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [3200/3654 (88%)], Loss: 1.512259\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [3328/3654 (91%)], Loss: 1.548895[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [3328/3654 (91%)], Loss: 1.528018\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [3456/3654 (95%)], Loss: 1.562200\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [3456/3654 (95%)], Loss: 1.549628\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 4, Rank 1: [3584/3654 (98%)], Loss: 1.459945\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 4, Rank 0: [3584/3654 (98%)], Loss: 1.441452\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4539, Accuracy: 480/1536 (31.25%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 5, Learning Rate: 0.0001\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [128/3654 (4%)], Loss: 1.513216\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [128/3654 (4%)], Loss: 1.453655\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [256/3654 (7%)], Loss: 1.514017\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [256/3654 (7%)], Loss: 1.459012\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [384/3654 (11%)], Loss: 1.556635\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [384/3654 (11%)], Loss: 1.417516\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [512/3654 (14%)], Loss: 1.511769[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [512/3654 (14%)], Loss: 1.567444\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [640/3654 (18%)], Loss: 1.479561\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [640/3654 (18%)], Loss: 1.545546\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [768/3654 (21%)], Loss: 1.484713\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [768/3654 (21%)], Loss: 1.522156\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [896/3654 (25%)], Loss: 1.537318\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [896/3654 (25%)], Loss: 1.435456\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [1024/3654 (28%)], Loss: 1.483903\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [1024/3654 (28%)], Loss: 1.496820\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [1152/3654 (32%)], Loss: 1.507750\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [1152/3654 (32%)], Loss: 1.538760\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [1280/3654 (35%)], Loss: 1.497171\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [1280/3654 (35%)], Loss: 1.482408\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [1408/3654 (39%)], Loss: 1.526423\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [1408/3654 (39%)], Loss: 1.473726\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [1536/3654 (42%)], Loss: 1.530330\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [1536/3654 (42%)], Loss: 1.572602\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [1664/3654 (46%)], Loss: 1.476724[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [1664/3654 (46%)], Loss: 1.490465\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [1792/3654 (49%)], Loss: 1.415069\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [1792/3654 (49%)], Loss: 1.544586\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [1920/3654 (53%)], Loss: 1.460660\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [1920/3654 (53%)], Loss: 1.465822\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [2048/3654 (56%)], Loss: 1.447310\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [2048/3654 (56%)], Loss: 1.574202[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [2176/3654 (60%)], Loss: 1.463587[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [2176/3654 (60%)], Loss: 1.520061\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [2304/3654 (63%)], Loss: 1.485379[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [2304/3654 (63%)], Loss: 1.481258\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [2432/3654 (67%)], Loss: 1.507477\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [2432/3654 (67%)], Loss: 1.503616\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [2560/3654 (70%)], Loss: 1.509555\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [2560/3654 (70%)], Loss: 1.560925\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [2688/3654 (74%)], Loss: 1.529573\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [2688/3654 (74%)], Loss: 1.484912\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [2816/3654 (77%)], Loss: 1.473037\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [2816/3654 (77%)], Loss: 1.487223\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [2944/3654 (81%)], Loss: 1.494137\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [2944/3654 (81%)], Loss: 1.511913\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [3072/3654 (84%)], Loss: 1.482655\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [3072/3654 (84%)], Loss: 1.475154\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [3200/3654 (88%)], Loss: 1.501192\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [3200/3654 (88%)], Loss: 1.490127\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [3328/3654 (91%)], Loss: 1.516347\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [3328/3654 (91%)], Loss: 1.471783\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [3456/3654 (95%)], Loss: 1.493322\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [3456/3654 (95%)], Loss: 1.411752\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 5, Rank 1: [3584/3654 (98%)], Loss: 1.577632[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 5, Rank 0: [3584/3654 (98%)], Loss: 1.495971\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>[1,mpirank:1,algo-2]<stderr>:\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()[1,mpirank:1,algo-2]<stderr>:\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:1,algo-2]<stderr>:\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4472, Accuracy: 460/1536 (29.95%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 6, Learning Rate: 0.0001\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [128/3654 (4%)], Loss: 1.514452\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [128/3654 (4%)], Loss: 1.553553\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [256/3654 (7%)], Loss: 1.542942\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [256/3654 (7%)], Loss: 1.578042\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [384/3654 (11%)], Loss: 1.514413\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [384/3654 (11%)], Loss: 1.456786\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [512/3654 (14%)], Loss: 1.508437\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [512/3654 (14%)], Loss: 1.440702\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [640/3654 (18%)], Loss: 1.434355\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [640/3654 (18%)], Loss: 1.481655\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [768/3654 (21%)], Loss: 1.518832\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [768/3654 (21%)], Loss: 1.468279\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [896/3654 (25%)], Loss: 1.486215\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [896/3654 (25%)], Loss: 1.496193\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [1024/3654 (28%)], Loss: 1.558428\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [1024/3654 (28%)], Loss: 1.524541\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [1152/3654 (32%)], Loss: 1.477710\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [1152/3654 (32%)], Loss: 1.506405\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [1280/3654 (35%)], Loss: 1.428892\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [1280/3654 (35%)], Loss: 1.498827\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [1408/3654 (39%)], Loss: 1.495053\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [1408/3654 (39%)], Loss: 1.508570[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [1536/3654 (42%)], Loss: 1.431380[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [1536/3654 (42%)], Loss: 1.503755\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [1664/3654 (46%)], Loss: 1.517823\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [1664/3654 (46%)], Loss: 1.521466\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [1792/3654 (49%)], Loss: 1.498338[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [1792/3654 (49%)], Loss: 1.567183\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [1920/3654 (53%)], Loss: 1.446959[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [1920/3654 (53%)], Loss: 1.453436\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [2048/3654 (56%)], Loss: 1.448824\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [2048/3654 (56%)], Loss: 1.531742\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [2176/3654 (60%)], Loss: 1.510735[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [2176/3654 (60%)], Loss: 1.459383\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [2304/3654 (63%)], Loss: 1.529816\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [2304/3654 (63%)], Loss: 1.507053\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [2432/3654 (67%)], Loss: 1.563758\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [2432/3654 (67%)], Loss: 1.519187\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [2560/3654 (70%)], Loss: 1.563143\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [2560/3654 (70%)], Loss: 1.539140\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [2688/3654 (74%)], Loss: 1.551290\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [2688/3654 (74%)], Loss: 1.525579\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [2816/3654 (77%)], Loss: 1.524292\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [2816/3654 (77%)], Loss: 1.521950\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [2944/3654 (81%)], Loss: 1.516931\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [2944/3654 (81%)], Loss: 1.585312\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [3072/3654 (84%)], Loss: 1.472643\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [3072/3654 (84%)], Loss: 1.550832\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [3200/3654 (88%)], Loss: 1.555784\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [3200/3654 (88%)], Loss: 1.476496\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [3328/3654 (91%)], Loss: 1.564232\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [3328/3654 (91%)], Loss: 1.513536[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [3456/3654 (95%)], Loss: 1.504518\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [3456/3654 (95%)], Loss: 1.519046\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 6, Rank 1: [3584/3654 (98%)], Loss: 1.473545\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 6, Rank 0: [3584/3654 (98%)], Loss: 1.500093\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:1,algo-2]<stderr>:\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4865, Accuracy: 456/1536 (29.69%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 7, Learning Rate: 0.0001\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [128/3654 (4%)], Loss: 1.470326[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [128/3654 (4%)], Loss: 1.421898\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [256/3654 (7%)], Loss: 1.510793\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [256/3654 (7%)], Loss: 1.586424\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [384/3654 (11%)], Loss: 1.494540\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [384/3654 (11%)], Loss: 1.586569\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [512/3654 (14%)], Loss: 1.511227\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [512/3654 (14%)], Loss: 1.453845\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [640/3654 (18%)], Loss: 1.599184\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [640/3654 (18%)], Loss: 1.410335[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [768/3654 (21%)], Loss: 1.502761\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [768/3654 (21%)], Loss: 1.490134\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [896/3654 (25%)], Loss: 1.487823\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [896/3654 (25%)], Loss: 1.474205\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [1024/3654 (28%)], Loss: 1.462300[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [1024/3654 (28%)], Loss: 1.510074\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [1152/3654 (32%)], Loss: 1.584272[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [1152/3654 (32%)], Loss: 1.430628\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [1280/3654 (35%)], Loss: 1.441192\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [1280/3654 (35%)], Loss: 1.524126[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [1408/3654 (39%)], Loss: 1.500019\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [1408/3654 (39%)], Loss: 1.483166\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [1536/3654 (42%)], Loss: 1.424703[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [1536/3654 (42%)], Loss: 1.476265\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [1664/3654 (46%)], Loss: 1.532286\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [1664/3654 (46%)], Loss: 1.494819\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [1792/3654 (49%)], Loss: 1.550725\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [1792/3654 (49%)], Loss: 1.490071[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [1920/3654 (53%)], Loss: 1.502798\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [1920/3654 (53%)], Loss: 1.556403\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [2048/3654 (56%)], Loss: 1.435487[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [2048/3654 (56%)], Loss: 1.504869\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [2176/3654 (60%)], Loss: 1.485993\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [2176/3654 (60%)], Loss: 1.449880[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [2304/3654 (63%)], Loss: 1.469386\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [2304/3654 (63%)], Loss: 1.520731\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [2432/3654 (67%)], Loss: 1.500384\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [2432/3654 (67%)], Loss: 1.527707\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [2560/3654 (70%)], Loss: 1.522111\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [2560/3654 (70%)], Loss: 1.499775\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [2688/3654 (74%)], Loss: 1.521237\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [2688/3654 (74%)], Loss: 1.479370\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [2816/3654 (77%)], Loss: 1.420986\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [2816/3654 (77%)], Loss: 1.478983\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [2944/3654 (81%)], Loss: 1.508178\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [2944/3654 (81%)], Loss: 1.499583\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [3072/3654 (84%)], Loss: 1.585527\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [3072/3654 (84%)], Loss: 1.490516\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [3200/3654 (88%)], Loss: 1.518465\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [3200/3654 (88%)], Loss: 1.556009\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [3328/3654 (91%)], Loss: 1.546888\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [3328/3654 (91%)], Loss: 1.496680\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [3456/3654 (95%)], Loss: 1.537670\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [3456/3654 (95%)], Loss: 1.543071\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 7, Rank 1: [3584/3654 (98%)], Loss: 1.517205\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 7, Rank 0: [3584/3654 (98%)], Loss: 1.537569\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError[1,mpirank:0,algo-1]<stderr>:: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError[1,mpirank:0,algo-1]<stderr>:: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4448, Accuracy: 504/1536 (32.81%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 8, Learning Rate: 0.0001\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [128/3654 (4%)], Loss: 1.493396\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [128/3654 (4%)], Loss: 1.452006\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [256/3654 (7%)], Loss: 1.431615\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [256/3654 (7%)], Loss: 1.445315\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [384/3654 (11%)], Loss: 1.518605\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [384/3654 (11%)], Loss: 1.420252\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [512/3654 (14%)], Loss: 1.515525\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [512/3654 (14%)], Loss: 1.451182[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [640/3654 (18%)], Loss: 1.535152\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [640/3654 (18%)], Loss: 1.548715\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [768/3654 (21%)], Loss: 1.427945\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [768/3654 (21%)], Loss: 1.485773\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [896/3654 (25%)], Loss: 1.528021[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [896/3654 (25%)], Loss: 1.516230\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [1024/3654 (28%)], Loss: 1.593383[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [1024/3654 (28%)], Loss: 1.506080\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [1152/3654 (32%)], Loss: 1.477929\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [1152/3654 (32%)], Loss: 1.474649\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [1280/3654 (35%)], Loss: 1.536564[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [1280/3654 (35%)], Loss: 1.475666[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [1408/3654 (39%)], Loss: 1.514640\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [1408/3654 (39%)], Loss: 1.510352[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [1536/3654 (42%)], Loss: 1.484367\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [1536/3654 (42%)], Loss: 1.499205\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [1664/3654 (46%)], Loss: 1.464364\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [1664/3654 (46%)], Loss: 1.479358\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [1792/3654 (49%)], Loss: 1.550817\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [1792/3654 (49%)], Loss: 1.484640\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [1920/3654 (53%)], Loss: 1.472423\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [1920/3654 (53%)], Loss: 1.496431\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [2048/3654 (56%)], Loss: 1.488681\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [2048/3654 (56%)], Loss: 1.459823\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [2176/3654 (60%)], Loss: 1.541836\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [2176/3654 (60%)], Loss: 1.543261\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [2304/3654 (63%)], Loss: 1.480301\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [2304/3654 (63%)], Loss: 1.518916\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [2432/3654 (67%)], Loss: 1.469905\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [2432/3654 (67%)], Loss: 1.473439\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [2560/3654 (70%)], Loss: 1.447745\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [2560/3654 (70%)], Loss: 1.430628\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [2688/3654 (74%)], Loss: 1.502375\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [2688/3654 (74%)], Loss: 1.560636\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [2816/3654 (77%)], Loss: 1.490055\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [2816/3654 (77%)], Loss: 1.486658\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [2944/3654 (81%)], Loss: 1.421622\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [2944/3654 (81%)], Loss: 1.538206\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [3072/3654 (84%)], Loss: 1.456286\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [3072/3654 (84%)], Loss: 1.496528\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [3200/3654 (88%)], Loss: 1.506892\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [3200/3654 (88%)], Loss: 1.520291\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [3328/3654 (91%)], Loss: 1.463327\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [3328/3654 (91%)], Loss: 1.531345\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [3456/3654 (95%)], Loss: 1.467256\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [3456/3654 (95%)], Loss: 1.532497\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 8, Rank 1: [3584/3654 (98%)], Loss: 1.489618\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 8, Rank 0: [3584/3654 (98%)], Loss: 1.482221\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError[1,mpirank:1,algo-2]<stderr>:: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.close()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError[1,mpirank:0,algo-1]<stderr>:: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4297, Accuracy: 488/1536 (31.77%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 9, Learning Rate: 0.0001[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [128/3654 (4%)], Loss: 1.503156\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [128/3654 (4%)], Loss: 1.454589\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [256/3654 (7%)], Loss: 1.568794\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [256/3654 (7%)], Loss: 1.474926\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [384/3654 (11%)], Loss: 1.458044[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [384/3654 (11%)], Loss: 1.477650\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [512/3654 (14%)], Loss: 1.456150\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [512/3654 (14%)], Loss: 1.489031\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [640/3654 (18%)], Loss: 1.450997\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [640/3654 (18%)], Loss: 1.442212\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [768/3654 (21%)], Loss: 1.532489\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [768/3654 (21%)], Loss: 1.490792\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [896/3654 (25%)], Loss: 1.483797\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [896/3654 (25%)], Loss: 1.454250\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [1024/3654 (28%)], Loss: 1.449344\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [1024/3654 (28%)], Loss: 1.412432\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [1152/3654 (32%)], Loss: 1.498020\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [1152/3654 (32%)], Loss: 1.471948\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [1280/3654 (35%)], Loss: 1.469859\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [1280/3654 (35%)], Loss: 1.478154\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [1408/3654 (39%)], Loss: 1.520243[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [1408/3654 (39%)], Loss: 1.553924\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [1536/3654 (42%)], Loss: 1.470496\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [1536/3654 (42%)], Loss: 1.445050\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [1664/3654 (46%)], Loss: 1.573994[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [1664/3654 (46%)], Loss: 1.463878\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [1792/3654 (49%)], Loss: 1.511749\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [1792/3654 (49%)], Loss: 1.406011\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [1920/3654 (53%)], Loss: 1.550935\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [1920/3654 (53%)], Loss: 1.475200\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [2048/3654 (56%)], Loss: 1.447829\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [2048/3654 (56%)], Loss: 1.504730\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [2176/3654 (60%)], Loss: 1.454559\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [2176/3654 (60%)], Loss: 1.417254\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [2304/3654 (63%)], Loss: 1.440068\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [2304/3654 (63%)], Loss: 1.534293\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [2432/3654 (67%)], Loss: 1.518308\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [2432/3654 (67%)], Loss: 1.481180\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [2560/3654 (70%)], Loss: 1.458641\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [2560/3654 (70%)], Loss: 1.485945\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [2688/3654 (74%)], Loss: 1.391551\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [2688/3654 (74%)], Loss: 1.466649\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [2816/3654 (77%)], Loss: 1.470191\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [2816/3654 (77%)], Loss: 1.426905\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [2944/3654 (81%)], Loss: 1.449234\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [2944/3654 (81%)], Loss: 1.438124[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [3072/3654 (84%)], Loss: 1.465620\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [3072/3654 (84%)], Loss: 1.522913\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [3200/3654 (88%)], Loss: 1.454487\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [3200/3654 (88%)], Loss: 1.479293\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [3328/3654 (91%)], Loss: 1.410173\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [3328/3654 (91%)], Loss: 1.491595\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [3456/3654 (95%)], Loss: 1.533439\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [3456/3654 (95%)], Loss: 1.486236\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 9, Rank 0: [3584/3654 (98%)], Loss: 1.489646\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 9, Rank 1: [3584/3654 (98%)], Loss: 1.503173\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError[1,mpirank:0,algo-1]<stderr>:: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.5210, Accuracy: 464/1536 (30.21%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 10, Learning Rate: 5e-05[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [128/3654 (4%)], Loss: 1.528329\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [128/3654 (4%)], Loss: 1.547595\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [256/3654 (7%)], Loss: 1.494577\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [256/3654 (7%)], Loss: 1.447945\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [384/3654 (11%)], Loss: 1.465895[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [384/3654 (11%)], Loss: 1.469379[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [512/3654 (14%)], Loss: 1.564982\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [512/3654 (14%)], Loss: 1.465934\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [640/3654 (18%)], Loss: 1.517177\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [640/3654 (18%)], Loss: 1.438341\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [768/3654 (21%)], Loss: 1.517873\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [768/3654 (21%)], Loss: 1.468083\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [896/3654 (25%)], Loss: 1.497681\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [896/3654 (25%)], Loss: 1.586278[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [1024/3654 (28%)], Loss: 1.402822\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [1024/3654 (28%)], Loss: 1.458898\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [1152/3654 (32%)], Loss: 1.471497\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [1152/3654 (32%)], Loss: 1.396048\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [1280/3654 (35%)], Loss: 1.517679\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [1280/3654 (35%)], Loss: 1.455725[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [1408/3654 (39%)], Loss: 1.465709\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [1408/3654 (39%)], Loss: 1.459523\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [1536/3654 (42%)], Loss: 1.510233[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [1536/3654 (42%)], Loss: 1.450313\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [1664/3654 (46%)], Loss: 1.460223\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [1664/3654 (46%)], Loss: 1.482643[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [1792/3654 (49%)], Loss: 1.544951\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [1792/3654 (49%)], Loss: 1.382281[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [1920/3654 (53%)], Loss: 1.550867\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [1920/3654 (53%)], Loss: 1.504438\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [2048/3654 (56%)], Loss: 1.464192\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [2048/3654 (56%)], Loss: 1.488914\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [2176/3654 (60%)], Loss: 1.501774[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [2176/3654 (60%)], Loss: 1.538201\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [2304/3654 (63%)], Loss: 1.428474\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [2304/3654 (63%)], Loss: 1.460287\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [2432/3654 (67%)], Loss: 1.517290\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [2432/3654 (67%)], Loss: 1.487974\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [2560/3654 (70%)], Loss: 1.492689\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [2560/3654 (70%)], Loss: 1.455626\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [2688/3654 (74%)], Loss: 1.455945\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [2688/3654 (74%)], Loss: 1.501133\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [2816/3654 (77%)], Loss: 1.440580\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [2816/3654 (77%)], Loss: 1.454147\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [2944/3654 (81%)], Loss: 1.495503\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [2944/3654 (81%)], Loss: 1.465297\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [3072/3654 (84%)], Loss: 1.506503\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [3072/3654 (84%)], Loss: 1.566688\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [3200/3654 (88%)], Loss: 1.447609\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [3200/3654 (88%)], Loss: 1.511881\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [3328/3654 (91%)], Loss: 1.547900\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [3328/3654 (91%)], Loss: 1.445081\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [3456/3654 (95%)], Loss: 1.472935\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [3456/3654 (95%)], Loss: 1.550191\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 10, Rank 0: [3584/3654 (98%)], Loss: 1.516596\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 10, Rank 1: [3584/3654 (98%)], Loss: 1.465531\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.close()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError[1,mpirank:0,algo-1]<stderr>:: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4489, Accuracy: 500/1536 (32.55%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 11, Learning Rate: 5e-05[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [128/3654 (4%)], Loss: 1.569003[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [128/3654 (4%)], Loss: 1.462689\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [256/3654 (7%)], Loss: 1.508487\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [256/3654 (7%)], Loss: 1.536538\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [384/3654 (11%)], Loss: 1.493975[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [384/3654 (11%)], Loss: 1.421272\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [512/3654 (14%)], Loss: 1.456491\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [512/3654 (14%)], Loss: 1.487673\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [640/3654 (18%)], Loss: 1.480466\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [640/3654 (18%)], Loss: 1.502377\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [768/3654 (21%)], Loss: 1.490363\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [768/3654 (21%)], Loss: 1.463782\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [896/3654 (25%)], Loss: 1.432260\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [896/3654 (25%)], Loss: 1.549224\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [1024/3654 (28%)], Loss: 1.484711[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [1024/3654 (28%)], Loss: 1.461232\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [1152/3654 (32%)], Loss: 1.444500\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [1152/3654 (32%)], Loss: 1.509446\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [1280/3654 (35%)], Loss: 1.492300\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [1280/3654 (35%)], Loss: 1.493804\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [1408/3654 (39%)], Loss: 1.469985\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [1408/3654 (39%)], Loss: 1.485431\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [1536/3654 (42%)], Loss: 1.511331[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [1536/3654 (42%)], Loss: 1.527925\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [1664/3654 (46%)], Loss: 1.512702\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [1664/3654 (46%)], Loss: 1.461409\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [1792/3654 (49%)], Loss: 1.602606\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [1792/3654 (49%)], Loss: 1.541520\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [1920/3654 (53%)], Loss: 1.528042\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [1920/3654 (53%)], Loss: 1.551870\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [2048/3654 (56%)], Loss: 1.466985[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [2048/3654 (56%)], Loss: 1.491364\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [2176/3654 (60%)], Loss: 1.441857\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [2176/3654 (60%)], Loss: 1.547395\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [2304/3654 (63%)], Loss: 1.531927\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [2304/3654 (63%)], Loss: 1.513342\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [2432/3654 (67%)], Loss: 1.508630\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [2432/3654 (67%)], Loss: 1.544305\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [2560/3654 (70%)], Loss: 1.433357\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [2560/3654 (70%)], Loss: 1.483683\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [2688/3654 (74%)], Loss: 1.467507\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [2688/3654 (74%)], Loss: 1.485388\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [2816/3654 (77%)], Loss: 1.444160\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [2816/3654 (77%)], Loss: 1.464396\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [2944/3654 (81%)], Loss: 1.483579\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [2944/3654 (81%)], Loss: 1.534920\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [3072/3654 (84%)], Loss: 1.517773\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [3072/3654 (84%)], Loss: 1.447707[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [3200/3654 (88%)], Loss: 1.472967\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [3200/3654 (88%)], Loss: 1.496858\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [3328/3654 (91%)], Loss: 1.432799\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [3328/3654 (91%)], Loss: 1.471272\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [3456/3654 (95%)], Loss: 1.533445\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [3456/3654 (95%)], Loss: 1.486233\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 11, Rank 0: [3584/3654 (98%)], Loss: 1.417236\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 11, Rank 1: [3584/3654 (98%)], Loss: 1.544392\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4772, Accuracy: 448/1536 (29.17%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 12, Learning Rate: 5e-05\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [128/3654 (4%)], Loss: 1.510605\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [128/3654 (4%)], Loss: 1.531218\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [256/3654 (7%)], Loss: 1.448325[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [256/3654 (7%)], Loss: 1.486688\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [384/3654 (11%)], Loss: 1.520311\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [384/3654 (11%)], Loss: 1.480061\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [512/3654 (14%)], Loss: 1.416493\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [512/3654 (14%)], Loss: 1.446276\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [640/3654 (18%)], Loss: 1.455885[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [640/3654 (18%)], Loss: 1.462495\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [768/3654 (21%)], Loss: 1.482005\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [768/3654 (21%)], Loss: 1.504492\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [896/3654 (25%)], Loss: 1.464752[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [896/3654 (25%)], Loss: 1.410131\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [1024/3654 (28%)], Loss: 1.416469\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [1024/3654 (28%)], Loss: 1.473349\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [1152/3654 (32%)], Loss: 1.419177\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [1152/3654 (32%)], Loss: 1.429087\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [1280/3654 (35%)], Loss: 1.539847\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [1280/3654 (35%)], Loss: 1.436214\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [1408/3654 (39%)], Loss: 1.483210\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [1408/3654 (39%)], Loss: 1.461891\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [1536/3654 (42%)], Loss: 1.439739\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [1536/3654 (42%)], Loss: 1.511320\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [1664/3654 (46%)], Loss: 1.455519\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [1664/3654 (46%)], Loss: 1.542128\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [1792/3654 (49%)], Loss: 1.478135\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [1792/3654 (49%)], Loss: 1.403053\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [1920/3654 (53%)], Loss: 1.468997\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [1920/3654 (53%)], Loss: 1.466120\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [2048/3654 (56%)], Loss: 1.471180\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [2048/3654 (56%)], Loss: 1.441501\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [2176/3654 (60%)], Loss: 1.500843\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [2176/3654 (60%)], Loss: 1.489397\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [2304/3654 (63%)], Loss: 1.524184\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [2304/3654 (63%)], Loss: 1.499684\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [2432/3654 (67%)], Loss: 1.525976[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [2432/3654 (67%)], Loss: 1.500298\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [2560/3654 (70%)], Loss: 1.438813\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [2560/3654 (70%)], Loss: 1.513409\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [2688/3654 (74%)], Loss: 1.479122\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [2688/3654 (74%)], Loss: 1.507409\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [2816/3654 (77%)], Loss: 1.454100\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [2816/3654 (77%)], Loss: 1.455939\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [2944/3654 (81%)], Loss: 1.422320\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [2944/3654 (81%)], Loss: 1.491476\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [3072/3654 (84%)], Loss: 1.480838[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [3072/3654 (84%)], Loss: 1.534822\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [3200/3654 (88%)], Loss: 1.464109\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [3200/3654 (88%)], Loss: 1.435396[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [3328/3654 (91%)], Loss: 1.542462\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [3328/3654 (91%)], Loss: 1.407399\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [3456/3654 (95%)], Loss: 1.427702\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [3456/3654 (95%)], Loss: 1.456954\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 12, Rank 1: [3584/3654 (98%)], Loss: 1.436827\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 12, Rank 0: [3584/3654 (98%)], Loss: 1.487547\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4287, Accuracy: 464/1536 (30.21%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 13, Learning Rate: 5e-05\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [128/3654 (4%)], Loss: 1.456497\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [128/3654 (4%)], Loss: 1.407813\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [256/3654 (7%)], Loss: 1.468684\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [256/3654 (7%)], Loss: 1.515920\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [384/3654 (11%)], Loss: 1.418260\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [384/3654 (11%)], Loss: 1.474622\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [512/3654 (14%)], Loss: 1.484197\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [512/3654 (14%)], Loss: 1.525121\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [640/3654 (18%)], Loss: 1.478571\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [640/3654 (18%)], Loss: 1.456159\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [768/3654 (21%)], Loss: 1.450103\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [768/3654 (21%)], Loss: 1.494393\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [896/3654 (25%)], Loss: 1.567993[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [896/3654 (25%)], Loss: 1.477685\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [1024/3654 (28%)], Loss: 1.472191\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [1024/3654 (28%)], Loss: 1.401288\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [1152/3654 (32%)], Loss: 1.476199\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [1152/3654 (32%)], Loss: 1.483288\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [1280/3654 (35%)], Loss: 1.514317\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [1280/3654 (35%)], Loss: 1.532506\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [1408/3654 (39%)], Loss: 1.455340\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [1408/3654 (39%)], Loss: 1.491256[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [1536/3654 (42%)], Loss: 1.587307\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [1536/3654 (42%)], Loss: 1.510009\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [1664/3654 (46%)], Loss: 1.533688\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [1664/3654 (46%)], Loss: 1.532290\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [1792/3654 (49%)], Loss: 1.451021\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [1792/3654 (49%)], Loss: 1.502243\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [1920/3654 (53%)], Loss: 1.471693\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [1920/3654 (53%)], Loss: 1.545777\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [2048/3654 (56%)], Loss: 1.442697[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [2048/3654 (56%)], Loss: 1.524401\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [2176/3654 (60%)], Loss: 1.471559[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [2176/3654 (60%)], Loss: 1.479877\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [2304/3654 (63%)], Loss: 1.439127\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [2304/3654 (63%)], Loss: 1.425005\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [2432/3654 (67%)], Loss: 1.482099\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [2432/3654 (67%)], Loss: 1.426121[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [2560/3654 (70%)], Loss: 1.516133\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [2560/3654 (70%)], Loss: 1.467038\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [2688/3654 (74%)], Loss: 1.423822\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [2688/3654 (74%)], Loss: 1.501705\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [2816/3654 (77%)], Loss: 1.513139\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [2816/3654 (77%)], Loss: 1.591494\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [2944/3654 (81%)], Loss: 1.494892\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [2944/3654 (81%)], Loss: 1.525768\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [3072/3654 (84%)], Loss: 1.442537\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [3072/3654 (84%)], Loss: 1.479950[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [3200/3654 (88%)], Loss: 1.466274\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [3200/3654 (88%)], Loss: 1.427671\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [3328/3654 (91%)], Loss: 1.472422\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [3328/3654 (91%)], Loss: 1.458670\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [3456/3654 (95%)], Loss: 1.544275\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [3456/3654 (95%)], Loss: 1.437263\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 13, Rank 0: [3584/3654 (98%)], Loss: 1.464798\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 13, Rank 1: [3584/3654 (98%)], Loss: 1.457754\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError[1,mpirank:0,algo-1]<stderr>:: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4488, Accuracy: 476/1536 (30.99%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 14, Learning Rate: 5e-05\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [128/3654 (4%)], Loss: 1.453379\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [128/3654 (4%)], Loss: 1.487049\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [256/3654 (7%)], Loss: 1.428524\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [256/3654 (7%)], Loss: 1.478569\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [384/3654 (11%)], Loss: 1.519224\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [384/3654 (11%)], Loss: 1.408889\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [512/3654 (14%)], Loss: 1.451106\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [512/3654 (14%)], Loss: 1.447973\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [640/3654 (18%)], Loss: 1.451416\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [640/3654 (18%)], Loss: 1.477260\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [768/3654 (21%)], Loss: 1.435547\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [768/3654 (21%)], Loss: 1.513974\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [896/3654 (25%)], Loss: 1.433313\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [896/3654 (25%)], Loss: 1.464213\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [1024/3654 (28%)], Loss: 1.451229[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [1024/3654 (28%)], Loss: 1.479036\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [1152/3654 (32%)], Loss: 1.445152\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [1152/3654 (32%)], Loss: 1.444402\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [1280/3654 (35%)], Loss: 1.414284[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [1280/3654 (35%)], Loss: 1.507402\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [1408/3654 (39%)], Loss: 1.457040\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [1408/3654 (39%)], Loss: 1.420027\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [1536/3654 (42%)], Loss: 1.427711[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [1536/3654 (42%)], Loss: 1.443076\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [1664/3654 (46%)], Loss: 1.521182\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [1664/3654 (46%)], Loss: 1.481959\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [1792/3654 (49%)], Loss: 1.514218\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [1792/3654 (49%)], Loss: 1.439361\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [1920/3654 (53%)], Loss: 1.571084\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [1920/3654 (53%)], Loss: 1.457652\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [2048/3654 (56%)], Loss: 1.495604\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [2048/3654 (56%)], Loss: 1.527603\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [2176/3654 (60%)], Loss: 1.542762\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [2176/3654 (60%)], Loss: 1.460815[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [2304/3654 (63%)], Loss: 1.423844\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [2304/3654 (63%)], Loss: 1.491970\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [2432/3654 (67%)], Loss: 1.426918\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [2432/3654 (67%)], Loss: 1.584310\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [2560/3654 (70%)], Loss: 1.438599\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [2560/3654 (70%)], Loss: 1.530365\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [2688/3654 (74%)], Loss: 1.503181\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [2688/3654 (74%)], Loss: 1.453062\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [2816/3654 (77%)], Loss: 1.423767\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [2816/3654 (77%)], Loss: 1.528138\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [2944/3654 (81%)], Loss: 1.467661\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [2944/3654 (81%)], Loss: 1.476989\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [3072/3654 (84%)], Loss: 1.464018\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [3072/3654 (84%)], Loss: 1.441693\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [3200/3654 (88%)], Loss: 1.542891\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [3200/3654 (88%)], Loss: 1.492426\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [3328/3654 (91%)], Loss: 1.462127\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [3328/3654 (91%)], Loss: 1.513888\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [3456/3654 (95%)], Loss: 1.426689\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [3456/3654 (95%)], Loss: 1.519498\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 14, Rank 1: [3584/3654 (98%)], Loss: 1.422316\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 14, Rank 0: [3584/3654 (98%)], Loss: 1.439574\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:1,algo-2]<stderr>:\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4364, Accuracy: 484/1536 (31.51%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 15, Learning Rate: 2.5e-05[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [128/3654 (4%)], Loss: 1.522744\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [128/3654 (4%)], Loss: 1.528369\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [256/3654 (7%)], Loss: 1.444238\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [256/3654 (7%)], Loss: 1.445744\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [384/3654 (11%)], Loss: 1.494916[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [384/3654 (11%)], Loss: 1.460050\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [512/3654 (14%)], Loss: 1.527018\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [512/3654 (14%)], Loss: 1.504483[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [640/3654 (18%)], Loss: 1.497801\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [640/3654 (18%)], Loss: 1.511716\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [768/3654 (21%)], Loss: 1.478683\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [768/3654 (21%)], Loss: 1.421581\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [896/3654 (25%)], Loss: 1.450053\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [896/3654 (25%)], Loss: 1.403998\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [1024/3654 (28%)], Loss: 1.454310\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [1024/3654 (28%)], Loss: 1.442593\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [1152/3654 (32%)], Loss: 1.369507\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [1152/3654 (32%)], Loss: 1.452975\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [1280/3654 (35%)], Loss: 1.502386\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [1280/3654 (35%)], Loss: 1.446470\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [1408/3654 (39%)], Loss: 1.406181[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [1408/3654 (39%)], Loss: 1.449265\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [1536/3654 (42%)], Loss: 1.472654[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [1536/3654 (42%)], Loss: 1.476863\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [1664/3654 (46%)], Loss: 1.486007[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [1664/3654 (46%)], Loss: 1.423928\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [1792/3654 (49%)], Loss: 1.445814\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [1792/3654 (49%)], Loss: 1.482156\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [1920/3654 (53%)], Loss: 1.424200\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [1920/3654 (53%)], Loss: 1.428083[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [2048/3654 (56%)], Loss: 1.464229\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [2048/3654 (56%)], Loss: 1.431783\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [2176/3654 (60%)], Loss: 1.433747\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [2176/3654 (60%)], Loss: 1.545323\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [2304/3654 (63%)], Loss: 1.442879\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [2304/3654 (63%)], Loss: 1.410384\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [2432/3654 (67%)], Loss: 1.480524\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [2432/3654 (67%)], Loss: 1.460232\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [2560/3654 (70%)], Loss: 1.422944[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [2560/3654 (70%)], Loss: 1.549670\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [2688/3654 (74%)], Loss: 1.381676\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [2688/3654 (74%)], Loss: 1.478567\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [2816/3654 (77%)], Loss: 1.518675\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [2816/3654 (77%)], Loss: 1.508985\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [2944/3654 (81%)], Loss: 1.442579\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [2944/3654 (81%)], Loss: 1.399165\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [3072/3654 (84%)], Loss: 1.406738\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [3072/3654 (84%)], Loss: 1.492019\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [3200/3654 (88%)], Loss: 1.472566\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [3200/3654 (88%)], Loss: 1.430765\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [3328/3654 (91%)], Loss: 1.533824\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [3328/3654 (91%)], Loss: 1.484999\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [3456/3654 (95%)], Loss: 1.462397[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [3456/3654 (95%)], Loss: 1.473929\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 15, Rank 1: [3584/3654 (98%)], Loss: 1.556006\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 15, Rank 0: [3584/3654 (98%)], Loss: 1.461096\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError\n",
      "[1,mpirank:0,algo-1]<stderr>:: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4289, Accuracy: 456/1536 (29.69%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 16, Learning Rate: 2.5e-05\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [128/3654 (4%)], Loss: 1.429183\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [128/3654 (4%)], Loss: 1.516841\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [256/3654 (7%)], Loss: 1.525212\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [256/3654 (7%)], Loss: 1.475731\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [384/3654 (11%)], Loss: 1.404687[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [384/3654 (11%)], Loss: 1.491537\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [512/3654 (14%)], Loss: 1.511579\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [512/3654 (14%)], Loss: 1.569355\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [640/3654 (18%)], Loss: 1.481230\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [640/3654 (18%)], Loss: 1.402329\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [768/3654 (21%)], Loss: 1.468013\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [768/3654 (21%)], Loss: 1.451253\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [896/3654 (25%)], Loss: 1.494018\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [896/3654 (25%)], Loss: 1.501346\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [1024/3654 (28%)], Loss: 1.542161\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [1024/3654 (28%)], Loss: 1.495878\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [1152/3654 (32%)], Loss: 1.499408\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [1152/3654 (32%)], Loss: 1.449078\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [1280/3654 (35%)], Loss: 1.524840[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [1280/3654 (35%)], Loss: 1.489969\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [1408/3654 (39%)], Loss: 1.492962\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [1408/3654 (39%)], Loss: 1.531714\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [1536/3654 (42%)], Loss: 1.418903\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [1536/3654 (42%)], Loss: 1.461990\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [1664/3654 (46%)], Loss: 1.487387\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [1664/3654 (46%)], Loss: 1.446911\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [1792/3654 (49%)], Loss: 1.482403[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [1792/3654 (49%)], Loss: 1.486389\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [1920/3654 (53%)], Loss: 1.485848\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [1920/3654 (53%)], Loss: 1.443703\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [2048/3654 (56%)], Loss: 1.489895\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [2048/3654 (56%)], Loss: 1.444085\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [2176/3654 (60%)], Loss: 1.411991\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [2176/3654 (60%)], Loss: 1.414335\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [2304/3654 (63%)], Loss: 1.463981\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [2304/3654 (63%)], Loss: 1.463742\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [2432/3654 (67%)], Loss: 1.465098\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [2432/3654 (67%)], Loss: 1.527271[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [2560/3654 (70%)], Loss: 1.469792\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [2560/3654 (70%)], Loss: 1.447506\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [2688/3654 (74%)], Loss: 1.471797\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [2688/3654 (74%)], Loss: 1.466477\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [2816/3654 (77%)], Loss: 1.417522\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [2816/3654 (77%)], Loss: 1.446634\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [2944/3654 (81%)], Loss: 1.465088\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [2944/3654 (81%)], Loss: 1.404110\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [3072/3654 (84%)], Loss: 1.342738\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [3072/3654 (84%)], Loss: 1.427379\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [3200/3654 (88%)], Loss: 1.509837\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [3200/3654 (88%)], Loss: 1.442094\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [3328/3654 (91%)], Loss: 1.559624\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [3328/3654 (91%)], Loss: 1.495512\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [3456/3654 (95%)], Loss: 1.464664\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [3456/3654 (95%)], Loss: 1.484739\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 16, Rank 0: [3584/3654 (98%)], Loss: 1.364791\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 16, Rank 1: [3584/3654 (98%)], Loss: 1.478156\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>[1,mpirank:1,algo-2]<stderr>:\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:1,algo-2]<stderr>:\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4169, Accuracy: 508/1536 (33.07%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 17, Learning Rate: 2.5e-05\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [128/3654 (4%)], Loss: 1.460950\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [128/3654 (4%)], Loss: 1.496969\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [256/3654 (7%)], Loss: 1.531100\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [256/3654 (7%)], Loss: 1.579649[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [384/3654 (11%)], Loss: 1.443695\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [384/3654 (11%)], Loss: 1.476029\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [512/3654 (14%)], Loss: 1.418615\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [512/3654 (14%)], Loss: 1.495961\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [640/3654 (18%)], Loss: 1.460274\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [640/3654 (18%)], Loss: 1.447005\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [768/3654 (21%)], Loss: 1.462378\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [768/3654 (21%)], Loss: 1.478113\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [896/3654 (25%)], Loss: 1.481217[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [896/3654 (25%)], Loss: 1.467885\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [1024/3654 (28%)], Loss: 1.515829\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [1024/3654 (28%)], Loss: 1.392526\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [1152/3654 (32%)], Loss: 1.470060\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [1152/3654 (32%)], Loss: 1.431930\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [1280/3654 (35%)], Loss: 1.446267\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [1280/3654 (35%)], Loss: 1.488858\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [1408/3654 (39%)], Loss: 1.487452\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [1408/3654 (39%)], Loss: 1.471810\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [1536/3654 (42%)], Loss: 1.415640\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [1536/3654 (42%)], Loss: 1.442230\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [1664/3654 (46%)], Loss: 1.445387[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [1664/3654 (46%)], Loss: 1.418441\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [1792/3654 (49%)], Loss: 1.470683\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [1792/3654 (49%)], Loss: 1.448293\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [1920/3654 (53%)], Loss: 1.425519\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [1920/3654 (53%)], Loss: 1.445624\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [2048/3654 (56%)], Loss: 1.602492\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [2048/3654 (56%)], Loss: 1.442212\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [2176/3654 (60%)], Loss: 1.492965[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [2176/3654 (60%)], Loss: 1.406561\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [2304/3654 (63%)], Loss: 1.497781\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [2304/3654 (63%)], Loss: 1.502362\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [2432/3654 (67%)], Loss: 1.523560\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [2432/3654 (67%)], Loss: 1.504331\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [2560/3654 (70%)], Loss: 1.448733\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [2560/3654 (70%)], Loss: 1.520780\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [2688/3654 (74%)], Loss: 1.481464\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [2688/3654 (74%)], Loss: 1.431665\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [2816/3654 (77%)], Loss: 1.479723\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [2816/3654 (77%)], Loss: 1.526147\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [2944/3654 (81%)], Loss: 1.429453\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [2944/3654 (81%)], Loss: 1.459565\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [3072/3654 (84%)], Loss: 1.471974\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [3072/3654 (84%)], Loss: 1.429813\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [3200/3654 (88%)], Loss: 1.482912\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [3200/3654 (88%)], Loss: 1.384408\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [3328/3654 (91%)], Loss: 1.471154\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [3328/3654 (91%)], Loss: 1.527723\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [3456/3654 (95%)], Loss: 1.443266\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [3456/3654 (95%)], Loss: 1.387988\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 17, Rank 0: [3584/3654 (98%)], Loss: 1.502779\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 17, Rank 1: [3584/3654 (98%)], Loss: 1.438049\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4347, Accuracy: 448/1536 (29.17%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 18, Learning Rate: 2.5e-05\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [128/3654 (4%)], Loss: 1.462837\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [128/3654 (4%)], Loss: 1.442932\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [256/3654 (7%)], Loss: 1.480152\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [256/3654 (7%)], Loss: 1.421076\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [384/3654 (11%)], Loss: 1.441505\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [384/3654 (11%)], Loss: 1.454956\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [512/3654 (14%)], Loss: 1.433201\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [512/3654 (14%)], Loss: 1.432313\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [640/3654 (18%)], Loss: 1.563823\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [640/3654 (18%)], Loss: 1.404291\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [768/3654 (21%)], Loss: 1.483131[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [768/3654 (21%)], Loss: 1.431005\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [896/3654 (25%)], Loss: 1.476351\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [896/3654 (25%)], Loss: 1.481587\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [1024/3654 (28%)], Loss: 1.503605\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [1024/3654 (28%)], Loss: 1.433377\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [1152/3654 (32%)], Loss: 1.420733\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [1152/3654 (32%)], Loss: 1.411014\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [1280/3654 (35%)], Loss: 1.390844\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [1280/3654 (35%)], Loss: 1.488844\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [1408/3654 (39%)], Loss: 1.482072\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [1408/3654 (39%)], Loss: 1.510365\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [1536/3654 (42%)], Loss: 1.537434\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [1536/3654 (42%)], Loss: 1.415219\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [1664/3654 (46%)], Loss: 1.445401[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [1664/3654 (46%)], Loss: 1.448242\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [1792/3654 (49%)], Loss: 1.495257\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [1792/3654 (49%)], Loss: 1.428072\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [1920/3654 (53%)], Loss: 1.435957\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [1920/3654 (53%)], Loss: 1.503339\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [2048/3654 (56%)], Loss: 1.483995\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [2048/3654 (56%)], Loss: 1.453827\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [2176/3654 (60%)], Loss: 1.420590\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [2176/3654 (60%)], Loss: 1.398284[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [2304/3654 (63%)], Loss: 1.417994\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [2304/3654 (63%)], Loss: 1.476429\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [2432/3654 (67%)], Loss: 1.434071\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [2432/3654 (67%)], Loss: 1.467080\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [2560/3654 (70%)], Loss: 1.416688\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [2560/3654 (70%)], Loss: 1.448096\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [2688/3654 (74%)], Loss: 1.508802\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [2688/3654 (74%)], Loss: 1.440308\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [2816/3654 (77%)], Loss: 1.387012\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [2816/3654 (77%)], Loss: 1.483125\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [2944/3654 (81%)], Loss: 1.468708[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [2944/3654 (81%)], Loss: 1.474248\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [3072/3654 (84%)], Loss: 1.440765\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [3072/3654 (84%)], Loss: 1.421497\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [3200/3654 (88%)], Loss: 1.325437\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [3200/3654 (88%)], Loss: 1.471245\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [3328/3654 (91%)], Loss: 1.426149\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [3328/3654 (91%)], Loss: 1.492147\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [3456/3654 (95%)], Loss: 1.421942\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [3456/3654 (95%)], Loss: 1.457304\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 18, Rank 1: [3584/3654 (98%)], Loss: 1.536599\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 18, Rank 0: [3584/3654 (98%)], Loss: 1.388291\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError[1,mpirank:0,algo-1]<stderr>:: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000003.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    [1,mpirank:1,algo-2]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError[1,mpirank:0,algo-1]<stderr>:: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError[1,mpirank:0,algo-1]<stderr>:: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4006, Accuracy: 556/1536 (36.20%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 19, Learning Rate: 2.5e-05\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [128/3654 (4%)], Loss: 1.505162\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [128/3654 (4%)], Loss: 1.436012\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [256/3654 (7%)], Loss: 1.446746\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [256/3654 (7%)], Loss: 1.496234\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [384/3654 (11%)], Loss: 1.545558[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [384/3654 (11%)], Loss: 1.457339\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [512/3654 (14%)], Loss: 1.420091\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [512/3654 (14%)], Loss: 1.562877\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [640/3654 (18%)], Loss: 1.383935[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [640/3654 (18%)], Loss: 1.452202\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [768/3654 (21%)], Loss: 1.560910\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [768/3654 (21%)], Loss: 1.461505[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [896/3654 (25%)], Loss: 1.438733\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [896/3654 (25%)], Loss: 1.485991\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [1024/3654 (28%)], Loss: 1.461732\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [1024/3654 (28%)], Loss: 1.387876\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [1152/3654 (32%)], Loss: 1.403401\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [1152/3654 (32%)], Loss: 1.525477\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [1280/3654 (35%)], Loss: 1.506442\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [1280/3654 (35%)], Loss: 1.531721\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [1408/3654 (39%)], Loss: 1.421686\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [1408/3654 (39%)], Loss: 1.462732\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [1536/3654 (42%)], Loss: 1.434656\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [1536/3654 (42%)], Loss: 1.392442\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [1664/3654 (46%)], Loss: 1.437316\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [1664/3654 (46%)], Loss: 1.486902[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [1792/3654 (49%)], Loss: 1.444985\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [1792/3654 (49%)], Loss: 1.448757\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [1920/3654 (53%)], Loss: 1.496276\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [1920/3654 (53%)], Loss: 1.479412\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [2048/3654 (56%)], Loss: 1.567341[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [2048/3654 (56%)], Loss: 1.527894\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [2176/3654 (60%)], Loss: 1.474029\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [2176/3654 (60%)], Loss: 1.481484\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [2304/3654 (63%)], Loss: 1.483388\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [2304/3654 (63%)], Loss: 1.461647\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [2432/3654 (67%)], Loss: 1.424168\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [2432/3654 (67%)], Loss: 1.452404\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [2560/3654 (70%)], Loss: 1.489007\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [2560/3654 (70%)], Loss: 1.465938\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [2688/3654 (74%)], Loss: 1.528580\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [2688/3654 (74%)], Loss: 1.432330\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [2816/3654 (77%)], Loss: 1.490207\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [2816/3654 (77%)], Loss: 1.467162\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [2944/3654 (81%)], Loss: 1.445503\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [2944/3654 (81%)], Loss: 1.450201\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [3072/3654 (84%)], Loss: 1.478773\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [3072/3654 (84%)], Loss: 1.458032\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [3200/3654 (88%)], Loss: 1.480038\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [3200/3654 (88%)], Loss: 1.510919[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [3328/3654 (91%)], Loss: 1.396193\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [3328/3654 (91%)], Loss: 1.444926\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [3456/3654 (95%)], Loss: 1.473319\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [3456/3654 (95%)], Loss: 1.401772\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 19, Rank 0: [3584/3654 (98%)], Loss: 1.456571\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 19, Rank 1: [3584/3654 (98%)], Loss: 1.437237\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4161, Accuracy: 560/1536 (36.46%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 20, Learning Rate: 1.25e-05\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [128/3654 (4%)], Loss: 1.479985\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [128/3654 (4%)], Loss: 1.515068\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [256/3654 (7%)], Loss: 1.426693\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [256/3654 (7%)], Loss: 1.463946\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [384/3654 (11%)], Loss: 1.545624\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [384/3654 (11%)], Loss: 1.432675\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [512/3654 (14%)], Loss: 1.429934[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [512/3654 (14%)], Loss: 1.462184\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [640/3654 (18%)], Loss: 1.418023\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [640/3654 (18%)], Loss: 1.462732\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [768/3654 (21%)], Loss: 1.422758\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [768/3654 (21%)], Loss: 1.372981\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [896/3654 (25%)], Loss: 1.506872[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [896/3654 (25%)], Loss: 1.440087[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [1024/3654 (28%)], Loss: 1.461027\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [1024/3654 (28%)], Loss: 1.489745\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [1152/3654 (32%)], Loss: 1.404119\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [1152/3654 (32%)], Loss: 1.424956\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [1280/3654 (35%)], Loss: 1.451889\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [1280/3654 (35%)], Loss: 1.514653\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [1408/3654 (39%)], Loss: 1.410412\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [1408/3654 (39%)], Loss: 1.378440\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [1536/3654 (42%)], Loss: 1.509420\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [1536/3654 (42%)], Loss: 1.425050\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [1664/3654 (46%)], Loss: 1.452212\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [1664/3654 (46%)], Loss: 1.498385\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [1792/3654 (49%)], Loss: 1.451711\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [1792/3654 (49%)], Loss: 1.450494\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [1920/3654 (53%)], Loss: 1.531381[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [1920/3654 (53%)], Loss: 1.472146\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [2048/3654 (56%)], Loss: 1.408557\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [2048/3654 (56%)], Loss: 1.376749\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [2176/3654 (60%)], Loss: 1.431118\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [2176/3654 (60%)], Loss: 1.412751\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [2304/3654 (63%)], Loss: 1.430958[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [2304/3654 (63%)], Loss: 1.469082\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [2432/3654 (67%)], Loss: 1.484432\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [2432/3654 (67%)], Loss: 1.428916\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [2560/3654 (70%)], Loss: 1.461185\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [2560/3654 (70%)], Loss: 1.475744\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [2688/3654 (74%)], Loss: 1.510277\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [2688/3654 (74%)], Loss: 1.431878\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [2816/3654 (77%)], Loss: 1.466062\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [2816/3654 (77%)], Loss: 1.438770\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [2944/3654 (81%)], Loss: 1.450613\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [2944/3654 (81%)], Loss: 1.381627\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [3072/3654 (84%)], Loss: 1.512593\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [3072/3654 (84%)], Loss: 1.552523\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [3200/3654 (88%)], Loss: 1.476250\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [3200/3654 (88%)], Loss: 1.520661\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [3328/3654 (91%)], Loss: 1.509924\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [3328/3654 (91%)], Loss: 1.510356[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [3456/3654 (95%)], Loss: 1.449672\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [3456/3654 (95%)], Loss: 1.488492\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 20, Rank 1: [3584/3654 (98%)], Loss: 1.505048\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 20, Rank 0: [3584/3654 (98%)], Loss: 1.375346\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()[1,mpirank:1,algo-2]<stderr>:\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:1,algo-2]<stderr>:\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError[1,mpirank:0,algo-1]<stderr>:: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000001.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError:\n",
      "[1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4319, Accuracy: 528/1536 (34.38%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 21, Learning Rate: 1.25e-05\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [128/3654 (4%)], Loss: 1.378175\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [128/3654 (4%)], Loss: 1.367744\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [256/3654 (7%)], Loss: 1.417248[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [256/3654 (7%)], Loss: 1.426495\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [384/3654 (11%)], Loss: 1.445946\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [384/3654 (11%)], Loss: 1.404373\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [512/3654 (14%)], Loss: 1.432195\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [512/3654 (14%)], Loss: 1.492660\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [640/3654 (18%)], Loss: 1.386567\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [640/3654 (18%)], Loss: 1.364797\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [768/3654 (21%)], Loss: 1.494581[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [768/3654 (21%)], Loss: 1.439432\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [896/3654 (25%)], Loss: 1.415260[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [896/3654 (25%)], Loss: 1.443091\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [1024/3654 (28%)], Loss: 1.458371\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [1024/3654 (28%)], Loss: 1.437971\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [1152/3654 (32%)], Loss: 1.385898\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [1152/3654 (32%)], Loss: 1.418174\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [1280/3654 (35%)], Loss: 1.362900\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [1280/3654 (35%)], Loss: 1.469157\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [1408/3654 (39%)], Loss: 1.392858\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [1408/3654 (39%)], Loss: 1.480778\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [1536/3654 (42%)], Loss: 1.474155[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [1536/3654 (42%)], Loss: 1.397941\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [1664/3654 (46%)], Loss: 1.401571\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [1664/3654 (46%)], Loss: 1.423903\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [1792/3654 (49%)], Loss: 1.472039\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [1792/3654 (49%)], Loss: 1.458555\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [1920/3654 (53%)], Loss: 1.441958[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [1920/3654 (53%)], Loss: 1.435483\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [2048/3654 (56%)], Loss: 1.479151\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [2048/3654 (56%)], Loss: 1.446755\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [2176/3654 (60%)], Loss: 1.385155\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [2176/3654 (60%)], Loss: 1.447796\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [2304/3654 (63%)], Loss: 1.427708\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [2304/3654 (63%)], Loss: 1.442782\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [2432/3654 (67%)], Loss: 1.465961\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [2432/3654 (67%)], Loss: 1.583273\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [2560/3654 (70%)], Loss: 1.409574\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [2560/3654 (70%)], Loss: 1.489322\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [2688/3654 (74%)], Loss: 1.563652\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [2688/3654 (74%)], Loss: 1.470355\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [2816/3654 (77%)], Loss: 1.420182\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [2816/3654 (77%)], Loss: 1.452648\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [2944/3654 (81%)], Loss: 1.457541\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [2944/3654 (81%)], Loss: 1.533936\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [3072/3654 (84%)], Loss: 1.424474\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [3072/3654 (84%)], Loss: 1.415270\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [3200/3654 (88%)], Loss: 1.500586\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [3200/3654 (88%)], Loss: 1.523115\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [3328/3654 (91%)], Loss: 1.436647\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [3328/3654 (91%)], Loss: 1.483154\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [3456/3654 (95%)], Loss: 1.464190\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [3456/3654 (95%)], Loss: 1.526368\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 21, Rank 0: [3584/3654 (98%)], Loss: 1.406724\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 21, Rank 1: [3584/3654 (98%)], Loss: 1.426949\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError[1,mpirank:0,algo-1]<stderr>:: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4207, Accuracy: 508/1536 (33.07%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 22, Learning Rate: 1.25e-05\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [128/3654 (4%)], Loss: 1.451372\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [128/3654 (4%)], Loss: 1.403508\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [256/3654 (7%)], Loss: 1.423537\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [256/3654 (7%)], Loss: 1.475039\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [384/3654 (11%)], Loss: 1.406323\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [384/3654 (11%)], Loss: 1.437535\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [512/3654 (14%)], Loss: 1.423115\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [512/3654 (14%)], Loss: 1.376969\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [640/3654 (18%)], Loss: 1.476086\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [640/3654 (18%)], Loss: 1.436393\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [768/3654 (21%)], Loss: 1.368707\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [768/3654 (21%)], Loss: 1.487852\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [896/3654 (25%)], Loss: 1.539675\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [896/3654 (25%)], Loss: 1.391411\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [1024/3654 (28%)], Loss: 1.506837\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [1024/3654 (28%)], Loss: 1.410042\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [1152/3654 (32%)], Loss: 1.509242\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [1152/3654 (32%)], Loss: 1.441911\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [1280/3654 (35%)], Loss: 1.448360\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [1280/3654 (35%)], Loss: 1.413786\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [1408/3654 (39%)], Loss: 1.514059\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [1408/3654 (39%)], Loss: 1.381706\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [1536/3654 (42%)], Loss: 1.547270[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [1536/3654 (42%)], Loss: 1.438159\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [1664/3654 (46%)], Loss: 1.430886\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [1664/3654 (46%)], Loss: 1.461993\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [1792/3654 (49%)], Loss: 1.437923\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [1792/3654 (49%)], Loss: 1.457721\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [1920/3654 (53%)], Loss: 1.435110[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [1920/3654 (53%)], Loss: 1.557931\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [2048/3654 (56%)], Loss: 1.475409[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [2048/3654 (56%)], Loss: 1.402358\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [2176/3654 (60%)], Loss: 1.439918\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [2176/3654 (60%)], Loss: 1.497535[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [2304/3654 (63%)], Loss: 1.460379\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [2304/3654 (63%)], Loss: 1.423744\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [2432/3654 (67%)], Loss: 1.407098\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [2432/3654 (67%)], Loss: 1.454054\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [2560/3654 (70%)], Loss: 1.436302\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [2560/3654 (70%)], Loss: 1.389659\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [2688/3654 (74%)], Loss: 1.453044\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [2688/3654 (74%)], Loss: 1.442335\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [2816/3654 (77%)], Loss: 1.502390\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [2816/3654 (77%)], Loss: 1.508530[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [2944/3654 (81%)], Loss: 1.369309\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [2944/3654 (81%)], Loss: 1.547994\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [3072/3654 (84%)], Loss: 1.483950\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [3072/3654 (84%)], Loss: 1.440989[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [3200/3654 (88%)], Loss: 1.458617\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [3200/3654 (88%)], Loss: 1.491661\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [3328/3654 (91%)], Loss: 1.409127\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [3328/3654 (91%)], Loss: 1.402059\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [3456/3654 (95%)], Loss: 1.414770\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [3456/3654 (95%)], Loss: 1.446096[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 22, Rank 0: [3584/3654 (98%)], Loss: 1.424030\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 22, Rank 1: [3584/3654 (98%)], Loss: 1.438240\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError[1,mpirank:0,algo-1]<stderr>:: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4337, Accuracy: 504/1536 (32.81%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 23, Learning Rate: 1.25e-05\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [128/3654 (4%)], Loss: 1.420136\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [128/3654 (4%)], Loss: 1.469108\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [256/3654 (7%)], Loss: 1.382022\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [256/3654 (7%)], Loss: 1.448924\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [384/3654 (11%)], Loss: 1.388816[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [384/3654 (11%)], Loss: 1.384252\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [512/3654 (14%)], Loss: 1.444270\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [512/3654 (14%)], Loss: 1.517713\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [640/3654 (18%)], Loss: 1.419244\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [640/3654 (18%)], Loss: 1.546945\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [768/3654 (21%)], Loss: 1.333220[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [768/3654 (21%)], Loss: 1.424086\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [896/3654 (25%)], Loss: 1.463294[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [896/3654 (25%)], Loss: 1.497697\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [1024/3654 (28%)], Loss: 1.421400\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [1024/3654 (28%)], Loss: 1.409576\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [1152/3654 (32%)], Loss: 1.471435\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [1152/3654 (32%)], Loss: 1.512674\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [1280/3654 (35%)], Loss: 1.420253\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [1280/3654 (35%)], Loss: 1.430590\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [1408/3654 (39%)], Loss: 1.480987\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [1408/3654 (39%)], Loss: 1.551666\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [1536/3654 (42%)], Loss: 1.465924\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [1536/3654 (42%)], Loss: 1.503347\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [1664/3654 (46%)], Loss: 1.480418\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [1664/3654 (46%)], Loss: 1.456569\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [1792/3654 (49%)], Loss: 1.456846\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [1792/3654 (49%)], Loss: 1.425622\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [1920/3654 (53%)], Loss: 1.454303\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [1920/3654 (53%)], Loss: 1.448608\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [2048/3654 (56%)], Loss: 1.508315\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [2048/3654 (56%)], Loss: 1.382374\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [2176/3654 (60%)], Loss: 1.477409[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [2176/3654 (60%)], Loss: 1.467433\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [2304/3654 (63%)], Loss: 1.382637\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [2304/3654 (63%)], Loss: 1.431477\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [2432/3654 (67%)], Loss: 1.389045\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [2432/3654 (67%)], Loss: 1.442655\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [2560/3654 (70%)], Loss: 1.436031\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [2560/3654 (70%)], Loss: 1.442392\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [2688/3654 (74%)], Loss: 1.457688\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [2688/3654 (74%)], Loss: 1.482195\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [2816/3654 (77%)], Loss: 1.442118\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [2816/3654 (77%)], Loss: 1.426999\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [2944/3654 (81%)], Loss: 1.467497\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [2944/3654 (81%)], Loss: 1.486657\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [3072/3654 (84%)], Loss: 1.502237\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [3072/3654 (84%)], Loss: 1.424477\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [3200/3654 (88%)], Loss: 1.490463\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [3200/3654 (88%)], Loss: 1.426650\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [3328/3654 (91%)], Loss: 1.451703\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [3328/3654 (91%)], Loss: 1.394638[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [3456/3654 (95%)], Loss: 1.430670\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [3456/3654 (95%)], Loss: 1.410905\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🔹 Train Epoch 23, Rank 1: [3584/3654 (98%)], Loss: 1.517416\n",
      "[1,mpirank:0,algo-1]<stdout>:🔹 Train Epoch 23, Rank 0: [3584/3654 (98%)], Loss: 1.453650\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:1,algo-2]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7f408453aa60>\n",
      "[1,mpirank:1,algo-2]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.close()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:1,algo-2]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:1,algo-2]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:1,algo-2]<stderr>:    [1,mpirank:1,algo-2]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:1,algo-2]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000005.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000002.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in:\n",
      "[1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError[1,mpirank:0,algo-1]<stderr>:: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000004.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/train/train-shard-000006.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError[1,mpirank:0,algo-1]<stderr>:: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/val/val-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4269, Accuracy: 520/1536 (33.85%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:⚠️ Early stopping aggregating 1035369423 from Rank 0...\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:⚠️ Early stopping at epoch 23 on Rank 0\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🟢 Start testing...\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/test/test-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/test/test-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError[1,mpirank:0,algo-1]<stderr>:: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/test/test-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError[1,mpirank:0,algo-1]<stderr>:: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/test/test-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/test/test-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:download failed: s3://p5-amazon-bin-images/webdataset/test/test-shard-000000.tar to - [Errno 32] Broken pipe\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: <function Pipe.__del__ at 0x7fde18457a60>\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError: (('aws s3 cp s3://p5-amazon-bin-images/webdataset/test/test-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stderr>:Exception ignored in: [1,mpirank:0,algo-1]<stderr>:<function Pipe.__del__ at 0x7fde18457a60>[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:Traceback (most recent call last):\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 121, in __del__\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.close()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 109, in close\n",
      "[1,mpirank:0,algo-1]<stderr>:    self.wait_for_child()\n",
      "[1,mpirank:0,algo-1]<stderr>:  File \"/opt/conda/lib/python3.9/site-packages/webdataset/gopen.py\", line 83, in wait_for_child\n",
      "[1,mpirank:0,algo-1]<stderr>:    [1,mpirank:0,algo-1]<stderr>:raise IOError(f\"{self.args}: exit {self.status} (read) {info}\")[1,mpirank:0,algo-1]<stderr>:\n",
      "[1,mpirank:0,algo-1]<stderr>:OSError\n",
      "[1,mpirank:0,algo-1]<stderr>:: [1,mpirank:0,algo-1]<stderr>:(('aws s3 cp s3://p5-amazon-bin-images/webdataset/test/test-shard-000000.tar -',), {'shell': True, 'bufsize': 8192}): exit 1 (read) {}\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 TEST: Average loss: 1.4599, Accuracy: 508/1536 (33.07%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🟢 Start saving the trained model...[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Model saved at '/opt/ml/model/model.pth'\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb:\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: \n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Run history:\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Rank 0, train_loss █▆▆█▆▅▇▄▅▅▆▅▄▄▄▃▃▄▄▄▃▄▃▄▆▆▅▄▄▃▃▄▃▄▃▄▃▁▄▄\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: val_accuracy_epoch ▁▅▃▄▅▄▄▆▅▅▆▄▅▅▅▄▆▄██▇▆▆▇\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb:     val_loss_epoch █▃▄▃▂▂▃▂▂▄▂▃▂▂▂▂▁▂▁▁▂▂▂▂\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: \n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Run summary:\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Rank 0, train_loss 1.45365\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: val_accuracy_epoch 33.85417\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb:     val_loss_epoch 1.42693\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: \n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: 🚀 View run p5-amazon-bin-job-20250208-041248-0q3ao9-algo-1 at: https://wandb.ai/nov05/udacity-awsmle-resnet34-amazon-bin/runs/p5-amazon-bin-job-20250208-041248-0q3ao9-algo-1\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: ⭐️ View project at: https://wandb.ai/nov05/udacity-awsmle-resnet34-amazon-bin\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Find logs at: ./wandb/run-20250208_101730-p5-amazon-bin-job-20250208-041248-0q3ao9-algo-1/logs\n",
      "--------------------------------------------------------------------------\n",
      "ORTE has lost communication with a remote daemon.\n",
      "  HNP daemon   : [[41139,0],0] on node algo-1\n",
      "  Remote daemon: [[41139,0],1] on node algo-2\n",
      "This is usually due to either a failure of the TCP network\n",
      "connection to the node, or possibly an internal failure of\n",
      "the daemon itself. We cannot recover from this failure, and\n",
      "therefore will terminate the job.\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "2025-02-08 11:06:07 Stopping - Stopping the training job\n",
      "2025-02-08 11:06:07 Uploading - Uploading generated training model\n",
      "2025-02-08 11:06:07 Stopped - Training job stopped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/08/25 05:06:50] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> Job ended with status <span style=\"color: #008700; text-decoration-color: #008700\">'Stopped'</span> rather than <span style=\"color: #008700; text-decoration-color: #008700\">'Completed'</span>. This could    <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py#8666\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8666</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         mean the job timed out or stopped early for some other reason:         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Consider checking whether it completed as you expect.                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/08/25 05:06:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m Job ended with status \u001b[38;2;0;135;0m'Stopped'\u001b[0m rather than \u001b[38;2;0;135;0m'Completed'\u001b[0m. This could    \u001b]8;id=314512;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=748119;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py#8666\u001b\\\u001b[2m8666\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         mean the job timed out or stopped early for some other reason:         \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Consider checking whether it completed as you expect.                  \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 6296\n",
      "Billable seconds: 6296\n",
      "CPU times: total: 1min 30s\n",
      "Wall time: 54min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#TODO: Create your training estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point='train_v1.py',  # Your training script that defines the ResNet50 model and training loop\n",
    "    source_dir='../scripts_train',  # Directory where your script and dependencies are stored\n",
    "    role=sagemaker_role_arn,\n",
    "    framework_version='1.13.1',  # Use the PyTorch version you need\n",
    "    py_version='py39',\n",
    "    instance_count=2,  ## multi-instance training, Udacity account level limit 2\n",
    "    # instance_type='ml.p3.2xlarge',  ## 16GB, Use GPU instances for deep learning\n",
    "    instance_type='ml.g4dn.xlarge',  ## 16GB, 1 GPU per instance\n",
    "    output_path=output_path,  ## if not specify, output to the sagemaker default bucket\n",
    "    hyperparameters=hyperparameters,\n",
    "    # use_spot_instances=True,\n",
    "## Debugger and profiler parameters\n",
    "    # rules=rules,\n",
    "    # debugger_hook_config=hook_config,    \n",
    "    # profiler_config=profiler_config,\n",
    "## Training using SMDataParallel Distributed Training Framework\n",
    "    # distribution={\"pytorchddp\": {\"enabled\": True}}  # mpirun, activates SMDDP AllReduce OR AllGather\n",
    "    # distribution={\"torch_distributed\": {\"enabled\": True}}  # torchrun, activates SMDDP AllGather\n",
    "    distribution={\"smdistributed\": {\"dataparallel\": { \"enabled\": True}}},  # mpirun, activates SMDDP AllReduce OR AllGather\n",
    ") \n",
    "# TODO: Fit your estimator\n",
    "from datetime import datetime\n",
    "estimator.fit(\n",
    "    wait=True,  \n",
    "    job_name=f\"p5-amazon-bin-job-{datetime.now().strftime('%Y%m%d-%H%M%S')}\", \n",
    "    ## Use WebDataset pipe to stream data instead \n",
    "    # inputs={\n",
    "    #     \"train\": train_data,  \n",
    "    #     \"validation\": val_data, \n",
    "    #     \"test\": test_data,\n",
    "    # },  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Baseline accuracy 28.125%, [wandb logs](https://wandb.ai/nov05/udacity-awsmle-resnet34-amazon-bin/runs/p5-amazon-bin-job-20250207-044502-xfnie3-algo-2?nw=nwusernov05)  \n",
    "  <img src=\"https://raw.githubusercontent.com/nov05/pictures/refs/heads/master/Udacity/20241119_aws-mle-nanodegree/2025-02-07%2005_28_14-baseline-p5-amazon-bin-job-20250207-044502-xfnie3-algo-2%20_%20udacity-awsmle-resnet.jpg\" width=800>  \n",
    "\n",
    "```log  \n",
    "[1,mpirank:0,algo-1]<stdout>:👉 TEST: Average loss: 1.4330, Accuracy: 432/1536 (28.12%)  \n",
    "[1,mpirank:0,algo-1]<stdout>:👉 Model saved at '/opt/ml/model/model.pth'\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: Run history:\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: Rank 0, train_loss ▇█▆▅▆▆▄█▅▅▅▅▅▄▃▃▄▅▄▃▆▅▄▄▄▃▄▄▅▄▃▃▆▆▄▅▅▁▃▃\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: val_accuracy_epoch ▁▆▂█▄▃▃▆▃▂▅▆▆▇▅▄▅▇▇▆▇▆▆▆\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb:     val_loss_epoch █▆▇▅▅▅▄▆▄▅▂▂▂▂▂▁▂▂▁▂▁▂▁▁\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: \n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: Run summary:\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: Rank 0, train_loss 1.3928\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: val_accuracy_epoch 28.125\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb:     val_loss_epoch 1.43298\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb:\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: 🚀 View run p5-amazon-bin-job-20250207-044502-xfnie3-algo-2 at: https://wandb.ai/nov05/udacity-awsmle-resnet34-amazon-bin/runs/p5-amazon-bin-job-20250207-044502-xfnie3-algo-2\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: ⭐️ View project at: https://wandb.ai/nov05/udacity-awsmle-resnet34-amazon-bin\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: Find logs at: ./wandb/run-20250207_104937-p5-amazon-bin-job-20250207-044502-xfnie3-algo-2/logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No class weights, 20 epochs, 36.46%  \n",
    "\n",
    "```log \n",
    "[1,mpirank:0,algo-1]<stdout>:👉 VAL: Average loss: 1.4161, Accuracy: 560/1536 (36.46%)\n",
    "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 20, Learning Rate: 1.25e-05\n",
    "[1,mpirank:0,algo-1]<stdout>:👉 TEST: Average loss: 1.4599, Accuracy: 508/1536 (33.07%)\n",
    "[1,mpirank:0,algo-1]<stdout>:🟢 Start saving the trained model...[1,mpirank:0,algo-1]<stdout>:\n",
    "[1,mpirank:0,algo-1]<stdout>:👉 Model saved at '/opt/ml/model/model.pth'\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: Run history:\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: Rank 0, train_loss █▆▆█▆▅▇▄▅▅▆▅▄▄▄▃▃▄▄▄▃▄▃▄▆▆▅▄▄▃▃▄▃▄▃▄▃▁▄▄\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: val_accuracy_epoch ▁▅▃▄▅▄▄▆▅▅▆▄▅▅▅▄▆▄██▇▆▆▇\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb:     val_loss_epoch █▃▄▃▂▂▃▂▂▄▂▃▂▂▂▂▁▂▁▁▂▂▂▂\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: \n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: Run summary:\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: Rank 0, train_loss 1.45365\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: val_accuracy_epoch 33.85417\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb:     val_loss_epoch 1.42693\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: \n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: 🚀 View run p5-amazon-bin-job-20250208-041248-0q3ao9-algo-1 at: https://wandb.ai/nov05/udacity-awsmle-resnet34-amazon-bin/runs/p5-amazon-bin-job-20250208-041248-0q3ao9-algo-1\n",
    "[1,mpirank:0,algo-1]<stderr>:wandb: ⭐️ View project at: https://wandb.ai/nov05/udacity-awsmle-resnet34-amazon-bin\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standout Suggestions\n",
    "You do not need to perform the tasks below to finish your project. However, you can attempt these tasks to turn your project into a more advanced portfolio piece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "**TODO:** Here you can perform hyperparameter tuning to increase the performance of your model. You are encouraged to \n",
    "- tune as many hyperparameters as you can to get the best performance from your model\n",
    "- explain why you chose to tune those particular hyperparameters and the ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar\n",
      "train_size: 7308, val_size: 1566, test_size: 1567\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/08/25 03:49:23] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> image_uri is not presented, retrieving image_uri based on            <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py#679\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">679</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         instance_type, framework etc.                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/08/25 03:49:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m image_uri is not presented, retrieving image_uri based on            \u001b]8;id=388480;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=151784;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py#679\u001b\\\u001b[2m679\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         instance_type, framework etc.                                        \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/08/25 03:49:24] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No finished training job found associated with this estimator.       <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\estimator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">estimator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\estimator.py#1914\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1914</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Please make sure this estimator is only used for building workflow   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         config                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/08/25 03:49:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No finished training job found associated with this estimator.       \u001b]8;id=404337;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\estimator.py\u001b\\\u001b[2mestimator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=439146;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\estimator.py#1914\u001b\\\u001b[2m1914\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         Please make sure this estimator is only used for building workflow   \u001b[2m                 \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         config                                                               \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> image_uri is not presented, retrieving image_uri based on            <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py#679\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">679</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         instance_type, framework etc.                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m image_uri is not presented, retrieving image_uri based on            \u001b]8;id=652585;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=166413;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py#679\u001b\\\u001b[2m679\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         instance_type, framework etc.                                        \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating hyperparameter tuning job with name:                          <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py#3383\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3383</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         p5-amazon-bin-hpo-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">250208</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0349</span>                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating hyperparameter tuning job with name:                          \u001b]8;id=123128;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=111499;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py#3383\u001b\\\u001b[2m3383\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         p5-amazon-bin-hpo-\u001b[1;36m250208\u001b[0m-\u001b[1;36m0349\u001b[0m                                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👉 p5-amazon-bin-hpo-250208-0349\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from datetime import datetime\n",
    "data_base_path = \"s3://p5-amazon-bin-images/webdataset/\"\n",
    "train_data_path = data_base_path + \"train/train-shard-{000000..000007}.tar\"\n",
    "val_data_path = data_base_path + \"val/val-shard-{000000..000001}.tar\"\n",
    "test_data_path = data_base_path + \"test/test-shard-{000000..000001}.tar\"\n",
    "print(train_data_path)\n",
    "output_path = \"s3://p5-amazon-bin-images-train/\"  \n",
    "## Manually set dataset sizes hyperparameters\n",
    "l = 10441  ## 10K dataset\n",
    "split_ratio=[0.7, 0.15, 0.15]\n",
    "train_data_size = int(l*split_ratio[0])\n",
    "val_data_size = int(l*split_ratio[1])\n",
    "test_data_size = l - train_data_size - val_data_size\n",
    "print(f\"train_size: {train_data_size}, val_size: {val_data_size}, test_size: {test_data_size}\")\n",
    "## s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000007}.tar\n",
    "## train_size: 7308, val_size: 1566, test_size: 1567\n",
    "#TODO: Create your hyperparameter search space\n",
    "## TODO: Declare your HP ranges, metrics etc.\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "hyperparameters = {\n",
    "    'epochs': 40,   \n",
    "    # 'batch-size': 128,  ## ⚠️ 256 causes ml.g4dn.xlarge memory issue\n",
    "    # 'opt-learning-rate': 8e-5,  \n",
    "    # 'opt-weight-decay': 1e-5,  \n",
    "    'lr-sched-step-size': 5,  \n",
    "    'lr-sched-gamma': 0.5,\n",
    "    'early-stopping-patience': 1000, ## use HPO Auto\n",
    "    'model-arch': 'resnet34', \n",
    "    'wandb': True,  \n",
    "    'debug': False, \n",
    "## input data \n",
    "    \"train-data-path\": train_data_path,\n",
    "    \"val-data-path\": val_data_path,\n",
    "    \"test-data-path\": test_data_path,\n",
    "    \"train-data-size\": train_data_size, \n",
    "    \"val-data-size\": val_data_size,\n",
    "    \"test-data-size\": test_data_size,\n",
    "    \"num-classes\": 5,\n",
    "    # \"class-weights-dict\": {\n",
    "    #     1: 1.7004885993485341, \n",
    "    #     2: 0.9083079599826012, \n",
    "    #     3: 0.7832708177044261, \n",
    "    #     4: 0.8799831436999579, \n",
    "    #     5: 1.1137066666666666\n",
    "    # },\n",
    "}\n",
    "hyperparameter_ranges = {\n",
    "    # 'epochs': IntegerParameter(20, 40, scaling_type=\"Auto\"),\n",
    "    'batch-size': CategoricalParameter([64, 128]),\n",
    "    'opt-learning-rate': ContinuousParameter(1e-6, 1e-5),\n",
    "    'opt-weight-decay': ContinuousParameter(1e-5, 1e-4),\n",
    "}\n",
    "objective_metric_name = \"eval_loss_epoch\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\n",
    "    \"Name\": \"eval_loss_epoch\", \n",
    "    \"Regex\": \"👉 VAL: Average loss: ([0-9.]+)\",\n",
    "}]\n",
    "## TODO: Create estimators for your HPs\n",
    "estimator = PyTorch(\n",
    "    entry_point='train_v1.py',  # Your training script that defines the ResNet50 model and training loop\n",
    "    source_dir='../scripts_train',  # Directory where your script and dependencies are stored\n",
    "    role=sagemaker_role_arn,\n",
    "    framework_version='1.13.1',  # Use the PyTorch version you need\n",
    "    py_version='py39',\n",
    "    instance_count=2,  # 👈 Adjust based on the number of instances you want to use\n",
    "    ## Running 2 ml.g4dn.xlarge instances concurrently would cost around $1.504 per hour in total.\n",
    "    instance_type='ml.g4dn.xlarge',  ## 16GB $0.752/hr, Use GPU instances for deep learning\n",
    "    # instance_type='ml.p3.2xlarge',  # 16GB $3.825/hr\n",
    "    # instance_type='ml.p4d.24xlarge, ## 40*8GB $32.77/hr\n",
    "    output_path=output_path,\n",
    "    hyperparameters=hyperparameters,\n",
    "    distribution={\"smdistributed\": {\"dataparallel\": { \"enabled\": True}}},  # 👈 mpirun, activates SMDDP AllReduce OR AllGather\n",
    "    # use_spot_instances=True, ## By default, there is no quota for GPU spot instances available.\n",
    ")\n",
    "## TODO: Your HP tuner here\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=8,\n",
    "    max_parallel_jobs=1,  ## this account limits gpu instance concurrent usage\n",
    "    objective_type=objective_type,\n",
    "    base_tuning_job_name='p5-amazon-bin-hpo',\n",
    "    early_stopping_type='Auto',\n",
    ")\n",
    "tuner.fit(\n",
    "    wait=False,  \n",
    ") \n",
    "print(\"👉\", tuner.latest_tuning_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the best hyperparameters\n",
    "hpo_job_name = \"p5-amazon-bin-hpo-250208-0349\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ Issue:  \n",
    "> terminate called after throwing an instance of 'SMDDPConfigError'\n",
    "  what():  The smdistributed.dataparallel functionality is invoked while the current job is not running as a distributed job. Please make sure you have the distribution strategy enabled in the SageMaker Estimator API according to https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-use-api.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Profiling and Debugging\n",
    "**TODO:** Use model debugging and profiling to better monitor and debug your model training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up debugging and profiling rules and hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and fit an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot a debugging output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Is there some anomalous behaviour in your debugging output? If so, what is the error and how will you fix it?  \n",
    "**TODO**: If not, suppose there was an error. What would that error look like and how would you have fixed it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the profiler output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deploying and Querying\n",
    "**TODO:** Can you deploy your model to an endpoint and then query that endpoint to get a result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Deploy your model to an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run an prediction on the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remember to shutdown/delete your endpoint once your work is done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheaper Training and Cost Analysis\n",
    "**TODO:** Can you perform a cost analysis of your system and then use spot instances to lessen your model training cost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train your model using a spot instance\n",
    "## By default, there is no quota for GPU spot instances available."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "awsmle_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
