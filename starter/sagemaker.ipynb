{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notebook created by nov05 on 2024-12-29\n",
    "* It was run locally with conda env `sagemaker_py310`.  \n",
    "\n",
    "---   \n",
    "* View the S3 bucket in your account   \n",
    "    https://s3.console.aws.amazon.com/s3/buckets/aft-vbi-pds\n",
    "* [Docs > Models and pre-trained weights > ResNet > resnet34](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet34.html)  \n",
    "* GitHub gist [code snippets](https://gist.github.com/nov05/95cb7edcbe2e8bb68c9d29bdc00b9ca8)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\github\\\\udacity-nd009t-capstone-starter\\\\starter'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## windows cmd to launch notepad to edit aws credential file\n",
    "# !notepad C:\\Users\\guido\\.aws\\config\n",
    "!notepad C:\\Users\\guido\\.aws\\credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/06/25 00:03:12] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\botocore\\credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\botocore\\credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/06/25 00:03:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=310397;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\botocore\\credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=596754;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\botocore\\credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/06/25 00:03:16] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> Couldn't call <span style=\"color: #008700; text-decoration-color: #008700\">'get_role'</span> to get Role ARN from role name voclabs to get <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py#5971\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5971</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Role path.                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/06/25 00:03:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m Couldn't call \u001b[38;2;0;135;0m'get_role'\u001b[0m to get Role ARN from role name voclabs to get \u001b]8;id=555252;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=129783;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py#5971\u001b\\\u001b[2m5971\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         Role path.                                                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current AWS Account ID: 570668189909\n",
      "AWS Region: us-east-1\n",
      "Default Bucket: sagemaker-us-east-1-570668189909\n",
      "Role voclabs ARN: arn:aws:iam::570668189909:role/voclabs\n",
      "SageMaker Role ARN: arn:aws:iam::570668189909:role/service-role/AmazonSageMaker-ExecutionRole-20250126T194519\n"
     ]
    }
   ],
   "source": [
    "## reset the session after updating credentials\n",
    "import boto3 # type: ignore\n",
    "boto3.DEFAULT_SESSION = None\n",
    "import sagemaker # type: ignore\n",
    "from sagemaker import get_execution_role # type: ignore\n",
    "\n",
    "# Extract and print the account ID\n",
    "sts_client = boto3.client('sts')\n",
    "response = sts_client.get_caller_identity() \n",
    "account_id = response['Account']\n",
    "\n",
    "role_arn = get_execution_role()  ## get role ARN\n",
    "if 'AmazonSageMaker-ExecutionRole' not in role_arn:\n",
    "    ## Go to \"IAM - Roles\", search for \"SageMaker\", find the execution role.\n",
    "    voclabs_role_arn = role_arn\n",
    "    sagemaker_role_arn = \"arn:aws:iam::570668189909:role/service-role/AmazonSageMaker-ExecutionRole-20250126T194519\"\n",
    "session = sagemaker.Session()  ## \"default\"\n",
    "region = session.boto_region_name\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "print(f\"Current AWS Account ID: {account_id}\")\n",
    "print(\"AWS Region: {}\".format(region))\n",
    "print(\"Default Bucket: {}\".format(bucket))\n",
    "print(f\"Role voclabs ARN: {voclabs_role_arn}\") ## If local, Role ARN: arn:aws:iam::807711953667:role/voclabs\n",
    "print(\"SageMaker Role ARN: {}\".format(sagemaker_role_arn)) \n",
    "\n",
    "## generate secrets.env. remember to add it to .gitignore  \n",
    "import wandb\n",
    "wandb.sagemaker_auth(path=\"../secrets\") \n",
    "\n",
    "## get my own AWS account info\n",
    "def get_secrets(name):\n",
    "    path = '../secrets/' + name\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            return line.strip()\n",
    "aws_account_number = get_secrets('aws_account_number')\n",
    "aws_account_profile = get_secrets('aws_account_profile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👉 **Data Preparation**\n",
    "**TODO:** Run the cell below to download the data.\n",
    "\n",
    "The cell below creates a folder called `data`, downloads training data and arranges it in subfolders. Each of these subfolders contain images where the number of objects is equal to the name of the folder. For instance, all images in folder `1` has images with 1 object in them. Images are not divided into training, testing or validation sets. If you feel like the number of samples are not enough, you can always download more data (instructions for that can be found [here](https://registry.opendata.aws/amazon-bin-imagery/)). However, we are not assessing you on the accuracy of your final trained model, but how you create your machine learning engineering pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* View the S3 bucket in your account   \n",
    "    https://s3.console.aws.amazon.com/s3/buckets/aft-vbi-pds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "\n",
    "def download_and_arrange_data(\n",
    "        prefix='bin-images', \n",
    "        file_extension='.jpg',\n",
    "        download_dir='../data/bin-images',\n",
    "        partition=True):\n",
    "    \n",
    "    s3_client = boto3.client('s3', config=Config(signature_version=UNSIGNED))  ## public access\n",
    "\n",
    "    ## There are 140536 image file names in the list. \n",
    "    with open('file_list.json', 'r') as f:\n",
    "        d = json.load(f)\n",
    "\n",
    "    for k, v in d.items():  ## There are 5 items (for 5 classes) in the JSON file.\n",
    "        print(f\"Downloading images/metadata of images with {k} object...\")\n",
    "        if partition:\n",
    "            download_dir = os.path.join(download_dir, k)\n",
    "        if not os.path.exists(download_dir):\n",
    "            os.makedirs(download_dir)\n",
    "        for file_path in tqdm(v):\n",
    "            file_name = os.path.basename(file_path).split('.')[0] + file_extension\n",
    "            s3_client.download_file(\n",
    "                'aft-vbi-pds', \n",
    "                prefix+'/'+file_name,  ## e.g. metadata/100313.json\n",
    "                download_dir+'/'+file_name)\n",
    "            \n",
    "## download the 10K-dataset metadata, 17.9 MB, 56m 57.4s\n",
    "download_and_arrange_data(\n",
    "    prefix='metadata', \n",
    "    file_extension='.json',\n",
    "    download_dir='../data/metadata',\n",
    "    partition=False)\n",
    "print(\"total metadata file number:\", 1228 + 2299 + 2666 + 2373 + 1875)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Downloading images/metadata of images with 1 object...\n",
    "100%|██████████| 1228/1228 [06:36<00:00,  3.09it/s]\n",
    "Downloading images/metadata of images with 2 object...\n",
    "100%|██████████| 2299/2299 [12:38<00:00,  3.03it/s]\n",
    "Downloading images/metadata of images with 3 object...\n",
    "100%|██████████| 2666/2666 [14:35<00:00,  3.04it/s]\n",
    "Downloading images/metadata of images with 4 object...\n",
    "100%|██████████| 2373/2373 [12:54<00:00,  3.06it/s]\n",
    "Downloading images/metadata of images with 5 object...\n",
    "100%|██████████| 1875/1875 [10:11<00:00,  3.07it/s]\n",
    "\n",
    "total metadata file number: 10441\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👉 **Convert 10K-dataset on S3 to WebDataset tar files with SageMaker ScriptProcessor on a custome image**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/25 17:55:50] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating processing-job with name                                      <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\sagemaker_py310\\lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\sagemaker_py310\\lib\\site-packages\\sagemaker\\session.py#1575\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1575</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         p5-amazon-bin-images-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-01-31-23-55-46-542                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/25 17:55:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating processing-job with name                                      \u001b]8;id=28680;file://d:\\Users\\guido\\miniconda3\\envs\\sagemaker_py310\\lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=800486;file://d:\\Users\\guido\\miniconda3\\envs\\sagemaker_py310\\lib\\site-packages\\sagemaker\\session.py#1575\u001b\\\u001b[2m1575\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         p5-amazon-bin-images-\u001b[1;36m2025\u001b[0m-01-31-23-55-46-542                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................Starting data processing...\n",
      "🟢 File list successfully loaded from s3://p5-amazon-bin-images/file_list.json\n",
      "    Total number of image files: 10441\n",
      "# writing train-shard-000000.tar 0 0.0 GB 0\n",
      "# writing train-shard-000001.tar 1000 0.1 GB 1000\n",
      "# writing train-shard-000002.tar 1000 0.1 GB 2000\n",
      "# writing train-shard-000003.tar 1000 0.1 GB 3000\n",
      "# writing train-shard-000004.tar 1000 0.1 GB 4000\n",
      "# writing train-shard-000005.tar 1000 0.1 GB 5000\n",
      "# writing train-shard-000006.tar 1000 0.1 GB 6000\n",
      "# writing train-shard-000007.tar 1000 0.1 GB 7000\n",
      "🟢 Successfully uploaded shard files to s3://p5-amazon-bin-images/webdataset/train/:\n",
      "    ['train-shard-000000.tar', 'train-shard-000001.tar', 'train-shard-000002.tar', 'train-shard-000003.tar', 'train-shard-000004.tar', 'train-shard-000005.tar', 'train-shard-000006.tar', 'train-shard-000007.tar']\n",
      "# writing val-shard-000000.tar 0 0.0 GB 0\n",
      "# writing val-shard-000001.tar 1000 0.1 GB 1000\n",
      "🟢 Successfully uploaded shard files to s3://p5-amazon-bin-images/webdataset/val/:\n",
      "    ['val-shard-000000.tar', 'val-shard-000001.tar']\n",
      "# writing test-shard-000000.tar 0 0.0 GB 0\n",
      "# writing test-shard-000001.tar 1000 0.1 GB 1000\n",
      "🟢 Successfully uploaded shard files to s3://p5-amazon-bin-images/webdataset/test/:\n",
      "    ['test-shard-000000.tar', 'test-shard-000001.tar']\n",
      "\n",
      "CPU times: total: 27.6 s\n",
      "Wall time: 15min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nIt took about 13 minutes to process 10.4K files (1.2 GB). If we keep 1K files per shard, \\nprocessing 500K files could take around 11 hours. I’ll probably increase it to 10K \\nfiles per shard, which would make each tar file around 1 GB and speed up the process.\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## TODO: Perform any data cleaning or data preprocessing\n",
    "## This cell shuffle then split the 10K dataset to train, val, and test.  \n",
    "## And convert the datasets to WebDataset tar files for SageMaker FastFile input mode.\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "processor = ScriptProcessor(\n",
    "    command=['python3'],\n",
    "    ## You can use a custom image or use the default SageMaker image\n",
    "    ## You can pull from AWS ECR or DockerHub\n",
    "    image_uri=f'{aws_account_number}.dkr.ecr.us-east-1.amazonaws.com/udacity/p5-amazon-bin-images:latest', \n",
    "    role=sagemaker_role_arn,  # Execution role\n",
    "    instance_count=1,\n",
    "    instance_type='ml.t3.large',  # Use the appropriate instance type\n",
    "    volume_size_in_gb=10,  # Minimal disk space since we're streaming\n",
    "    base_job_name='p5-amazon-bin-images' \n",
    ")\n",
    "processor.run(\n",
    "    code='../scripts_process/convert_to_webdataset_10k.py',  # process the 10K files in the list\n",
    "    arguments=[\n",
    "        '--SM_INPUT_BUCKET', 'aft-vbi-pds',\n",
    "        '--SM_INPUT_PREFIX_IMAGES', 'bin-images/',\n",
    "        '--SM_INPUT_PREFIX_METADATA', 'metadata/',\n",
    "        '--SM_OUTPUT_BUCKET', 'p5-amazon-bin-images',\n",
    "        '--SM_OUTPUT_PREFIX', 'webdataset/',\n",
    "    ]\n",
    ")\n",
    "## It took about 13 minutes to process 10.4K files (1.2 GB). If we keep 1K files per shard, \n",
    "## processing 500K files could take around 11 hours. I’ll probably increase it to 10K \n",
    "## files per shard, which would make each tar file around 1 GB and speed up the process.\n",
    "## CPU times: total: 21.9 s\n",
    "## Wall time: 12min 58s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👉 **Dataset**  \n",
    "\n",
    "**TODO:** Explain what dataset you are using for this project. Give a small overview of the classes, class distributions etc that can help anyone not familiar with the dataset get a better understanding of it. You can find more information about the data [here](https://registry.opendata.aws/amazon-bin-imagery/).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000001}.tar\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "# from sagemaker.inputs import TrainingInput\n",
    "data_base_path = \"s3://p5-amazon-bin-images/webdataset/\"\n",
    "# train_data = TrainingInput(data_base_path + \"train/\", \n",
    "#                            content_type=\"application/x-tar\")\n",
    "# val_data = TrainingInput(data_base_path + \"val/\", \n",
    "#                          content_type=\"application/x-tar\")\n",
    "# test_data = TrainingInput(data_base_path + \"test/\", \n",
    "#                           content_type=\"application/x-tar\")\n",
    "train_data_path = data_base_path + \"train/train-shard-{000000..000001}.tar\"\n",
    "val_data_path = data_base_path + \"val/val-shard-{000000..000000}.tar\"\n",
    "test_data_path = data_base_path + \"test/test-shard-{000000..000000}.tar\"\n",
    "print(train_data_path)\n",
    "## ⚠️ don't use prefix in output_path, cause source folder will be created \n",
    "## at bucket level, while other folders, e.g. debug-output, at prefix levle.\n",
    "output_path = \"s3://p5-amazon-bin-images-train/\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👉 **Model Training (Distributed Data Parallel)**  \n",
    "\n",
    "**TODO:** This is the part where you can train a model. The type or architecture of the model you use is not important.   \n",
    "**Note:** You will need to use the `train.py` script to train your model.\n",
    "\n",
    "* Official document: [SageMaker distributed data parallel (SDP) with PyTorch](https://sagemaker-examples.readthedocs.io/en/latest/training/distributed_training/index.html#pytorch-distributed)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/06/25 05:39:39] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> Framework profiling will be deprecated from tensorflow <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.12</span> and     <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\deprecations.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">deprecations.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\deprecations.py#34\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         pytorch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span> in sagemaker&gt;=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>.                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         See: <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/v2.html</span> for         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         details.                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/06/25 05:39:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m Framework profiling will be deprecated from tensorflow \u001b[1;36m2.12\u001b[0m and     \u001b]8;id=46050;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\deprecations.py\u001b\\\u001b[2mdeprecations.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=207173;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\deprecations.py#34\u001b\\\u001b[2m34\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         pytorch \u001b[1;36m2.0\u001b[0m in sagemaker>=\u001b[1;36m2\u001b[0m.                                        \u001b[2m                  \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         See: \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/v2.html\u001b[0m for         \u001b[2m                  \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         details.                                                            \u001b[2m                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO: Declare your model training hyperparameter.\n",
    "#NOTE: You do not need to do hyperparameter tuning. You can use fixed hyperparameter values\n",
    "import json\n",
    "from sagemaker.debugger import (\n",
    "    Rule,\n",
    "## debugger\n",
    "    DebuggerHookConfig,\n",
    "    rule_configs,\n",
    "## profiler \n",
    "    ProfilerRule,\n",
    "    ProfilerConfig,\n",
    "    FrameworkProfile\n",
    ")\n",
    "## SageMaker will automatically append these as command-line arguments  \n",
    "hyperparameters = {\n",
    "    'epochs': 2,   \n",
    "    'batch-size': 256,   \n",
    "    'opt-learning-rate': 8e-5,  \n",
    "    'opt-weight-decay': 1e-5,  \n",
    "    'lr-sched-step-size': 5,  \n",
    "    'lr-sched-gamma': 0.5,\n",
    "    'early-stopping-patience': 5,\n",
    "    'model-type': 'resnet50', \n",
    "    'wandb': True,  \n",
    "    'debug': False, \n",
    "## input data \n",
    "    \"train-data-path\": train_data_path,\n",
    "    \"val-data-path\": val_data_path,\n",
    "    \"test-data-path\": test_data_path,\n",
    "    \"train-data-size\": 2000,  \n",
    "    \"val-data-size\": 1000,\n",
    "    \"test-data-size\": 1000,\n",
    "    \"class-weights-dict\": {\n",
    "        1: 1.7004885993485341, \n",
    "        2: 0.9083079599826012, \n",
    "        3: 0.7832708177044261, \n",
    "        4: 0.8799831436999579, \n",
    "        5: 1.1137066666666666\n",
    "    },\n",
    "}\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "    Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "]\n",
    "hook_config = DebuggerHookConfig(\n",
    "    hook_parameters={\n",
    "        \"train.save_interval\": \"100\", \n",
    "        \"eval.save_interval\": \"10\"\n",
    "    }\n",
    ")\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, \n",
    "    framework_profile_params=FrameworkProfile(num_steps=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size: 7308, val_size: 1566, test_size: 1567\n"
     ]
    }
   ],
   "source": [
    "l = 10441\n",
    "split_ratio=[0.7, 0.15, 0.15]\n",
    "train_size = int(l*split_ratio[0])\n",
    "val_size = int(l*split_ratio[1])\n",
    "test_size = l - train_size - val_size\n",
    "print(f\"train_size: {train_size}, val_size: {val_size}, test_size: {test_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check [SageMaker AI Pricing](https://aws.amazon.com/sagemaker-ai/pricing/) > On-Demand Pricing > Training  \n",
    "    | Instance Type      | vCPU | Memory  | Price per Hour |\n",
    "    |--------------------|------|---------|----------------|\n",
    "    | ml.g4dn.xlarge      | 4    | 16 GiB  | $0.736         |\n",
    "    |ml.p3.2xlarge\t| 8\t| 61 GiB\t| $3.825 |\n",
    "\n",
    "<br>  \n",
    "\n",
    "* Documentation > Amazon SageMaker > Developer Guide   \n",
    "  [**Use the PyTorch framework estimators in the SageMaker Python SDK**](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-framework-estimator.html)    \n",
    "\n",
    "* sagemaker 2.239.0  \n",
    "  [**PyTorch Guide to SageMaker’s distributed data parallel library**](https://sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1.0.0/smd_data_parallel_pytorch.html)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your training estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point='train.py',  # Your training script that defines the ResNet50 model and training loop\n",
    "    source_dir='../scripts_train',  # Directory where your script and dependencies are stored\n",
    "    role=sagemaker_role_arn,\n",
    "    framework_version='1.13.1',  # Use the PyTorch version you need\n",
    "    py_version='py39',\n",
    "    instance_count=2,  ## multi-instance training, Udacity account level limit 2\n",
    "    # instance_type='ml.p3.2xlarge',  ## 16GB, Use GPU instances for deep learning\n",
    "    instance_type='ml.g4dn.xlarge',  ## 16GB, 1 GPU per instance\n",
    "    output_path=output_path,  ## if not specify, output to the sagemaker default bucket\n",
    "    hyperparameters=hyperparameters,\n",
    "    # use_spot_instances=True,\n",
    "## Debugger and profiler parameters\n",
    "    # rules=rules,\n",
    "    # debugger_hook_config=hook_config,    \n",
    "    # profiler_config=profiler_config,\n",
    "## Training using SMDataParallel Distributed Training Framework\n",
    "    # distribution={\"pytorchddp\": {\"enabled\": True}}  # mpirun, activates SMDDP AllReduce OR AllGather\n",
    "    # distribution={\"torch_distributed\": {\"enabled\": True}}  # torchrun, activates SMDDP AllGather\n",
    "    distribution={\"smdistributed\": {\"dataparallel\": { \"enabled\": True}}},  # mpirun, activates SMDDP AllReduce OR AllGather\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ⚠️ [Traning issues](https://gist.github.com/nov05/1bdc15eda0e781640b46ab28d38f45bd)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/06/25 05:39:43] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/06/25 05:39:43]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=246967;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=890794;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/06/25 05:39:44] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> image_uri is not presented, retrieving image_uri based on            <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py#679\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">679</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         instance_type, framework etc.                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/06/25 05:39:44]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m image_uri is not presented, retrieving image_uri based on            \u001b]8;id=833194;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=751926;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\image_uris.py#679\u001b\\\u001b[2m679\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         instance_type, framework etc.                                        \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name: p5-amazon-bin-job-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20250206</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">053943</span>     <a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name: p5-amazon-bin-job-\u001b[1;36m20250206\u001b[0m-\u001b[1;36m053943\u001b[0m     \u001b]8;id=792511;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=372442;file://d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-06 11:39:44 Starting - Starting the training job...\n",
      "2025-02-06 11:39:59 Starting - Preparing the instances for training...\n",
      "2025-02-06 11:40:33 Downloading - Downloading input data...\n",
      "2025-02-06 11:40:58 Downloading - Downloading the training image............\n",
      "2025-02-06 11:43:45 Training - Training image download completed. Training in progress...bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "/opt/conda/lib/python3.9/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "/opt/conda/lib/python3.9/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n",
      "2025-02-06 11:43:57,439 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2025-02-06 11:43:57,462 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-06 11:43:57,476 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2025-02-06 11:43:57,481 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\n",
      "2025-02-06 11:43:57,481 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2025-02-06 11:43:58,728 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\n",
      "Collecting wandb (from -r requirements.txt (line 1))\n",
      "Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting webdataset==0.2.100 (from -r requirements.txt (line 2))\n",
      "Downloading webdataset-0.2.100-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting braceexpand (from webdataset==0.2.100->-r requirements.txt (line 2))\n",
      "Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from webdataset==0.2.100->-r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from webdataset==0.2.100->-r requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting eval-type-backport (from wandb->-r requirements.txt (line 1))\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.15.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (5.9.8)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb->-r requirements.txt (line 1))\n",
      "Downloading setproctitle-1.3.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (71.0.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 1)) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 1))\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.9/site-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 1)) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2024.7.4)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 1))\n",
      "Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading webdataset-0.2.100-py3-none-any.whl (74 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 74.8/74.8 kB 10.6 MB/s eta 0:00:00\n",
      "Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.9 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.9/20.9 MB 100.8 MB/s eta 0:00:00\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.6/207.6 kB 33.6 MB/s eta 0:00:00\n",
      "Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl (322 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 322.6/322.6 kB 52.2 MB/s eta 0:00:00\n",
      "Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading setproctitle-1.3.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.8/62.8 kB 12.6 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: braceexpand, webdataset, smmap, setproctitle, sentry-sdk, eval-type-backport, docker-pycreds, gitdb, gitpython, wandb\n",
      "bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "/opt/conda/lib/python3.9/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "/opt/conda/lib/python3.9/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n",
      "2025-02-06 11:43:57,493 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2025-02-06 11:43:57,515 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-06 11:43:57,529 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2025-02-06 11:43:57,533 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\n",
      "2025-02-06 11:43:57,533 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2025-02-06 11:43:58,747 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\n",
      "Collecting wandb (from -r requirements.txt (line 1))\n",
      "Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting webdataset==0.2.100 (from -r requirements.txt (line 2))\n",
      "Downloading webdataset-0.2.100-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting braceexpand (from webdataset==0.2.100->-r requirements.txt (line 2))\n",
      "Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from webdataset==0.2.100->-r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from webdataset==0.2.100->-r requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting eval-type-backport (from wandb->-r requirements.txt (line 1))\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.15.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (5.9.8)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb->-r requirements.txt (line 1))\n",
      "Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb->-r requirements.txt (line 1))\n",
      "Downloading setproctitle-1.3.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (71.0.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 1)) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 1))\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.9/site-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 1)) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2024.7.4)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 1))\n",
      "Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading webdataset-0.2.100-py3-none-any.whl (74 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 74.8/74.8 kB 9.6 MB/s eta 0:00:00\n",
      "Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.9 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.9/20.9 MB 108.6 MB/s eta 0:00:00\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.6/207.6 kB 41.6 MB/s eta 0:00:00\n",
      "Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl (322 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 322.6/322.6 kB 57.2 MB/s eta 0:00:00\n",
      "Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading setproctitle-1.3.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.8/62.8 kB 16.0 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: braceexpand, webdataset, smmap, setproctitle, sentry-sdk, eval-type-backport, docker-pycreds, gitdb, gitpython, wandb\n",
      "Successfully installed braceexpand-0.1.7 docker-pycreds-0.4.0 eval-type-backport-0.2.2 gitdb-4.0.12 gitpython-3.1.44 sentry-sdk-2.20.0 setproctitle-1.3.4 smmap-5.0.2 wandb-0.19.6 webdataset-0.2.100\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "[notice] A new release of pip is available: 24.1.2 -> 25.0\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2025-02-06 11:44:02,857 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2025-02-06 11:44:02,857 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2025-02-06 11:44:02,907 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-06 11:44:02,954 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-06 11:44:02,973 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\n",
      "2025-02-06 11:44:02,973 sagemaker-training-toolkit INFO     Waiting for MPI Master to create SSH daemon.\n",
      "2025-02-06 11:44:02,974 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\n",
      "2025-02-06 11:44:02,974 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.0.212.36.              Can be ignored for worker when master completes and exits.\n",
      "Successfully installed braceexpand-0.1.7 docker-pycreds-0.4.0 eval-type-backport-0.2.2 gitdb-4.0.12 gitpython-3.1.44 sentry-sdk-2.20.0 setproctitle-1.3.4 smmap-5.0.2 wandb-0.19.6 webdataset-0.2.100\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "[notice] A new release of pip is available: 24.1.2 -> 25.0\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2025-02-06 11:44:02,974 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2025-02-06 11:44:02,974 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2025-02-06 11:44:03,025 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-06 11:44:03,069 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-06 11:44:03,089 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\n",
      "2025-02-06 11:44:03,089 sagemaker-training-toolkit INFO     Creating SSH daemon.\n",
      "2025-02-06 11:44:03,093 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\n",
      "2025-02-06 11:44:03,094 sagemaker-training-toolkit INFO     Cannot connect to host algo-2 at port 22. Retrying...\n",
      "2025-02-06 11:44:03,094 sagemaker-training-toolkit INFO     Connection closed\n",
      "2025-02-06 11:44:03,985 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\n",
      "2025-02-06 11:44:04,156 paramiko.transport INFO     Authentication (publickey) successful!\n",
      "2025-02-06 11:44:04,157 sagemaker-training-toolkit INFO     Can connect to host algo-1\n",
      "2025-02-06 11:44:04,157 sagemaker-training-toolkit INFO     MPI Master online, creating SSH daemon.\n",
      "2025-02-06 11:44:04,157 sagemaker-training-toolkit INFO     Writing environment variables to /etc/environment for the MPI process.\n",
      "2025-02-06 11:44:04,164 sagemaker-training-toolkit INFO     Waiting for MPI process to finish.\n",
      "2025-02-06 11:44:04,096 sagemaker-training-toolkit INFO     Cannot connect to host algo-2 at port 22. Retrying...\n",
      "2025-02-06 11:44:04,096 sagemaker-training-toolkit INFO     Connection closed\n",
      "2025-02-06 11:44:05,107 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\n",
      "2025-02-06 11:44:05,306 paramiko.transport INFO     Authentication (publickey) successful!\n",
      "2025-02-06 11:44:05,306 sagemaker-training-toolkit INFO     Can connect to host algo-2 at port 22\n",
      "2025-02-06 11:44:05,306 sagemaker-training-toolkit INFO     Connection closed\n",
      "2025-02-06 11:44:05,306 sagemaker-training-toolkit INFO     Worker algo-2 available for communication\n",
      "2025-02-06 11:44:05,306 sagemaker-training-toolkit INFO     Network interface name: eth0\n",
      "2025-02-06 11:44:05,306 sagemaker-training-toolkit INFO     Host: ['algo-1', 'algo-2']\n",
      "2025-02-06 11:44:05,357 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-06 11:44:05,378 sagemaker-training-toolkit INFO     instance type: ml.g4dn.xlarge\n",
      "2025-02-06 11:44:05,378 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1', 'algo-2'] Hosts: ['algo-1:1', 'algo-2:1'] process_per_hosts: 1 num_processes: 2\n",
      "2025-02-06 11:44:05,407 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-02-06 11:44:05,428 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_distributed_dataparallel_custom_mpi_options\": \"\",\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": true,\n",
      "        \"sagemaker_instance_type\": \"ml.g4dn.xlarge\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 256,\n",
      "        \"class-weights-dict\": {\n",
      "            \"1\": 1.7004885993485341,\n",
      "            \"2\": 0.9083079599826012,\n",
      "            \"3\": 0.7832708177044261,\n",
      "            \"4\": 0.8799831436999579,\n",
      "            \"5\": 1.1137066666666666\n",
      "        },\n",
      "        \"debug\": false,\n",
      "        \"early-stopping-patience\": 5,\n",
      "        \"epochs\": 5,\n",
      "        \"lr-sched-gamma\": 0.5,\n",
      "        \"lr-sched-step-size\": 5,\n",
      "        \"model-type\": \"resnet50\",\n",
      "        \"opt-learning-rate\": 8e-05,\n",
      "        \"opt-weight-decay\": 1e-05,\n",
      "        \"test-data-path\": \"s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000000}.tar\",\n",
      "        \"test-data-size\": 1000,\n",
      "        \"train-data-path\": \"s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000001}.tar\",\n",
      "        \"train-data-size\": 2000,\n",
      "        \"val-data-path\": \"s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000000}.tar\",\n",
      "        \"val-data-size\": 1000,\n",
      "        \"wandb\": true\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"p5-amazon-bin-job-20250206-053943\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://p5-amazon-bin-images-train/p5-amazon-bin-job-20250206-053943/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"batch-size\":256,\"class-weights-dict\":{\"1\":1.7004885993485341,\"2\":0.9083079599826012,\"3\":0.7832708177044261,\"4\":0.8799831436999579,\"5\":1.1137066666666666},\"debug\":false,\"early-stopping-patience\":5,\"epochs\":5,\"lr-sched-gamma\":0.5,\"lr-sched-step-size\":5,\"model-type\":\"resnet50\",\"opt-learning-rate\":8e-05,\"opt-weight-decay\":1e-05,\"test-data-path\":\"s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000000}.tar\",\"test-data-size\":1000,\"train-data-path\":\"s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000001}.tar\",\"train-data-size\":2000,\"val-data-path\":\"s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000000}.tar\",\"val-data-size\":1000,\"wandb\":true}\n",
      "SM_USER_ENTRY_POINT=train.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.g4dn.xlarge\"}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g4dn.xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-2\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=train\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=4\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://p5-amazon-bin-images-train/p5-amazon-bin-job-20250206-053943/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.g4dn.xlarge\"},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.g4dn.xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch-size\":256,\"class-weights-dict\":{\"1\":1.7004885993485341,\"2\":0.9083079599826012,\"3\":0.7832708177044261,\"4\":0.8799831436999579,\"5\":1.1137066666666666},\"debug\":false,\"early-stopping-patience\":5,\"epochs\":5,\"lr-sched-gamma\":0.5,\"lr-sched-step-size\":5,\"model-type\":\"resnet50\",\"opt-learning-rate\":8e-05,\"opt-weight-decay\":1e-05,\"test-data-path\":\"s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000000}.tar\",\"test-data-size\":1000,\"train-data-path\":\"s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000001}.tar\",\"train-data-size\":2000,\"val-data-path\":\"s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000000}.tar\",\"val-data-size\":1000,\"wandb\":true},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"is_smddprun_installed\":true,\"job_name\":\"p5-amazon-bin-job-20250206-053943\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://p5-amazon-bin-images-train/p5-amazon-bin-job-20250206-053943/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\n",
      "SM_USER_ARGS=[\"--batch-size\",\"256\",\"--class-weights-dict\",\"1=1.7004885993485341,2=0.9083079599826012,3=0.7832708177044261,4=0.8799831436999579,5=1.1137066666666666\",\"--debug\",\"False\",\"--early-stopping-patience\",\"5\",\"--epochs\",\"5\",\"--lr-sched-gamma\",\"0.5\",\"--lr-sched-step-size\",\"5\",\"--model-type\",\"resnet50\",\"--opt-learning-rate\",\"8e-05\",\"--opt-weight-decay\",\"1e-05\",\"--test-data-path\",\"s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000000}.tar\",\"--test-data-size\",\"1000\",\"--train-data-path\",\"s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000001}.tar\",\"--train-data-size\",\"2000\",\"--val-data-path\",\"s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000000}.tar\",\"--val-data-size\",\"1000\",\"--wandb\",\"True\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_HP_BATCH-SIZE=256\n",
      "SM_HP_CLASS-WEIGHTS-DICT={\"1\":1.7004885993485341,\"2\":0.9083079599826012,\"3\":0.7832708177044261,\"4\":0.8799831436999579,\"5\":1.1137066666666666}\n",
      "SM_HP_DEBUG=false\n",
      "SM_HP_EARLY-STOPPING-PATIENCE=5\n",
      "SM_HP_EPOCHS=5\n",
      "SM_HP_LR-SCHED-GAMMA=0.5\n",
      "SM_HP_LR-SCHED-STEP-SIZE=5\n",
      "SM_HP_MODEL-TYPE=resnet50\n",
      "SM_HP_OPT-LEARNING-RATE=8e-05\n",
      "SM_HP_OPT-WEIGHT-DECAY=1e-05\n",
      "SM_HP_TEST-DATA-PATH=s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000000}.tar\n",
      "SM_HP_TEST-DATA-SIZE=1000\n",
      "SM_HP_TRAIN-DATA-PATH=s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000001}.tar\n",
      "SM_HP_TRAIN-DATA-SIZE=2000\n",
      "SM_HP_VAL-DATA-PATH=s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000000}.tar\n",
      "SM_HP_VAL-DATA-SIZE=1000\n",
      "SM_HP_WANDB=true\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\n",
      "Invoking script with the following command:\n",
      "mpirun --host algo-1:1,algo-2:1 -np 2 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 2 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_HOMOGENEOUS=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.9/site-packages/gethostname.cpython-39-x86_64-linux-gnu.so -x SMDATAPARALLEL_SERVER_ADDR=algo-1 -x SMDATAPARALLEL_SERVER_PORT=7592 -x SAGEMAKER_INSTANCE_TYPE=ml.g4dn.xlarge smddprun /opt/conda/bin/python3.9 -m mpi4py train.py --batch-size 256 --class-weights-dict 1=1.7004885993485341,2=0.9083079599826012,3=0.7832708177044261,4=0.8799831436999579,5=1.1137066666666666 --debug False --early-stopping-patience 5 --epochs 5 --lr-sched-gamma 0.5 --lr-sched-step-size 5 --model-type resnet50 --opt-learning-rate 8e-05 --opt-weight-decay 1e-05 --test-data-path s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000000}.tar --test-data-size 1000 --train-data-path s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000001}.tar --train-data-size 2000 --val-data-path s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000000}.tar --val-data-size 1000 --wandb True\n",
      "Warning: Permanently added 'algo-2,10.0.198.61' (ECDSA) to the list of known hosts.\n",
      "2025-02-06 11:44:06,169 sagemaker-training-toolkit INFO     Process[es]: [psutil.Process(pid=86, name='orted', status='sleeping', started='11:44:05')]\n",
      "2025-02-06 11:44:06,169 sagemaker-training-toolkit INFO     Orted process found [psutil.Process(pid=86, name='orted', status='sleeping', started='11:44:05')]\n",
      "2025-02-06 11:44:06,170 sagemaker-training-toolkit INFO     Waiting for orted process [psutil.Process(pid=86, name='orted', status='sleeping', started='11:44:05')]\n",
      "[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:1,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:1,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:1,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:1,algo-2]<stdout>:DDP Mode\n",
      "[1,mpirank:1,algo-2]<stderr>:train.py:38: DeprecationWarning: smdistributed.dataparallel.torch.dist is deprecated in the SageMaker distributed data parallel library v1.4.0+.Please use torch.distributed and specify 'smddp' as a backend when initializing process group as follows:torch.distributed.init_process_group(backend='smddp')For more information, see the library's API documentation at https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-modify-sdp-pt.html\n",
      "[1,mpirank:1,algo-2]<stderr>:  import smdistributed.dataparallel.torch.distributed as dist\n",
      "[1,mpirank:0,algo-1]<stdout>:DDP Mode\n",
      "[1,mpirank:0,algo-1]<stderr>:train.py:38: DeprecationWarning: smdistributed.dataparallel.torch.dist is deprecated in the SageMaker distributed data parallel library v1.4.0+.Please use torch.distributed and specify 'smddp' as a backend when initializing process group as follows:torch.distributed.init_process_group(backend='smddp')For more information, see the library's API documentation at https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-modify-sdp-pt.html\n",
      "[1,mpirank:0,algo-1]<stderr>:  import smdistributed.dataparallel.torch.distributed as dist\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Bootstrap : Using eth0:10.0.212.36<0>\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO cudaDriverVersion 12040\n",
      "[1,mpirank:0,algo-1]<stdout>:NCCL version 2.14.3+cuda11.7\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO cudaDriverVersion 12040\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.212.36<0>\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Using network Socket\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Bootstrap : Using eth0:10.0.198.61<0>\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.198.61<0>\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Using network Socket\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 00/02 :    0   1\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 01/02 :    0   1\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:125 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 00/0 : 0[1e0] -> 1[1e0] [receive] via NET/Socket/0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:128 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 00/0 : 1[1e0] -> 0[1e0] [receive] via NET/Socket/0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:125 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 01/0 : 0[1e0] -> 1[1e0] [receive] via NET/Socket/0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:128 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 01/0 : 1[1e0] -> 0[1e0] [receive] via NET/Socket/0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 00/0 : 1[1e0] -> 0[1e0] [send] via NET/Socket/0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 00/0 : 0[1e0] -> 1[1e0] [send] via NET/Socket/0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 01/0 : 1[1e0] -> 0[1e0] [send] via NET/Socket/0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 01/0 : 0[1e0] -> 1[1e0] [send] via NET/Socket/0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Connected all rings\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Connected all trees\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Connected all rings\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Connected all trees\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO comm 0x55864b6a3350 rank 0 nranks 2 cudaDev 0 busId 1e0 - Init COMPLETE\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO comm 0x555decfa9190 rank 1 nranks 2 cudaDev 0 busId 1e0 - Init COMPLETE\n",
      "[1,mpirank:1,algo-2]<stdout>:NCCL version 2.14.3+cuda11.7\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Using network Socket\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Using network Socket\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 00/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 01/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 02/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 03/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 04/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 05/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 06/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 07/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 08/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 09/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 10/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 11/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 12/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 13/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 14/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 15/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 16/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 17/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 18/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 19/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 20/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 21/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 22/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 23/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 24/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 25/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 26/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 27/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 28/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 29/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 30/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Channel 31/32 :    0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Connected all rings\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO Connected all trees\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 00/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 01/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 02/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 03/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 04/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 05/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 06/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 07/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 08/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 09/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 10/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 11/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 12/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 13/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 14/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 15/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 16/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 17/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 18/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 19/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 20/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 21/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 22/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 23/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 24/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 25/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 26/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 27/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 28/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 29/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 30/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Channel 31/32 :    0\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Connected all rings\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO Connected all trees\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:106:106 [0] NCCL INFO comm 0x55864bd461e0 rank 0 nranks 1 cudaDev 0 busId 1e0 - Init COMPLETE\n",
      "[1,mpirank:0,algo-1]<stdout>:Running smdistributed.dataparallel v1.7.0\n",
      "[1,mpirank:0,algo-1]<stdout>:SMDDP: Multi node ENA mode[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:algo-2:105:105 [0] NCCL INFO comm 0x555ded1ae5f0 rank 0 nranks 1 cudaDev 0 busId 1e0 - Init COMPLETE\n",
      "[1,mpirank:0,algo-1]<stdout>:🟢 SageMkaer DDP is initialized.\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Total GPU count: 2\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Rank: 0, Local Rank: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 task.config:\n",
      "[1,mpirank:0,algo-1]<stdout>:{\n",
      "[1,mpirank:0,algo-1]<stdout>:'batch_size': 256,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'class_weights_dict': {1: 1.7004885993485341,\n",
      "[1,mpirank:0,algo-1]<stdout>:                        2: 0.9083079599826012,\n",
      "[1,mpirank:0,algo-1]<stdout>:                        3: 0.7832708177044261,\n",
      "[1,mpirank:0,algo-1]<stdout>:                        4: 0.8799831436999579,\n",
      "[1,mpirank:0,algo-1]<stdout>:                        5: 1.1137066666666666},\n",
      "[1,mpirank:0,algo-1]<stdout>: 'debug': False,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'early_stopping_patience': 5,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'epochs': 5,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'lr_sched_gamma': 0.5,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'lr_sched_step_size': 5,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'model_arch': 'resnet34',\n",
      "[1,mpirank:0,algo-1]<stdout>: 'model_dir': '/opt/ml/model',\n",
      "[1,mpirank:0,algo-1]<stdout>: 'opt_learning_rate': 8e-05,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'opt_weight_decay': 1e-05,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'output_data_dir': '/opt/ml/output/data',\n",
      "[1,mpirank:0,algo-1]<stdout>: 'test_data_path':\n",
      "[1,mpirank:0,algo-1]<stdout>:'s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000000}.tar',\n",
      "[1,mpirank:0,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:'test_data_size': [1,mpirank:0,algo-1]<stdout>:1000,\n",
      "[1,mpirank:0,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:'train_data_path'[1,mpirank:0,algo-1]<stdout>:: [1,mpirank:0,algo-1]<stdout>:'s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000001}.tar',\n",
      "[1,mpirank:0,algo-1]<stdout>: 'train_data_size'[1,mpirank:0,algo-1]<stdout>:: 2000,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'use_cuda': [1,mpirank:0,algo-1]<stdout>:True,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'val_data_path': [1,mpirank:0,algo-1]<stdout>:'s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000000}.tar',\n",
      "[1,mpirank:0,algo-1]<stdout>: [1,mpirank:0,algo-1]<stdout>:'val_data_size'[1,mpirank:0,algo-1]<stdout>:: [1,mpirank:0,algo-1]<stdout>:1000[1,mpirank:0,algo-1]<stdout>:,\n",
      "[1,mpirank:0,algo-1]<stdout>: 'wandb': [1,mpirank:0,algo-1]<stdout>:True[1,mpirank:0,algo-1]<stdout>:}[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🟢 SageMkaer DDP is initialized.\n",
      "[1,mpirank:1,algo-2]<stdout>:👉 Total GPU count: 2\n",
      "[1,mpirank:1,algo-2]<stdout>:👉 Rank: 1, Local Rank: 0\n",
      "[1,mpirank:1,algo-2]<stdout>:👉 Device: cuda, Rank: 1, Local rank: 0\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Currently logged in as: nov05 to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Tracking run with wandb version 0.19.6\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Run data is saved locally in /opt/ml/code/wandb/run-20250206_114413-p5-amazon-bin-job-20250206-053943-xexzf4-algo-1\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Run `wandb offline` to turn off syncing.\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Syncing run p5-amazon-bin-job-20250206-053943-xexzf4-algo-1\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: ⭐️ View project at https://wandb.ai/nov05/udacity-awsmle-resnet34-amazon-bin\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: 🚀 View run at https://wandb.ai/nov05/udacity-awsmle-resnet34-amazon-bin/runs/p5-amazon-bin-job-20250206-053943-xexzf4-algo-1\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Device: cuda, Rank: 0, Local rank: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Rank 0: Model resnet34 has been created successfully.\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:👉 Rank 1: Model resnet34 has been created successfully.\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-06 11:44:14.627 algo-1:106 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-06 11:44:14.720 algo-2:105 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-06 11:44:15.015 algo-1:106 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-06 11:44:15.016 algo-1:106 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-06 11:44:15.017 algo-1:106 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-06 11:44:15.018 algo-1:106 INFO hook.py:259] Saving to /opt/ml/output/tensors\n",
      "[1,mpirank:0,algo-1]<stdout>:[2025-02-06 11:44:15.018 algo-1:106 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-06 11:44:15.088 algo-2:105 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-06 11:44:15.089 algo-2:105 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-06 11:44:15.089 algo-2:105 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-06 11:44:15.090 algo-2:105 INFO hook.py:259] Saving to /opt/ml/output/tensors\n",
      "[1,mpirank:1,algo-2]<stdout>:[2025-02-06 11:44:15.090 algo-2:105 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "[1,mpirank:1,algo-2]<stdout>:🏷️ Rank 1, Train Epoch: 0 [0.0/2000 (0%)], Loss: 2.940898\n",
      "[1,mpirank:0,algo-1]<stdout>:🏷️ Rank 0, Train Epoch: 0 [0.0/2000 (0%)], Loss: 3.057763\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\n",
      "[1,mpirank:1,algo-2]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\n",
      "[1,mpirank:1,algo-2]<stdout>:👉 Train Epoch: 1, Learning Rate: 0.00016\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 EVAL: Average loss: 2.8803, Accuracy: 667.0/4000.0 (16.68%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 1, Learning Rate: 0.00016\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 1\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🏷️ Rank 0, Train Epoch: 1 [0.0/2000 (0%)], Loss: 1.933717\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🏷️ Rank 1, Train Epoch: 1 [0.0/2000 (0%)], Loss: 2.222192\n",
      "[1,mpirank:1,algo-2]<stdout>:👉 Train Epoch: 2, Learning Rate: 0.00016\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 EVAL: Average loss: 1.7232, Accuracy: 556.0/4000.0 (13.90%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 2, Learning Rate: 0.00016[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 2\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🏷️ Rank 0, Train Epoch: 2 [0.0/2000 (0%)], Loss: 1.863173\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🏷️ Rank 1, Train Epoch: 2 [0.0/2000 (0%)], Loss: 1.854225\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 EVAL: Average loss: 1.9735, Accuracy: 502.0/4000.0 (12.55%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 3, Learning Rate: 0.00016[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 3\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:👉 Train Epoch: 3, Learning Rate: 0.00016\n",
      "[1,mpirank:0,algo-1]<stdout>:🏷️ Rank 0, Train Epoch: 3 [0.0/2000 (0%)], Loss: 2.020099\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🏷️ Rank 1, Train Epoch: 3 [0.0/2000 (0%)], Loss: 1.832961\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 EVAL: Average loss: 2.1299, Accuracy: 457.0/4000.0 (11.43%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 4, Learning Rate: 0.00016\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 4\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:👉 Train Epoch: 4, Learning Rate: 0.00016\n",
      "[1,mpirank:0,algo-1]<stdout>:🏷️ Rank 0, Train Epoch: 4 [0.0/2000 (0%)], Loss: 1.735486\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:🏷️ Rank 1, Train Epoch: 4 [0.0/2000 (0%)], Loss: 1.822714\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 EVAL: Average loss: 1.8210, Accuracy: 579.0/4000.0 (14.47%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Train Epoch: 5, Learning Rate: 8e-05[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:🟢 Start testing...\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 TEST: Average loss: 1.7704, Accuracy: 646.0/4000.0 (16.15%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:👉 Model saved at '/opt/ml/model/model.pth'\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb:\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: \n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Run history:\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb:     Rank 0, eval_loss_epoch █▁▃▃▂\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb:          Rank 0, train_loss ██▅▅▄▄▃▃▅▄▄▅▄▄▄▃▃▃▃▃▃▃▁\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Rank 0: eval_accuracy_epoch █▄▃▁▅\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: \n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Run summary:\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb:     Rank 0, eval_loss_epoch 1.821\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb:          Rank 0, train_loss 1.18429\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Rank 0: eval_accuracy_epoch 14.475\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb:\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: 🚀 View run p5-amazon-bin-job-20250206-053943-xexzf4-algo-1 at: https://wandb.ai/nov05/udacity-awsmle-resnet34-amazon-bin/runs/p5-amazon-bin-job-20250206-053943-xexzf4-algo-1\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: ⭐️ View project at: https://wandb.ai/nov05/udacity-awsmle-resnet34-amazon-bin\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "[1,mpirank:0,algo-1]<stderr>:wandb: Find logs at: ./wandb/run-20250206_114413-p5-amazon-bin-job-20250206-053943-xexzf4-algo-1/logs\n",
      "[1,mpirank:1,algo-2]<stdout>:Traceback (most recent call last):\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "[1,mpirank:1,algo-2]<stdout>:    return _run_code(code, main_globals, None,\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "[1,mpirank:1,algo-2]<stdout>:    exec(code, run_globals)\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/mpi4py/__main__.py\", line 7, in <module>\n",
      "[1,mpirank:1,algo-2]<stdout>:    main()\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/mpi4py/run.py\", line 230, in main\n",
      "[1,mpirank:1,algo-2]<stdout>:    run_command_line(args)\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/mpi4py/run.py\", line 47, in run_command_line\n",
      "[1,mpirank:1,algo-2]<stdout>:    run_path(sys.argv[0], run_name='__main__')\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/runpy.py\", line 288, in run_path\n",
      "[1,mpirank:1,algo-2]<stdout>:    return _run_module_code(code, init_globals, run_name,\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/runpy.py\", line 97, in _run_module_code\n",
      "[1,mpirank:1,algo-2]<stdout>:    _run_code(code, mod_globals, init_globals,\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "[1,mpirank:1,algo-2]<stdout>:    exec(code, run_globals)\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"train.py\", line 691, in <module>\n",
      "[1,mpirank:1,algo-2]<stdout>:    main(task)\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"train.py\", line 586, in main\n",
      "[1,mpirank:1,algo-2]<stdout>:    train(task)\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"train.py\", line 284, in train\n",
      "[1,mpirank:1,algo-2]<stdout>:    output = task.model(data)\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "[1,mpirank:1,algo-2]<stdout>:    return forward_call(*input, **kwargs)\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/torch/nn/parallel/distributed.py\", line 1040, in forward\n",
      "[1,mpirank:1,algo-2]<stdout>:    output = self._run_ddp_forward(*inputs, **kwargs)\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/torch/nn/parallel/distributed.py\", line 1000, in _run_ddp_forward\n",
      "[1,mpirank:1,algo-2]<stdout>:    return module_to_run(*inputs[0], **kwargs[0])\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "[1,mpirank:1,algo-2]<stdout>:    return forward_call(*input, **kwargs)\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "[1,mpirank:1,algo-2]<stdout>:    return self._forward_impl(x)\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/torchvision/models/resnet.py\", line 269, in _forward_impl\n",
      "[1,mpirank:1,algo-2]<stdout>:    x = self.bn1(x)\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "[1,mpirank:1,algo-2]<stdout>:    return forward_call(*input, **kwargs)\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\", line 752, in forward\n",
      "[1,mpirank:1,algo-2]<stdout>:    return sync_batch_norm.apply(\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/torch/nn/modules/_functions.py\", line 65, in forward\n",
      "[1,mpirank:1,algo-2]<stdout>:    dist.all_gather(combined_list, combined, process_group, async_op=False)\n",
      "[1,mpirank:1,algo-2]<stdout>:  File \"/opt/conda/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py\", line 2282, in all_gather\n",
      "[1,mpirank:1,algo-2]<stdout>:    work.wait()\n",
      "[1,mpirank:1,algo-2]<stdout>:RuntimeError: Timeout: A call to a collective SMDDP operation has taken over 1800 seconds. Terminating the distributed job.\n",
      "--------------------------------------------------------------------------\n",
      "MPI_ABORT was invoked on rank 1 in communicator MPI COMMUNICATOR 4 DUP FROM 0\n",
      "with errorcode 1.\n",
      "NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.\n",
      "You may or may not see output from other processes, depending on\n",
      "exactly when Open MPI kills them.\n",
      "--------------------------------------------------------------------------\n",
      "2025-02-06 12:17:16,474 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2025-02-06 12:17:16,474 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\n",
      "2025-02-06 12:17:16,475 sagemaker-training-toolkit ERROR    Reporting training FAILURE\n",
      "2025-02-06 12:17:16,475 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\n",
      "ExitCode 1\n",
      "ErrorMessage \"RuntimeError: Timeout: A call to a collective SMDDP operation has taken over 1800 seconds. Terminating the distributed job.\"\n",
      "Command \"mpirun --host algo-1:1,algo-2:1 -np 2 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 2 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_HOMOGENEOUS=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.9/site-packages/gethostname.cpython-39-x86_64-linux-gnu.so -x SMDATAPARALLEL_SERVER_ADDR=algo-1 -x SMDATAPARALLEL_SERVER_PORT=7592 -x SAGEMAKER_INSTANCE_TYPE=ml.g4dn.xlarge smddprun /opt/conda/bin/python3.9 -m mpi4py train.py --batch-size 256 --class-weights-dict 1=1.7004885993485341,2=0.9083079599826012,3=0.7832708177044261,4=0.8799831436999579,5=1.1137066666666666 --debug False --early-stopping-patience 5 --epochs 5 --lr-sched-gamma 0.5 --lr-sched-step-size 5 --model-type resnet50 --opt-learning-rate 8e-05 --opt-weight-decay 1e-05 --test-data-path s3://p5-amazon-bin-images/webdataset/test/test-shard-{000000..000000}.tar --test-data-size 1000 --train-data-path s3://p5-amazon-bin-images/webdataset/train/train-shard-{000000..000001}.tar --train-data-size 2000 --val-data-path s3://p5-amazon-bin-images/webdataset/val/val-shard-{000000..000000}.tar --val-data-size 1000 --wandb True\"\n",
      "2025-02-06 12:17:16,475 sagemaker-training-toolkit ERROR    Encountered exit_code 1\n",
      "2025-02-06 12:17:16,482 sagemaker-training-toolkit INFO     Invoked on_terminate from psutil.wait_for_procs\n",
      "2025-02-06 12:17:16,482 sagemaker-training-toolkit INFO     process psutil.Process(pid=86, name='orted', status='terminated', started='11:44:05') terminated with exit code None\n",
      "2025-02-06 12:17:16,483 sagemaker-training-toolkit INFO     Reporting status for ORTEd process. gone: [psutil.Process(pid=86, name='orted', status='terminated', started='11:44:05')] alive: []\n",
      "2025-02-06 12:17:16,483 sagemaker-training-toolkit INFO     Orted process exited\n",
      "\n",
      "2025-02-06 12:17:28 Uploading - Uploading generated training model\n",
      "2025-02-06 12:17:42 Failed - Training job failed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─────────────────────────────── </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\IPython\\core\\magics\\execution.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">355</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">time</span>                                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1352 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># multi-line %%time case</span>                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1353 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> expr_val <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1354 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>code_2 = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.shell.compile(expr_val, source, <span style=\"color: #808000; text-decoration-color: #808000\">'eval'</span>)                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1355 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>out = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">eval</span>(code_2, glob, local_ns)                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1356 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span>:                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1357 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.shell.showtraceback()                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1358 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span>                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logg</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">ing.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">167</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>caught_ex = e                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">165 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">finally</span>:                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> caught_ex:                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>167 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> caught_ex                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> response  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># pylint: disable=W0150</span>                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">170 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>logger.debug(                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logg</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">ing.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">138</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>start_timer = perf_counter()                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Call the original function</span>                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>138 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>response = func(*args, **kwargs)                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>stop_timer = perf_counter()                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>elapsed = stop_timer - start_timer                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>extra += <span style=\"color: #808000; text-decoration-color: #808000\">f\"&amp;x-latency={</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">round</span>(elapsed,<span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\workflow\\pipeline_contex</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">t.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">346</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">343 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">344 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _StepArguments(retrieve_caller_name(self_instance), run_func, *args,    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">345 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>346 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> run_func(*args, **kwargs)                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">347 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">348 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapper                                                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">349 </span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\estimator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1380</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1377 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>wait = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1378 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>forward_to_mlflow_tracking_server = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1379 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> wait:                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1380 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.latest_training_job.wait(logs=logs)                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1381 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1382 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> forward_to_mlflow_tracking_server:                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1383 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">sagemaker.mlflow.forward_sagemaker_metrics</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> log_sagemaker_job  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\estimator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2766</span> in     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wait</span>                                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2763 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>logs = log_string_map[logs]                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2764 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># If logs are requested, call logs_for_jobs.</span>                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2765 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> logs != <span style=\"color: #808000; text-decoration-color: #808000\">\"None\"</span>:                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2766 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sagemaker_session.logs_for_job(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.job_name, wait=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, log_type=logs)  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2767 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2768 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sagemaker_session.wait_for_job(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.job_name)                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2769 </span>                                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6017</span> in       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">logs_for_job</span>                                                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6014 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">exceptions.CapacityError: If the training job fails with CapacityError.</span>       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6015 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">exceptions.UnexpectedStatusException: If waiting and the training job fails.</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6016 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>6017 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>_logs_for_job(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, job_name, wait, poll, log_type, timeout)                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6018 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">logs_for_processing_job</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, job_name, wait=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>, poll=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">10</span>):                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6020 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Display logs for a given processing job, optionally tailing them until the is</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8630</span> in       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_logs_for_job</span>                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8627 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>last_profiler_rule_statuses = profiler_rule_statuses                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8628 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8629 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> wait:                                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>8630 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>_check_job_status(job_name, description, <span style=\"color: #808000; text-decoration-color: #808000\">\"TrainingJobStatus\"</span>)                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8631 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> dot:                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8632 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>()                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8633 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Customers are not billed for hardware provisioning, so billable time is less t</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">d:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8694</span> in       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_check_job_status</span>                                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8691 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>allowed_statuses=[<span style=\"color: #808000; text-decoration-color: #808000\">\"Completed\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"Stopped\"</span>],                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8692 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>actual_status=status,                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8693 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>8694 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> exceptions.UnexpectedStatusException(                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8695 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>message=message,                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8696 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>allowed_statuses=[<span style=\"color: #808000; text-decoration-color: #808000\">\"Completed\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"Stopped\"</span>],                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8697 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>actual_status=status,                                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">UnexpectedStatusException: </span>Error for Training job p5-amazon-bin-job-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20250206</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">053943</span>: Failed. Reason: \n",
       "AlgorithmError: ExecuteUserScriptError:\n",
       "ExitCode <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "ErrorMessage <span style=\"color: #008700; text-decoration-color: #008700\">\"RuntimeError: Timeout: A call to a collective SMDDP operation has taken over 1800 seconds. </span>\n",
       "<span style=\"color: #008700; text-decoration-color: #008700\">Terminating the distributed job.\"</span>\n",
       "Command \"mpirun --host algo-1:1,algo-2:1 -np <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> --allow-run-as-root --tag-output --oversubscribe -mca \n",
       "btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> -mca pml ob1 -mca btl ^openib \n",
       "-mca orte_abort_on_non_zero_status <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> -x \n",
       "<span style=\"color: #d7af00; text-decoration-color: #d7af00\">NCCL_SOCKET_IFNAME</span>=<span style=\"color: #e100e1; text-decoration-color: #e100e1\">eth0</span> -x <span style=\"color: #d7af00; text-decoration-color: #d7af00\">NCCL_DEBUG</span>=<span style=\"color: #e100e1; text-decoration-color: #e100e1\">INFO</span> -x LD_LIBRARY_PATH -x PATH -x <span style=\"color: #d7af00; text-decoration-color: #d7af00\">SMDATAPARALLEL_USE_HOMOGENEOUS</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> -x \n",
       "<span style=\"color: #d7af00; text-decoration-color: #d7af00\">FI_PROVIDER</span>=<span style=\"color: #e100e1; text-decoration-color: #e100e1\">efa</span> -x <span style=\"color: #d7af00; text-decoration-color: #d7af00\">RDMAV_FORK_SAFE</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> -x \n",
       "<span style=\"color: #d7af00; text-decoration-color: #d7af00\">LD_PRELOAD</span>=<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/opt/conda/lib/python3.9/site-packages/gethostname.cpython-39-x86_64-linux-gnu.so</span> -x \n",
       "<span style=\"color: #d7af00; text-decoration-color: #d7af00\">SMDATAPARALLEL_SERVER_ADDR</span>=<span style=\"color: #e100e1; text-decoration-color: #e100e1\">algo</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> -x <span style=\"color: #d7af00; text-decoration-color: #d7af00\">SMDATAPARALLEL_SERVER_PORT</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7592</span> -x <span style=\"color: #d7af00; text-decoration-color: #d7af00\">SAGEMAKER_INSTANCE_TYPE</span>=<span style=\"color: #e100e1; text-decoration-color: #e100e1\">ml</span>.g4dn.xlarge \n",
       "smddprun <span style=\"color: #e100e1; text-decoration-color: #e100e1\">/opt/conda/bin/python3.9</span> -m mpi4py train.py --batch-size <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span> --class-weights-dict \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.7004885993485341</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9083079599826012</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7832708177044261</span>. Check troubleshooting guide for common errors: \n",
       "<span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;0;0m╭─\u001b[0m\u001b[38;2;255;0;0m──────────────────────────────\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0m───────────────────────────────\u001b[0m\u001b[38;2;255;0;0m─╮\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[33md:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m:\u001b[94m1\u001b[0m \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[94m355\u001b[0m in \u001b[92mtime\u001b[0m                                                                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1352 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# multi-line %%time case\u001b[0m                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1353 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m expr_val \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1354 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcode_2 = \u001b[96mself\u001b[0m.shell.compile(expr_val, source, \u001b[33m'\u001b[0m\u001b[33meval\u001b[0m\u001b[33m'\u001b[0m)                 \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m1355 \u001b[2m│   │   │   │   │   \u001b[0mout = \u001b[96meval\u001b[0m(code_2, glob, local_ns)                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1356 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m:                                                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1357 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.shell.showtraceback()                                                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1358 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m                                                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[33md:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logg\u001b[0m \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[33ming.py\u001b[0m:\u001b[94m167\u001b[0m in \u001b[92mwrapper\u001b[0m                                                                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcaught_ex = e                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m165 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m caught_ex:                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m167 \u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m caught_ex                                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m response  \u001b[2m# pylint: disable=W0150\u001b[0m                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m170 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlogger.debug(                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[33md:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logg\u001b[0m \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[33ming.py\u001b[0m:\u001b[94m138\u001b[0m in \u001b[92mwrapper\u001b[0m                                                                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m135 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mstart_timer = perf_counter()                                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m# Call the original function\u001b[0m                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m138 \u001b[2m│   │   │   │   │   \u001b[0mresponse = func(*args, **kwargs)                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mstop_timer = perf_counter()                                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0melapsed = stop_timer - start_timer                                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mextra += \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m&x-latency=\u001b[0m\u001b[33m{\u001b[0m\u001b[96mround\u001b[0m(elapsed,\u001b[90m \u001b[0m\u001b[94m2\u001b[0m)\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[33md:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\workflow\\pipeline_contex\u001b[0m \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[33mt.py\u001b[0m:\u001b[94m346\u001b[0m in \u001b[92mwrapper\u001b[0m                                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m343 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m344 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m _StepArguments(retrieve_caller_name(self_instance), run_func, *args,    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m345 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m346 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m run_func(*args, **kwargs)                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m347 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m348 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m wrapper                                                                         \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m349 \u001b[0m                                                                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[33md:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\estimator.py\u001b[0m:\u001b[94m1380\u001b[0m in \u001b[92mfit\u001b[0m \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1377 \u001b[0m\u001b[2m│   │   │   \u001b[0mwait = \u001b[94mTrue\u001b[0m                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1378 \u001b[0m\u001b[2m│   │   │   \u001b[0mforward_to_mlflow_tracking_server = \u001b[94mTrue\u001b[0m                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1379 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m wait:                                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m1380 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.latest_training_job.wait(logs=logs)                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1381 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1382 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m forward_to_mlflow_tracking_server:                                         \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1383 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96msagemaker\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mmlflow\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mforward_sagemaker_metrics\u001b[0m \u001b[94mimport\u001b[0m log_sagemaker_job  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[33md:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\estimator.py\u001b[0m:\u001b[94m2766\u001b[0m in     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[92mwait\u001b[0m                                                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2763 \u001b[0m\u001b[2m│   │   │   \u001b[0mlogs = log_string_map[logs]                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2764 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# If logs are requested, call logs_for_jobs.\u001b[0m                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2765 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m logs != \u001b[33m\"\u001b[0m\u001b[33mNone\u001b[0m\u001b[33m\"\u001b[0m:                                                                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m2766 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.sagemaker_session.logs_for_job(\u001b[96mself\u001b[0m.job_name, wait=\u001b[94mTrue\u001b[0m, log_type=logs)  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2767 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2768 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.sagemaker_session.wait_for_job(\u001b[96mself\u001b[0m.job_name)                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2769 \u001b[0m                                                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[33md:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\u001b[0m:\u001b[94m6017\u001b[0m in       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[92mlogs_for_job\u001b[0m                                                                                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6014 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mexceptions.CapacityError: If the training job fails with CapacityError.\u001b[0m       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6015 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mexceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[0m  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6016 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m6017 \u001b[2m│   │   \u001b[0m_logs_for_job(\u001b[96mself\u001b[0m, job_name, wait, poll, log_type, timeout)                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6018 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6019 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mlogs_for_processing_job\u001b[0m(\u001b[96mself\u001b[0m, job_name, wait=\u001b[94mFalse\u001b[0m, poll=\u001b[94m10\u001b[0m):                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6020 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Display logs for a given processing job, optionally tailing them until the is\u001b[0m  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[33md:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\u001b[0m:\u001b[94m8630\u001b[0m in       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[92m_logs_for_job\u001b[0m                                                                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8627 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlast_profiler_rule_statuses = profiler_rule_statuses                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8628 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8629 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m wait:                                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m8630 \u001b[2m│   │   \u001b[0m_check_job_status(job_name, description, \u001b[33m\"\u001b[0m\u001b[33mTrainingJobStatus\u001b[0m\u001b[33m\"\u001b[0m)                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8631 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m dot:                                                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8632 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mprint\u001b[0m()                                                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8633 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Customers are not billed for hardware provisioning, so billable time is less t\u001b[0m  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[33md:\\Users\\guido\\miniconda3\\envs\\awsmle_py310\\lib\\site-packages\\sagemaker\\session.py\u001b[0m:\u001b[94m8694\u001b[0m in       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[92m_check_job_status\u001b[0m                                                                                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8691 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mallowed_statuses=[\u001b[33m\"\u001b[0m\u001b[33mCompleted\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mStopped\u001b[0m\u001b[33m\"\u001b[0m],                                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8692 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mactual_status=status,                                                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8693 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m8694 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m exceptions.UnexpectedStatusException(                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8695 \u001b[0m\u001b[2m│   │   │   \u001b[0mmessage=message,                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8696 \u001b[0m\u001b[2m│   │   │   \u001b[0mallowed_statuses=[\u001b[33m\"\u001b[0m\u001b[33mCompleted\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mStopped\u001b[0m\u001b[33m\"\u001b[0m],                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8697 \u001b[0m\u001b[2m│   │   │   \u001b[0mactual_status=status,                                                         \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mUnexpectedStatusException: \u001b[0mError for Training job p5-amazon-bin-job-\u001b[1;36m20250206\u001b[0m-\u001b[1;36m053943\u001b[0m: Failed. Reason: \n",
       "AlgorithmError: ExecuteUserScriptError:\n",
       "ExitCode \u001b[1;36m1\u001b[0m\n",
       "ErrorMessage \u001b[38;2;0;135;0m\"RuntimeError: Timeout: A call to a collective SMDDP operation has taken over 1800 seconds. \u001b[0m\n",
       "\u001b[38;2;0;135;0mTerminating the distributed job.\"\u001b[0m\n",
       "Command \"mpirun --host algo-1:1,algo-2:1 -np \u001b[1;36m2\u001b[0m --allow-run-as-root --tag-output --oversubscribe -mca \n",
       "btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn \u001b[1;36m1\u001b[0m -mca pml ob1 -mca btl ^openib \n",
       "-mca orte_abort_on_non_zero_status \u001b[1;36m1\u001b[0m -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent \u001b[1;36m2\u001b[0m -x \n",
       "\u001b[38;2;215;175;0mNCCL_SOCKET_IFNAME\u001b[0m=\u001b[38;2;225;0;225meth0\u001b[0m -x \u001b[38;2;215;175;0mNCCL_DEBUG\u001b[0m=\u001b[38;2;225;0;225mINFO\u001b[0m -x LD_LIBRARY_PATH -x PATH -x \u001b[38;2;215;175;0mSMDATAPARALLEL_USE_HOMOGENEOUS\u001b[0m=\u001b[1;36m1\u001b[0m -x \n",
       "\u001b[38;2;215;175;0mFI_PROVIDER\u001b[0m=\u001b[38;2;225;0;225mefa\u001b[0m -x \u001b[38;2;215;175;0mRDMAV_FORK_SAFE\u001b[0m=\u001b[1;36m1\u001b[0m -x \n",
       "\u001b[38;2;215;175;0mLD_PRELOAD\u001b[0m=\u001b[38;2;225;0;225m/opt/conda/lib/python3.9/site-packages/\u001b[0m\u001b[38;2;225;0;225mgethostname.cpython-39-x86_64-linux-gnu.so\u001b[0m -x \n",
       "\u001b[38;2;215;175;0mSMDATAPARALLEL_SERVER_ADDR\u001b[0m=\u001b[38;2;225;0;225malgo\u001b[0m-\u001b[1;36m1\u001b[0m -x \u001b[38;2;215;175;0mSMDATAPARALLEL_SERVER_PORT\u001b[0m=\u001b[1;36m7592\u001b[0m -x \u001b[38;2;215;175;0mSAGEMAKER_INSTANCE_TYPE\u001b[0m=\u001b[38;2;225;0;225mml\u001b[0m.g4dn.xlarge \n",
       "smddprun \u001b[38;2;225;0;225m/opt/conda/bin/\u001b[0m\u001b[38;2;225;0;225mpython3.9\u001b[0m -m mpi4py train.py --batch-size \u001b[1;36m256\u001b[0m --class-weights-dict \n",
       "\u001b[1;36m1\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.7004885993485341\u001b[0m,\u001b[1;36m2\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.9083079599826012\u001b[0m,\u001b[1;36m3\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.7832708177044261\u001b[0m. Check troubleshooting guide for common errors: \n",
       "\u001b[4;38;2;0;105;255mhttps://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# TODO: Fit your estimator\n",
    "from datetime import datetime\n",
    "estimator.fit(\n",
    "    wait=True,  \n",
    "    job_name=f\"p5-amazon-bin-job-{datetime.now().strftime('%Y%m%d-%H%M%S')}\", \n",
    "    ## Use WebDataset pipe to stream data instead \n",
    "    # inputs={\n",
    "    #     \"train\": train_data,  \n",
    "    #     \"validation\": val_data, \n",
    "    #     \"test\": test_data,\n",
    "    # },  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standout Suggestions\n",
    "You do not need to perform the tasks below to finish your project. However, you can attempt these tasks to turn your project into a more advanced portfolio piece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "**TODO:** Here you can perform hyperparameter tuning to increase the performance of your model. You are encouraged to \n",
    "- tune as many hyperparameters as you can to get the best performance from your model\n",
    "- explain why you chose to tune those particular hyperparameters and the ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your hyperparameter search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your training estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit your estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the best hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Profiling and Debugging\n",
    "**TODO:** Use model debugging and profiling to better monitor and debug your model training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up debugging and profiling rules and hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and fit an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot a debugging output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Is there some anomalous behaviour in your debugging output? If so, what is the error and how will you fix it?  \n",
    "**TODO**: If not, suppose there was an error. What would that error look like and how would you have fixed it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the profiler output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deploying and Querying\n",
    "**TODO:** Can you deploy your model to an endpoint and then query that endpoint to get a result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Deploy your model to an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run an prediction on the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remember to shutdown/delete your endpoint once your work is done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheaper Training and Cost Analysis\n",
    "**TODO:** Can you perform a cost analysis of your system and then use spot instances to lessen your model training cost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train your model using a spot instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train your model on Multiple Instances"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "awsmle_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
